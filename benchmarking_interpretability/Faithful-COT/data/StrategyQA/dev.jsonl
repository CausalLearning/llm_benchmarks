{"id": 916, "term": "Conducting", "description": "Directing a musical performance by way of visible gestures", "question": "Do solo pianists require a conductor?", "answer": false, "facts": ["Conductors direct a group of musicians by ensuring they all keep the same beat and place in the music.", "A solo pianist performing alone can keep their own pace."], "decomposition": ["What is the minimum number of music performers that would need a conductor?", "Is #1 less than or equal to the number in a solo performance?"], "evidence": [[[["Conducting-32"]], [["Conducting-32"]]], [[["Conducting-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Conducting-1"], "no_evidence"], [["Solo performance-1"], "operation"]]]}
{"id": 823, "term": "September", "description": "ninth month in the Julian and Gregorian calendars", "question": "Does Home Depot sell item in late September zodiac sign symbol?", "answer": true, "facts": ["The zodiac sign for late September is Libra.", "The Libra zodiac sign is represented by scales. ", "Home Depot sells a number of scales including Pelouze and Ozeri brands."], "decomposition": ["What is the zodiac sign that represents late September?", "What is symbol of #1?", "What kinds of goods (and services) does The Home Depot deal in?", "Is #2 likely to be included in #3?"], "evidence": [[[["Libra (astrology)-1"]], [["Weighing scale-1"]], [["The Home Depot-1"]], ["operation"]], [[["Libra (astrology)-1"]], [["Libra (astrology)-2"]], [["The Home Depot-1"]], ["operation"]], [[["Libra-1"]], [["Libra (astrology)-2"]], [["The Home Depot-1"]], ["operation"]]]}
{"id": 956, "term": "Jerry Seinfeld", "description": "American comedian and actor", "question": "Did Jerry Seinfeld have reason to cheer in 1986?", "answer": true, "facts": ["Jerry Seinfeld is a fan of the New York Mets baseball team", "The New York Mets won a World Series title in 1986"], "decomposition": ["Do fans cheer if their team wins?", "Is Jerry Seinfeld a NY Mets fan?", "Did the NY Mets win the World Series in 1986?", "Is #1, #2 and #3 \"yes\"?"], "evidence": [[[["Cheering-20"]], [["Jerry Seinfeld-28"]], [["1986 World Series-4"]], ["operation"]], [[["Cheering-18"], "no_evidence"], [["Jerry Seinfeld-28"]], [["1986 World Series-1"]], ["operation"]], [[["Cheering-1"]], [["The Boyfriend (Seinfeld)-2"]], [["1986 World Series-1"]], ["operation"]]]}
{"id": 688, "term": "Jackie Chan", "description": "Hong Kong actor and martial artist", "question": "Would Jackie Chan have trouble communicating with a deaf person?", "answer": false, "facts": ["Jackie Chan speaks Cantonese, Mandarin, English, and American Sign Language.", "American Sign Language (ASL) is a natural language that serves as the predominant sign language of Deaf communities in the United States and most of Anglophone Canada."], "decomposition": ["What languages can Jackie Chan speak?", "What language do deaf people communicate with?", "Is #2 not included in #1?"], "evidence": [[[["Jackie Chan-38"]], [["Sign language-1"]], ["operation"]], [[["Jackie Chan-38"]], [["Sign language-3"]], ["operation"]], [[["Jackie Chan-38"]], [["American Sign Language-1"]], ["operation"]]]}
{"id": 323, "term": "Snow White", "description": "fairy tale", "question": "Do Snow White dwarves best The Hobbit dwarves in battle?", "answer": false, "facts": ["Snow White had seven dwarves.", "There are 13 dwarves in The Hobbit.", "Several of The Hobbit dwarves, including Thorin Oakenshield, were acclaimed warriors."], "decomposition": ["How many dwarves are there in the Snow White story?", "How many dwarves are in The Hobbit?", "Is #1 greater than #2?"], "evidence": [[[["Snow White and the Seven Dwarfs (1937 film)-7"]], [["The Hobbit-7"]], ["operation"]], [[["Snow White-3"]], [["Hobbit-13"], "no_evidence"], ["operation"]], [[["Snow White (Fables)-1"]], [["The Hobbit-26"], "no_evidence"], ["operation"]]]}
{"id": 800, "term": "Alexander Graham Bell", "description": "scientist and inventor known for his work on the telephone", "question": "Would Alexander Graham Bell hypothetically support Nazi eugenics?", "answer": true, "facts": ["Eugenics was the idea of selective breeding or sterilization to rid the human populace of certain traits.", "Nazis used eugenics to justify mass sterilization and mass murder.", "Alexander Graham Bell Alexander Graham Bell advocated against the use of sign language and hoped to eradicate deafness through selective breeding."], "decomposition": ["What did the Nazi's use to justify mass sterilization and mass murder?", "What is the definition of #1?", "What did Alexander Graham Bell advocate against the use of?", "Did Alexander Graham Bell use #2 to get rid of #3?"], "evidence": [[[["Nazi eugenics-3"]], [["Eugenics-1"]], [["History of eugenics-21"], "no_evidence"], ["no_evidence"]], [[["Eugenics-4"]], [["Eugenics-1"]], [["History of eugenics-21"]], ["operation"]], [[["Nazism and race-3", "Nazism-59", "Nazism-60"]], [["Racial hierarchy-11"]], [["History of eugenics-21"]], ["no_evidence", "operation"]]]}
{"id": 124, "term": "Modern Family", "description": "American comedy TV series", "question": "Did Modern Family win a Slammy award?", "answer": false, "facts": ["Modern Family is a television sitcom", "The Slammy Awards were presented to people involved in professional wrestling"], "decomposition": ["What television genre is Modern Family?", "What genre are the Slammy Awards given to?", "Is #1 and #2 the same?"], "evidence": [[[["Modern Family-1"]], [["Slammy Award-1"]], ["operation"]], [[["Modern Family-1"]], [["Slammy Award-1"]], ["operation"]], [[["Modern Family-1"]], [["Slammy Award-1"]], ["operation"]]]}
{"id": 165, "term": "Chives", "description": "edible species of plant", "question": "Are there any chives hypothetically good for battling vampires?", "answer": true, "facts": ["Vampires in folklore have a weakness to garlic.", "Chives, an edible plant species, come in a number of varieties.", "Garlic chives are a variant of chives first found in China thousands of years ago."], "decomposition": ["What items are used to ward off vampires according to folklore?", "What are the varieties of chives that exist?", "Is any of #1 included in #2?"], "evidence": [[[["Garlic-61"]], [["Garlic-1"]], [["Garlic-1"], "operation"]], [[["Vampire-16"]], [["Chives-1"]], ["operation"]], [[["Garlic-61"]], [["Allium-1"]], ["operation"]]]}
{"id": 194, "term": "Tom Cruise", "description": "American actor and producer", "question": "Would Tom Cruise ever insult L. Ron Hubbard?", "answer": false, "facts": ["Tom Cruise is an outspoken advocate for the Church of Scientology and its associated social programs.", "The Church of Scientology was founded by L. Ron Hubbard.", "L. Ron Hubbard is a revered and god-like figure in The Church of Scientology."], "decomposition": ["What was founded by Ron Hubbard? ", "Would Tom Cruise ever insult #1"], "evidence": [[[["L. Ron Hubbard-86"]], [["Tom Cruise-36"]]], [[["L. Ron Hubbard-1"]], [["Tom Cruise-4"]]], [[["L. Ron Hubbard-1"]], [["Tom Cruise-4"]]]]}
{"id": 370, "term": "Ahura Mazda", "description": "highest deity of Zoroastrianism", "question": "Does Ahura Mazda have a rivalry with Zeus?", "answer": false, "facts": ["Ahura Mazda is a deity of Zoroastrianism, a contemporary religion", "Zeus is a deity of Greek mythology"], "decomposition": ["What belief system is Ahura Mazda associated with?", "What belief system is Zeus associated with?", "Is #1 the same as #2?"], "evidence": [[[["Ahura Mazda-1"]], [["Zeus-1"]], ["operation"]], [[["Ahura Mazda-1"]], [["Zeus-1"]], ["operation"]], [[["Ahura Mazda-1"]], [["Zeus-1"]], ["operation"]]]}
{"id": 919, "term": "Metallica", "description": "American heavy metal band", "question": "Did the original lead guitarist of Metallica fail after parting from the band?", "answer": false, "facts": ["Metallica's original lead guitarist was Dave Mustaine.", "Dave Mustaine was fired from Metallica in 1983.", "Dave Mustaine formed the band Megadeth in 1983 and is the lead vocalist.", "Megadeth has sold over 38 million records worldwide."], "decomposition": ["Who was the original lead guitarist of Metallica?", "What band did #1 start after leaving Metallica?", "Is #2 an unsuccessful band?"], "evidence": [[[["Metallica-6"]], [["Dave Mustaine-1"]], [["Megadeth-4"], "operation"]], [[["Metallica-1"]], [["Megadeth-1"]], [["Megadeth-88"], "operation"]], [[["Dave Mustaine-1"]], [["Dave Mustaine-1"]], [["Megadeth-4"]]]]}
{"id": 672, "term": "Lionel Richie", "description": "American singer-songwriter, musician, record producer and actor", "question": "Did Lionel Richie ever have dinner with Abraham Lincoln?", "answer": false, "facts": ["Abraham Lincoln died in 1865.", "Lionel Richie was born in 1949."], "decomposition": ["When did Abraham Lincoln die?", "When was Lionel Richie born?", "Is #2 before #1?"], "evidence": [[[["Abraham Lincoln-1"]], [["Lionel Richie-1"]], ["operation"]], [[["Outline of Abraham Lincoln-2"]], [["Lionel Richie-1"]], ["operation"]], [[["Abraham Lincoln-1"]], [["Lionel Richie-1"]], ["operation"]]]}
{"id": 76, "term": "Veto", "description": "legal power to unilaterally stop an official action, especially the enactment of legislation", "question": "Can the US branch of government that has power over the military also have the power to veto?", "answer": true, "facts": ["The US President is the commander in chief of the US military.", "The executive branch of the USA includes the President.", "The President has power to veto."], "decomposition": ["What US branch has power over the military?", "Who has the power to veto?", "Is #2 part of #1?"], "evidence": [[[["Article Two of the United States Constitution-1", "Article Two of the United States Constitution-4", "Executive (government)-5"]], [["Federal government of the United States-18", "Veto-1"]], ["operation"]], [[["Federal government of the United States-17"]], [["Federal government of the United States-17", "Federal government of the United States-18"]], [["Federal government of the United States-17"]]], [[["Federal jurisdiction (United States)-4"]], [["Veto-34"]], ["operation"]]]}
{"id": 943, "term": "Equator", "description": "Intersection of a sphere's surface with the plane perpendicular to the sphere's axis of rotation and midway between the poles", "question": "Is most coffee produced South of the Equator?", "answer": true, "facts": ["The countries with the highest coffee production are in South America.", "Almost all of South America is in the Southern Hemisphere."], "decomposition": ["Which countries produce the most coffee?", "Which hemisphere are most of #1 located?", "Is #2 south of the equator?"], "evidence": [[[["Coffee-45"], "no_evidence"], ["no_evidence"], [["Brazil-43"], "no_evidence", "operation"]], [[["Coffee-5"], "no_evidence"], [["Southern Hemisphere-9"]], [["Southern Hemisphere-1"], "operation"]], [[["Coffee-5"]], [["Southern Hemisphere-9"]], [["Southern Hemisphere-9"]]]]}
{"id": 912, "term": "New Year's Day", "description": "Holiday", "question": "Do Jehovah's Witnesses celebrate day before New Year's Day?", "answer": false, "facts": ["The Day before New Year's Day is New Year's Eve.", "Jehovah's Witnesses do not celebrate holidays, citing in many cases that they have pagan origins.", "New Year's has origins in pagan Babylonia."], "decomposition": ["Which holidays do Jehovah's Witnesses refrain from celebrating or participating in?", "What is the day before New Year's Day known as?", "Is #2 included in #1?"], "evidence": [[[["Jehovah's Witnesses practices-42", "Jehovah's Witnesses-3"]], [["New Year's Eve-1"]], ["operation"]], [[["Jehovah's Witnesses-3"]], [["New Year's Eve-1"], "no_evidence"], ["operation"]], [[["Jehovah's Witnesses-41"]], [["New Year's Eve-41"]], [["Jehovah's Witnesses-41", "New Year's Eve-41"], "operation"]]]}
{"id": 363, "term": "Alfred Nobel", "description": "Swedish chemist, innovator, and armaments manufacturer (1833–1896)", "question": "Has categories of Nobel prizes remained same since Alfred Nobel established them?", "answer": false, "facts": ["Alfred Nobel established the Nobel prize in his will in 1895.", "Alfred Nobel established 5 Nobel prize categories: Chemistry, Literature, Peace, Physics, and Physiology or Medicine.", "The Nobel prize evolved to include a sixth category of Economic Sciences in 1968."], "decomposition": ["When did Alfred Nobel establish the Nobel prize?", "Has the Nobel Prize remained unchanged in all respects since #1?"], "evidence": [[[["Nobel Prize-1"]], [["Nobel Prize-21"], "operation"]], [[["Nobel Prize-1"]], [["Nobel Prize-2"]]], [[["Alfred Nobel-13"]], [["Alfred Nobel-14", "Alfred Nobel-17"], "operation"]]]}
{"id": 219, "term": "Monty Python's Flying Circus", "description": "British sketch comedy television series", "question": "Did Monty Python write the Who's on First sketch?", "answer": false, "facts": ["Who's on First debuted in 1945.", "Monty Python's first show was in 1969."], "decomposition": ["When was the Who's on First sketch first performed?", "When was the debut of the Monty Python show?", "Is #2 before #1?"], "evidence": [[[["Who's on First?-2"]], [["Monty Python-1"]], ["operation"]], [[["Abbott and Costello-25", "Who's on First?-3"]], [["Monty Python's Flying Circus-16"]], ["operation"]], [[["Who's on First?-2", "Who's on First?-3"]], [["Monty Python-1"]], ["operation"]]]}
{"id": 91, "term": "Ronda Rousey", "description": "American professional wrestler, actress, author, mixed martial artist and judoka", "question": "Does Ronda Rousey avoid BBQ restaraunts?", "answer": true, "facts": ["Ronda Rousey is a professional athlete in MMA.", "Ronda Rousey is a vegan.", "BBQ is a style of restaurant that predominantly serves cooked meat.", "Meat consumption is opposed and avoided by vegans.", "Vegans don't eat meat."], "decomposition": ["What kind of food is served at BBQ restaurants?", "What dietary restrictions does Ronda Rousey follow?", "Would #2 avoid #1?"], "evidence": [[[["Ribs (food)-4"]], [["Ronda Rousey-73"]], [["Veganism-24"]]], [[["Barbecue restaurant-10"]], [["Ronda Rousey-73"]], [["Paleolithic diet-11"], "operation"]], [[["Barbecue-3"]], [["Ronda Rousey-73"]], [["Veganism-1"], "operation"]]]}
{"id": 466, "term": "Blueberry", "description": "section of plants", "question": "Was the Treaty of Versailles settled over blueberry scones?", "answer": false, "facts": ["Blueberries are native to North America.", "Blueberries did not come to Europe until the 1930's.", "The treaty of Versailles was made effective in 1920. "], "decomposition": ["Where was the The Treaty of Versailles settled?", "When did blueberries first go over to #1?", "When was The Treaty of Versailles settled?", "Did #2 occur before #3?"], "evidence": [[[["Paris Peace Conference (1919–1920)-1"]], [["Blueberry-33"], "no_evidence"], [["Treaty of Versailles-1"]], ["operation"]], [[["Paris-1", "Treaty of Versailles-1", "Versailles, Yvelines-1"]], [["Blueberry-33"]], [["Treaty of Versailles-1"]], ["operation"]], [[["Treaty of Versailles-7"]], ["no_evidence"], [["Treaty of Versailles-7"]], ["no_evidence", "operation"]]]}
{"id": 944, "term": "New Mexico", "description": "U.S. state in the United States", "question": "Is the largest city in New Mexico also known as Yootó?", "answer": false, "facts": ["Yootó stands for Bead Water Place.", "The area Santa Fe occupied was known by the Navajo people as Yootó.", "The largest city in New Mexico is Albuquerque."], "decomposition": ["What is the largest city in New Mexico?", "Is #1 known as Yootó?"], "evidence": [[[["Albuquerque, New Mexico-1"]], ["operation"]], [[["Albuquerque, New Mexico-1"]], ["operation"]], [["no_evidence"], [["Santa Fe, New Mexico-1"]]]]}
{"id": 75, "term": "Brussels sprout", "description": "vegetable", "question": "Are Brussels sprout particularly good for adrenal fatigue?", "answer": true, "facts": ["Adenal fatigue is a disorder in which the body does not produce enough hormones and people get tired.", "Brussels sprout are foods rich in vitamin C.", "When stress levels rise, the adrenal glands require more Vitamin C and it is used very quickly."], "decomposition": ["What vitamins are found in abundance in Brussels sprouts?", "What vitamins do the adrenal glands require when a body is under stress?", "Is #2 found in #1?"], "evidence": [[[["Brussels sprout-12"]], [["Adrenaline-29"]], ["operation"]], [[["Brussels sprout-12"]], [["Adrenal gland-2"], "no_evidence"], ["no_evidence"]], [[["Brussels sprout-12"]], [["Adrenal fatigue-1", "Adrenal gland-2"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 566, "term": "Supreme Court of Canada", "description": "highest court of Canada", "question": "Is clerk of Supreme Court of Canada safe profession for someone with seismophobia?", "answer": true, "facts": ["Seismophobia is the extreme fear of earthquakes.", "The Supreme Court of Canada is located in Ottawa.", "The Ottawa-Gattineau region is located far from active tectonic plates."], "decomposition": ["What is seismophobia a fear of?", "Movement of what causes #1?", "Where is the Supreme Court of Canada located?", "Is #3 located near active #2's?"], "evidence": [[[["2019–20 Puerto Rico earthquakes-23"]], [["Earthquake-3"]], ["no_evidence"], [["Earthquake-25"], "operation"]], [[["Earthquake-1"], "no_evidence"], [["Earthquake-3"]], [["Supreme Court of Canada-19"]], [["Ottawa-16"], "operation"]], [[["2019–20 Puerto Rico earthquakes-23"], "no_evidence"], [["Seismology-5"]], [["Supreme Court of Canada-19"]], [["Ottawa-16"], "operation"]]]}
{"id": 13, "term": "Frigate", "description": "Type of warship", "question": "Are ropes required to operate a frigate?", "answer": true, "facts": ["Frigates are a kind of sailing ship.", "Many features of ships require rope to use."], "decomposition": ["What force powers frigates?", "What characteristic of frigates allows them to use #1?", "Are ropes used to manipulate #2?"], "evidence": [[[["Sailing-1"]], [["Frigate-6"]], [["Sailing ship-35"], "operation"]], [[["Frigate-11"]], [["Sail-1"]], [["Sail-3"], "no_evidence"]], [[["Full-rigged ship-5"], "no_evidence"], [["Rigging-1"]], ["operation"]]]}
{"id": 223, "term": "Chinook salmon", "description": "species of fish", "question": "Could eating Chinook salmon help Ryan Reynolds?", "answer": true, "facts": ["Chinook salmon is high in omega-3 fatty acids.", "Omega-3 fatty acids can aid treatment of depression. ", "Ryan Reynolds has struggled with depression."], "decomposition": ["What mental disorder did Ryan Reynolds suffer from?", "What nutrient may be able to aid in treatment of #1?", "Is chinook salmon high in #2?"], "evidence": [[[["Ryan Reynolds-24"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Ryan Reynolds-24"]], [["Anxiety disorder-29", "Anxiety-58"], "no_evidence"], [["Chinook salmon-2"], "no_evidence"]], [[["Ryan Reynolds-24"]], [["Generalized anxiety disorder-20"]], ["operation"]]]}
{"id": 277, "term": "Apollo 13", "description": "A failed crewed mission to land on the Moon", "question": "Was ship that recovered Apollo 13 named after a World War II battle?", "answer": true, "facts": ["Apollo 13 was recovered by the USS Iwo Jima.", "Iwo Jima was captured from the Imperial Japanese Army during World War II by the US in a conflict called the Battle of Iwo Jima."], "decomposition": ["Which ship recovered Apollo 13 crew?", "What was #1 named for?", "Did #2 occur during World War II?"], "evidence": [[[["USS Iwo Jima (LPH-2)-13"]], [["USS Iwo Jima (LPH-2)-1"]], [["Battle of Iwo Jima-1"]]], [[["Apollo 13-55"]], [["USS Iwo Jima (LPH-2)-1"]], ["operation"]], [[["Apollo 13-55"]], [["Iwo Jima-3"]], [["Iwo Jima-19"]]]]}
{"id": 189, "term": "The Jackson 5", "description": "American pop music family group", "question": "Could the Jackson 5 play a full game of rugby with each other?", "answer": false, "facts": ["The Jackson 5 consisted of five members.", "A full game of rugby is played between 2 teams of 15 players each."], "decomposition": ["How many members are in the Jackson 5?", "How many players are there in a full game of rugby?", "Is #1 greater than or equal to #2?"], "evidence": [[[["The Jackson 5-1"]], [["Rugby union-1"]], ["operation"]], [[["The Jackson 5-1"]], [["Rugby union-1"]], ["operation"]], [[["The Jackson 5-1"]], [["Rugby league positions-1"]], ["operation"]]]}
{"id": 553, "term": "Grizzly bear", "description": "Subspecies of mammal", "question": "Did occupants of Vellore Fort need to defend themselves from Grizzly Bears?", "answer": false, "facts": ["The Vellore Fort was a 16th century stronghold in India.", "Grizzly Bears are native to the North American continent."], "decomposition": ["Where is the Vellore Fort located?", "Where can grizzly bears be found?", "Is #1 included in #2?"], "evidence": [[[["Vellore Fort-1"]], [["Brown bear-21"], "no_evidence"], ["operation"]], [[["Vellore Fort-1"]], [["Grizzly bear-1"]], ["operation"]], [[["Vellore Fort-1"]], [["Grizzly bear-1"]], [["India-1", "North America-1"], "operation"]]]}
{"id": 33, "term": "Bartender", "description": "person who serves usually alcoholic beverages behind the bar in a licensed establishment", "question": "Would a responsible bartender make a drink for Millie Bobby Brown?", "answer": false, "facts": ["Millie Bobby Brown is currently 16 years old.", "In the United States, the minimum legal age to purchase any alcohol beverage is 21 years old.", "Bartenders are usually responsible for confirming that customers meet the legal drinking age requirements before serving them alcoholic beverages. "], "decomposition": ["How old is Millie Bobby Brown?", "What is the minimum legal age one must be to be served alcohol in the US?", "Is #1 larger than #2?"], "evidence": [[[["Millie Bobby Brown-1"]], [["National Minimum Drinking Age Act-1"]], ["operation"]], [[["Millie Bobby Brown-1"]], [["Legal drinking age-6"]], ["operation"]], [[["Millie Bobby Brown-1"]], [["Legal drinking age-6"]], ["operation"]]]}
{"id": 533, "term": "Slot machine", "description": "Casino gambling machine", "question": "Do any video games about the end of civilization have slot machines?", "answer": true, "facts": ["Fallout New Vegas is a game that takes place after the apocalypse has ocurred. ", "In Fallout New Vegas, players can go to casinos and play on slot machines."], "decomposition": ["What video games take place in a post-apocalyptic world?", "Which video games have slot machines?", "Is at least one game in #1 found in #2?"], "evidence": [[[["Fallout (series)-2", "Fallout: New Vegas-1"]], [["Fallout: New Vegas-4"]], ["operation"]], [[["Fallout: New Vegas-1", "The Last of Us-1"], "no_evidence"], [["Fallout: New Vegas-4"], "no_evidence"], ["operation"]], [[["Fallout (series)-1"], "no_evidence"], [["Fallout: New Vegas-2", "Fallout: New Vegas-4"], "no_evidence"], ["operation"]]]}
{"id": 612, "term": "Great Pyramid of Giza", "description": "Largest pyramid in the Giza Necropolis, Egypt", "question": "Is Great Pyramid of Giza the last wonder of its kind?", "answer": true, "facts": ["The Great Pyramid of Giza is classified as one of the Seven Wonders of the Ancient World.", "Five of the ancient wonders were destroyed, and a sixth (the Hanging Gardens of Babylon) may not have existed.", "The Great Pyramid of Giza is largely intact as of 2020."], "decomposition": ["What are the wonders of the ancient world that are either destroyed or non-existent?", "What is the wonder of the ancient world that is still intact?", "Has #2 survived a much longer time than #1?"], "evidence": [[[["Seven Wonders of the Ancient World-1"]], [["Great Pyramid of Giza-1"]], ["operation"]], [[["Seven Wonders of the Ancient World-1"]], [["Great Pyramid of Giza-1"]], ["operation"]], [[["Seven Wonders of the Ancient World-1"]], [["Great Pyramid of Giza-1"]], ["no_evidence", "operation"]]]}
{"id": 660, "term": "The Atlantic", "description": "Magazine and multi-platform publisher based in Washington, D.C.", "question": "Could the Atlantic readers fill 500 battalions?", "answer": false, "facts": ["A battalion is a military unit of measurement that includes 1000 soldiers.", "As of 2018 The Atlantic has a circulation of 478,534."], "decomposition": ["What is the number of readers (copies in circulation) of The Atlantic magazines?", "What is the average number of soldiers in a battalion in the US?", "Is #1 at least equal to 500 times #2?"], "evidence": [[["no_evidence"], [["Battalion-1"]], ["operation"]], [[["The Atlantic-24"]], [["Battalion-21"], "no_evidence"], ["operation"]], [[["The Atlantic-24"]], [["Battalion-21"]], ["operation"]]]}
{"id": 441, "term": "Sophist", "description": "Specific kind of teacher in both Ancient Greece and in the Roman Empire", "question": "Would a sophist use an épée?", "answer": false, "facts": ["A sophist is a specific kind of teacher in ancient Greece, in the fifth and fourth centuries BC.", "Sophists specialized in using the tools of philosophy and rhetoric, though other sophists taught subjects such as music, athletics and mathematics.", "An épée is a sword used in fencing.", "The épée was not developed until the 19th century."], "decomposition": ["How long ago were the sophists around?", "How long ago was the epee developed?", "Is #2 greater than or equal to #1?"], "evidence": [[[["Sophist-1"]], [["Épée-15"]], ["operation"]], [[["Sophist-1"]], [["Épée-1"]], ["operation"]], [[["Sophist-1"]], [["Épée-16"]], ["operation"]]]}
{"id": 48, "term": "Jackfruit", "description": "species of plant", "question": "Would it be safe to have a jackfruit thrown at your head?", "answer": false, "facts": ["Jackfruit can weigh between 22-55 lbs. ", "Jackfruit are covered in small spikes."], "decomposition": ["How much do jackfruit weigh?", "Is #1 light enough to not hurt you?"], "evidence": [[[["Jackfruit-2"]], [["Jackfruit-2"], "no_evidence"]], [[["Jackfruit-2"]], ["operation"]], [[["Jackfruit-2"]], ["operation"]]]}
{"id": 157, "term": "Lip", "description": "Visible body part at the mouth", "question": "Does having lip piercings lead to more expensive dental bills?", "answer": true, "facts": ["Lip piercings can rub the enamel on your teeth and can cause tissue damage to the gums.", "Tooth enamel protects the teeth from decay."], "decomposition": ["What is the function of Tooth Enamel?", "Can Lip piercing cause damage to #1", "Will #2 cost you more expensive dental bills?"], "evidence": [[[["Tooth enamel-1"]], [["Tooth enamel-26"], "no_evidence"], ["no_evidence"]], [[["Tooth enamel-1"]], [["Lip piercing-5"], "no_evidence"], ["no_evidence", "operation"]], [[["Tooth enamel-21"]], [["Body piercing-42", "Lip piercing-4"]], [["Tooth enamel-39"], "no_evidence"]]]}
{"id": 71, "term": "Phobos (moon)", "description": "natural satellite of Mars", "question": "Is Phobos part of the Andromeda galaxy?", "answer": false, "facts": ["Phobos orbits around Mars.", "Mars is a planet in Earth's solar system.", "The solar system is in the Milky Way galaxy."], "decomposition": ["What planet does Phobos orbit around?", "What solar system is #1 part of?", "What galaxy is #2 part of?", "Is #3 the same as the Andromeda galaxy?"], "evidence": [[[["Phobos (moon)-1"]], [["Mars-1"]], [["Milky Way-1"]], [["Andromeda Galaxy-1"]]], [[["Phobos (moon)-1"]], [["Solar System-2"]], [["Milky Way-1"]], ["operation"]], [[["Phobos (moon)-16"]], [["Solar System-37"]], [["Solar System-73"]], ["operation"]]]}
{"id": 935, "term": "Moon Jae-in", "description": "President of South Korea", "question": "Did Moon Jae-in earn the Abitur as a teenager?", "answer": false, "facts": ["Moon Jae-in attended high school in South Korea.", "The Abitur is a qualification granted by university-preparatory schools in Germany, Lithuania, and Estonia."], "decomposition": ["Which countries' schools award Abitur to their students?", "Which country did Moon Jae-in school in as a teenager?", "Is #2 included in #1?"], "evidence": [[[["Abitur-1"]], [["Moon Jae-in-7"]], ["operation"]], [[["Abitur-1"]], [["Moon Jae-in-7"]], ["operation"]], [[["Abitur-1"]], [["Kyungnam High School-2", "Moon Jae-in-7"]], ["operation"]]]}
{"id": 260, "term": "Northern fur seal", "description": "The largest fur seal in the northern hemisphere", "question": "Is a northern fur seal needing emergency surgery in July likely a safe anesthesia candidate?", "answer": true, "facts": ["Northern fur seals fast throughout the mating season", "It is recommended that patients, including animals, fast for a time before surgery that requires anesthesia ", "Peak mating season for northern fur seals occurs in June and July"], "decomposition": ["What is recommended for patients needing anesthesia?", "What do northern fur seals do in July?", "Does #2 include #1?"], "evidence": [[[["Anesthesia-12"]], [["Northern fur seal-17"]], ["operation"]], [[["Anesthesia-7"]], [["Northern fur seal-17"]], ["operation"]], [[["Anesthesia-34"], "no_evidence"], [["Northern fur seal-17"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 258, "term": "Surveillance", "description": "monitoring of behavior, activities, or other changing information", "question": "Can you conduct surveillance from a teddy bear?", "answer": true, "facts": ["Surveillance is the act of monitoring or observation", "Nanny cams are used for surveillance of behavior when a family leaves their home and/or children in the care of a third party", "Nanny cams are often placed in common household objects like teddy bears"], "decomposition": ["In what kind of context/environment are nanny cams used for surveillance?", "Would a teddy bear accommodate a nanny can and be commonly found in #1?"], "evidence": [[[["Hidden camera-8"]], [["Hidden camera-8"]]], [[["Hidden camera-1"], "no_evidence"], [["Teddy bear-1"], "no_evidence", "operation"]], [[["Hidden camera-8"]], ["no_evidence"]]]}
{"id": 740, "term": "League of Legends", "description": "Multiplayer online battle arena video game", "question": "Could Cosmic Girls play League of Legends alone?", "answer": true, "facts": ["Cosmic Girls is a 13 member kpop group", "League of Legends is a video game requiring two teams of five players each"], "decomposition": ["How many players are needed for a League of Legends match?", "How many people are in the group \"Cosmic Girls\"?", "Is #2 greater than or equal to #1?"], "evidence": [[[["League of Legends: Wild Rift-2"], "no_evidence"], [["Cosmic Girls-1"]], ["operation"]], [[["League of Legends: Wild Rift-4"]], [["Cosmic Girls-1"]], ["operation"]], [[["League of Legends-10"]], [["Cosmic Girls-1"]], ["operation"]]]}
{"id": 26, "term": "Dementia", "description": "long-term brain disorders causing impaired memory, reasoning, and normal function together with personality changes", "question": "Can dementia be cured with a cast?", "answer": false, "facts": ["Dementia refers to various disorders of the brain.", "Casts are used to help treat broken bones.", "The brain does not contain any bones."], "decomposition": ["What part of the body does Dementia affect?", "What do cast help fix?", "Are there any #2 in #1?"], "evidence": [[[["Dementia-21"]], [["Bone fracture-22"]], [["Bone fracture-22", "Dementia-21"], "operation"]], [[["Dementia-1"]], [["Orthopedic cast-1"]], ["operation"]], [[["Dementia-1"]], [["Orthopedic cast-1"]], [["Brain-1"]]]]}
{"id": 882, "term": "2010 United Kingdom general election", "description": "election of members to the House of Commons in 2010", "question": "Did John Kerry run in the 2010 United Kingdom general election?", "answer": false, "facts": ["John Kerry is an American citizen and politician", "Only citizens of the UK, Ireland or a Commonwealth nation are eligible to run in the United Kingdom general elections"], "decomposition": ["In order to run in the UK general election, a person must be a citizen of one of which countries? ", "John Kerry is a citizen of what country?", "Is #2 listed in #1?"], "evidence": [[[["Elections in the United Kingdom-7"]], [["John Kerry-1"]], ["operation"]], [[["Member of parliament-34"]], [["John Kerry-2"]], ["operation"]], [[["Citizenship-38"], "no_evidence"], [["John Kerry-5"], "no_evidence"], ["operation"]]]}
{"id": 609, "term": "JAG (TV series)", "description": "American legal drama television series (1996-2005)", "question": "Did Joan Crawford guest star on  JAG (TV series)?", "answer": false, "facts": ["JAG began airing in 1995.", "Joan Crawford died in 1977."], "decomposition": ["When did Joan Crawford's career as a television actress come to an end?", "When was the TV series JAG launched?", "Is #2 before #1?"], "evidence": [[[["Joan Crawford-64"]], [["NCIS (TV series)-19"], "no_evidence"], ["operation"]], [[["Joan Crawford-61", "Joan Crawford-64"]], [["JAG (season 1)-1"]], ["operation"]], [[["Joan Crawford-37"]], [["JAG (season 1)-1"]], ["operation"]]]}
{"id": 207, "term": "Macbeth", "description": "play by William Shakespeare", "question": "Would costumes with robes and pointy hats be helpful for Macbeth?", "answer": true, "facts": ["Macbeth features scenes with three witches throughout the play. ", "Witches are often displayed with pointy hats and long black robes."], "decomposition": ["What characters are in Macbeth?", "What characters wear pointy hats and robes?", "Would any of #1 wear #2?"], "evidence": [[[["Macbeth-2"], "no_evidence"], [["Cloak-10", "Pointed hat-5"]], ["operation"]], [[["Macbeth-5"]], ["no_evidence"], ["operation"]], [[["Macbeth-2"]], [["Witch hat-1"]], ["operation"]]]}
{"id": 336, "term": "Isaac Newton", "description": "Influential British physicist and mathematician", "question": "Is Issac Newton often associated with a red fruit?", "answer": true, "facts": ["Issac Newton claimed to have contemplated gravity for the first time after seeing an apple fall.", "In most illustrations of Issac Newton discovering gravity, the apple shown falling is red."], "decomposition": ["Which of Isaac Newton's famous discoveries featured a fruit?", "Is #1 colored red in popular depictions?"], "evidence": [[[["Isaac Newton-84"]], ["no_evidence"]], [[["Isaac Newton-84"]], [["Apple-8"], "operation"]], [[["Isaac Newton-88"]], [["Gala (apple)-1"]]]]}
{"id": 708, "term": "Saddam Hussein", "description": "Iraqi politician and President", "question": "Did Saddam Hussein witness the inauguration of Donald Trump?", "answer": false, "facts": ["Saddam Hussein died on December 30th, 2006.", "Donald Trump was inaugurated as the President of the United States on January 20, 2017."], "decomposition": ["When did Saddam Hussein die?", "When was Donald Trump inaugurated as President?", "Is #2 before #1?"], "evidence": [[[["Saddam Hussein-101"]], [["Timeline of the Donald Trump presidency-1"]], ["operation"]], [[["Saddam Hussein-4"]], [["Inauguration of Donald Trump-1"]], ["operation"]], [[["Saddam Hussein-1"]], [["Inauguration of Donald Trump-1"]], ["operation"]]]}
{"id": 667, "term": "Ashland, Oregon", "description": "City in Oregon, United States", "question": "Is 2018 Ashland, Oregon population inadequate to be a hypothetical military division?", "answer": false, "facts": ["The 2018 population of Ashland Oregon was 21,263 people.", "The number of soldiers in a military division is between 10,000 and 25,000 people."], "decomposition": ["What was the population of Ashland, Oregon in 2018?", "How many soldiers are in a military division?", "Is #1 less than the minimum in #2?"], "evidence": [[[["Ashland, Oregon-1"], "no_evidence"], [["Division (military)-16"], "no_evidence"], ["no_evidence"]], [[["Ashland, Oregon-1"]], [["Division (military)-1"]], ["operation"]], [[["Ashland, Oregon-1"]], [["Division (military)-1"]], ["operation"]]]}
{"id": 173, "term": "Reddit", "description": "Online news aggregator", "question": "Can you buy Reddit at Walmart?", "answer": false, "facts": ["Reddit is an online social networking forum and community", "Walmart sells tangible goods and services"], "decomposition": ["What is Reddit?", "Is #1 tangible?", "Does Walmart sell tangible items??", "Are #2 and #3 the same?"], "evidence": [[[["Reddit-1"]], ["operation"], [["Walmart-1"], "no_evidence"], ["operation"]], [[["Reddit-5"]], [["Reddit-5"]], [["Walmart-5"]], [["Walmart-5"]]], [[["Reddit-1"]], ["operation"], [["Walmart-1"], "no_evidence"], ["operation"]]]}
{"id": 115, "term": "Black", "description": "The darkest shade, resulting from the absence or complete absorption of light. Like white and grey, it has no hue", "question": "Is Anakin Skywalker from Star Wars associated with the color black?", "answer": true, "facts": ["As a Jedi during the Clone Wars, Anakin Skywalker often wore black robes.", "After he was burned and transformed into the cyborg Darth Vader, he received a distinctive and famous all-black outfit including a black mask."], "decomposition": ["What is the color of most outfits worn by Star Wars' Anakin Skywalker?", "Is #1 the same as black?"], "evidence": [[[["Darth Vader-1", "Darth Vader-15"]], ["operation"]], [[["Darth Vader-15"]], ["operation"]], [[["Darth Vader-1", "Darth Vader-15"]], ["operation"]]]}
{"id": 977, "term": "Welfare", "description": "Means-oriented social benefit", "question": "Do Republicans reject all forms of welfare?", "answer": false, "facts": ["Welfare is all of the social programs that provide benefits to citizens for little or no money.", "Republicans have traditionally voted against welfare benefits in the form of food stamps and medicaid expansion.", "Public roads are a form of welfare since people are not required to build their own road each time they need to get to work."], "decomposition": ["What welfare policies are on the Republican platform?", "Are government-funded public works absent from #1?"], "evidence": [[[["Political positions of the Republican Party-3"]], [["Political positions of the Republican Party-3"]]], [[["Political positions of the Republican Party-3"]], ["operation"]], [[["Republican Party (United States)-22"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 621, "term": "Black pepper", "description": "species of plant", "question": "Are ground bell peppers the main ingredient of black pepper?", "answer": false, "facts": ["Black pepper is made from black peppercorns.", "Black peppercorns grow on the Piper Nigrum plant.", "Bell peppers are from the capsicum annuum plant."], "decomposition": ["What is used to make black pepper?", "Is #1 the same thing as bell pepper?"], "evidence": [[[["Black pepper-1"]], [["Bell pepper-1"], "operation"]], [[["Black pepper-1"]], [["Bell pepper-1"], "operation"]], [[["Black pepper-1"]], [["Bell pepper-1"]]]]}
{"id": 344, "term": "Bob Marley", "description": "Jamaican singer-songwriter", "question": "Can you find Bob Marley's face in most smoke shops?", "answer": true, "facts": ["Bob Marley's face is on the packaging of a popular brand of rolling papers.", "Bob Marley is a popular graphic to print on t-shirts for sale to smokers."], "decomposition": ["On what items is Bob Marley's face commonly found?", "Are some of #1 sold in most smoke shops?"], "evidence": [[["no_evidence"], [["Tobacconist-1"]]], [["no_evidence"], ["no_evidence", "operation"]], [[["Bob Marley-1"]], [["Head shop-1", "Tobacconist-1"], "operation"]]]}
{"id": 712, "term": "Sudoku", "description": "Logic-based number-placement puzzle", "question": "Do you need different colored pens for sudoku?", "answer": false, "facts": ["Sudoku is played both online and offline.", "Sudoku has no color component in the game."], "decomposition": ["How is Sudoku played?", "Is color necessary to do #1?"], "evidence": [[[["Sudoku-1"]], [["Sudoku-1"]]], [[["Sudoku-1"]], ["operation"]], [[["Sudoku-1"]], ["operation"]]]}
{"id": 955, "term": "Cholera", "description": "Bacterial infection of the small intestine", "question": "Is a platypus immune from cholera?", "answer": true, "facts": ["Cholera is a bacteria that damages the small intestines in humans.", "The intestines are part of the stomach of humans.", "A platypus does not have a stomach."], "decomposition": ["What parts of the body does Cholera damage?", "Does a platypus not have #1?"], "evidence": [[[["2016–2020 Yemen cholera outbreak-6"]], [["Platypus-4"], "no_evidence"]], [[["Vibrio cholerae-6"]], ["no_evidence"]], [[["Diseases and epidemics of the 19th century-10"]], ["no_evidence", "operation"]]]}
{"id": 357, "term": "Los Angeles County, California", "description": "County in California, United States", "question": "Is Disney associated with Los Angeles County?", "answer": true, "facts": ["Disney Concert Hall and Disney Studio are located in Los Angeles.", "The city of Los Angeles is located in Los Angeles County."], "decomposition": ["Where are Disney Concert Hall and Disney Studio located?", "Is #1 located in Los Angeles County?"], "evidence": [[[["Walt Disney Animation Studios-1", "Walt Disney Concert Hall-1"]], [["Burbank, California-1", "Central Los Angeles-1", "Downtown Los Angeles-1"], "operation"]], [[["Walt Disney Concert Hall-1", "Walt Disney Studios (division)-1"]], [["Burbank, California-1", "Los Angeles County, California-1"]]], [[["Walt Disney Studios (Burbank)-4"]], [["Burbank, California-1"], "operation"]]]}
{"id": 971, "term": "Sand cat", "description": "Small wild cat", "question": "Can you hide a basketball in a sand cat's ear?", "answer": false, "facts": ["The diameter of a standard NBA basketball is around 9.5 inches", "A sand cat's ear grows to 2.8 inches tall"], "decomposition": ["On average, how large is a sand cat's ear?", "What is the size of a standard NBA basketball?", "Is #1 greater than #2?"], "evidence": [[[["Sand cat-1"]], [["Basketball-1"]], ["operation"]], [[["Sand cat-1"], "no_evidence"], [["Basketball-1"]], ["no_evidence", "operation"]], [[["Sand cat-19"], "no_evidence"], [["Basketball (ball)-1"], "no_evidence"], ["operation"]]]}
{"id": 374, "term": "Cornwall", "description": "County of England", "question": "Was John George Bice's birthplace near Cornwall?", "answer": true, "facts": ["Politician John George Bice was born in Callington.", "Cornwall is a place located in South West England.", "Callington is a small town in South East Cornwall."], "decomposition": ["Where was John George Bice born?", "Is #1 located close to Cornwall?"], "evidence": [[[["John George Bice-2"]], ["operation"]], [[["John George Bice-2"]], [["John George Bice-2"]]], [[["John George Bice-2"]], [["Callington-1"]]], [[["John George Bice-2"]], [["John George Bice-2"]]]]}
{"id": 551, "term": "Maritime pilot", "description": "mariner who manoeuvres ships through dangerous or congested waters", "question": "Can COVID-19 spread to maritime pilots?", "answer": true, "facts": ["Maritime pilots are human beings.", "COVID-19 can spread among human population. "], "decomposition": ["Which organisms are susceptible to COVID-19?", "Are maritime pilots one of #1?"], "evidence": [[[["Coronavirus disease 2019-1"], "no_evidence"], ["operation"]], [[["Coronavirus disease 2019-1"]], [["Maritime pilot-1"], "operation"]], [[["Coronavirus disease 2019-83"], "no_evidence"], ["operation"]]]}
{"id": 757, "term": "Benito Mussolini", "description": "Fascist leader of Italy", "question": "Did Benito Mussolini wear bigger shoes than Hafþór Björnsson?", "answer": false, "facts": ["Benito Mussolini was 5' 6​1⁄2\" tall.", "Hafþór Björnsson is 6 feet 9 inches tall.", "Shoe size increases proportionally as height increases."], "decomposition": ["How tall was Benito Mussolini?", "How tall is Hafþór Björnsson?", "Is #2 smaller than #1?"], "evidence": [[[["Benito Mussolini-8"], "no_evidence"], [["Hafþór Júlíus Björnsson-5"]], ["operation"]], [[["Benito Mussolini-1"], "no_evidence"], [["Hafþór Júlíus Björnsson-19"]], ["no_evidence", "operation"]], [["no_evidence"], [["Hafþór Júlíus Björnsson-5"]], ["no_evidence", "operation"]]]}
{"id": 778, "term": "United Nations Conference on Trade and Development", "description": "organization", "question": "Could Edward Snowden have visited the headquarters of United Nations Conference on Trade and Development?", "answer": true, "facts": ["The headquarters of the United Nations Conference on Trade and Development is in Geneva, Switzerland.", "Edward Snowden was stationed in Geneva in 2007 with the task of representing the US at the UN."], "decomposition": ["What city and country is the United Nations Conference on Trade and Development located in?", "In 2007, what was Edward Snowden's tasked with?", "Was Edward Snowden stationed in #1 in 2007 to accomplish #2? "], "evidence": [[[["United Nations Conference on Trade and Development-7"]], [["Edward Snowden-13"]], ["operation"]], [[["Palace of Nations-1"]], [["Edward Snowden-13"]], ["operation"]], [[["United Nations Conference on Trade and Development-3"]], [["Edward Snowden-13"]], ["operation"]]]}
{"id": 653, "term": "Stanley Baldwin", "description": "Former Prime Minister of the United Kingdom", "question": "Was a woman Prime Minister directly before or after Stanley Baldwin?", "answer": false, "facts": ["Stanley Baldwin was preceded by Ramsay MacDonald as Prime Minister.", "Stanley Baldwin was succeeded as Prime Minister by Neville Chamberlain."], "decomposition": ["Who was the Prime Minister before Stanley Baldwin?", "Who was the Prime Minister after Stanley Baldwin?", "Was #1 a woman?", "Was #2 a woman?", "Is the answer to either #3 or #4 yes?"], "evidence": [[[["Ramsay MacDonald-1"]], [["Neville Chamberlain-1"]], ["operation"], ["operation"], ["operation"]], [[["Ramsay MacDonald-1", "Ramsay MacDonald-1", "Stanley Baldwin-5"]], [["Neville Chamberlain-3"]], [["Ramsay MacDonald-1"]], [["Neville Chamberlain-8"]], ["operation"]], [[["Stanley Baldwin-14"]], [["Sir Roger Conant, 1st Baronet-3"]], ["operation"], ["operation"], ["operation"]]]}
{"id": 754, "term": "Olive oil", "description": "liquid fat extracted by pressing olives", "question": "Can olive oil kill rabies?", "answer": false, "facts": ["Olive oil is a fat used in cooking.", "Olive oil is made up of palmitic acid which is a weak acid found in plants and animals.", "Rabies is a disease from an infected animal bite.", "Rabies is treated by a shot containing immunoglobuin, a protein that is found in plasma cells.", "Plasma cells are found in the bone marrow of humans."], "decomposition": ["What is used to treat rabies?", "What is olive oil made of?", "Are any of #2 present in #1?"], "evidence": [[[["Rabies-31"]], [["Olive oil-1"]], ["operation"]], [[["Rabies-30", "Rabies-33"]], [["Olive oil-1"]], ["operation"]], [[["Rabies-30"]], [["Olive oil-3"]], ["operation"]]]}
{"id": 5, "term": "Alan Greenspan", "description": "13th Chairman of the Federal Reserve in the United States", "question": "Do Squidward Tentacles and Alan Greenspan have different musical passions?", "answer": false, "facts": ["Squidward Tentacles plays the clarinet.", "Alan Greenspan played clarinet and saxophone along with Stan Getz.", "Alan Greenspan studied clarinet at the Juilliard School from 1943 to 1944."], "decomposition": ["What musical instruments does Squidward Tentacles play?", "What musical instruments does Alan Greenspan play?", "Is at least one instrument in #1 also found in #2?"], "evidence": [[[["Squidward Tentacles-5"]], [["Alan Greenspan-5"]], ["operation"]], [[["Squidward Tentacles-5"]], [["Alan Greenspan-5"]], ["operation"]], [[["Squidward Tentacles-5"]], [["Alan Greenspan-5"]], ["operation"]]]}
{"id": 805, "term": "Toyota Hilux", "description": "Series of light commercial vehicles produced by the Japanese car-manufacturer Toyota.", "question": "Can a 2019 Toyota Hilux hypothetically support weight of thirty Big John Studd clones?", "answer": false, "facts": ["The 2019 Toyota Hilux has a maximum carry load of 3500kg or, around 7,700 pounds.", "Big John Studd was a professional wrestler that weighed 364 pounds."], "decomposition": ["What is the maximum carry load weight of a Toyota Hilux?", "How much did Big John Studd weigh?", "What is #2 multiplied by 30?", "Is #1 greater than or equal to #3?"], "evidence": [[["no_evidence"], ["no_evidence"], ["no_evidence", "operation"], ["no_evidence", "operation"]], [[["Toyota Hilux-1"], "no_evidence"], [["Big John Studd-14"], "no_evidence"], ["operation"], ["operation"]], [[["Toyota Hilux-1"], "no_evidence"], [["Big John Studd-1", "NWA Mid-Atlantic Heavyweight Championship-4"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 507, "term": "New York Public Library", "description": "Public library system in New York City", "question": "Does the New York Public Library sell Alpo products?", "answer": false, "facts": ["The New York Public Library is a public lending library system in New York City", "Alpo produces pet food and related products"], "decomposition": ["What does The New York Public Library offer for customers?", "What kinds of products does Alpo make?", "Is there any overlap between #1 and #2?"], "evidence": [[[["New York Public Library-30", "New York Public Library-31"]], [["Alpo (pet food)-1"]], ["operation"]], [[["New York Public Library-3"]], [["Alpo (pet food)-1"]], ["operation"]], [[["New York Public Library-19", "New York Public Library-28"]], [["Alpo (pet food)-1"]], ["operation"]]]}
{"id": 473, "term": "New Year's Eve", "description": "holiday celebrated on 31 December", "question": "Should you ask a neighbor for candy on New Year's Eve?", "answer": false, "facts": ["Halloween is a holiday where children knock on doors of houses in their neighborhood asking for treats", "Halloween falls on October 31st", "New Year's Eve is a celebration of the end of the year held on December 31st"], "decomposition": ["On which holiday do children go trick-or-treating?", "What is the date of #1?", "When is New Year's Eve celebration?", "Are #2 and #3 the same?"], "evidence": [[[["Halloween-3"]], [["Halloween-1"]], [["New Year's Eve-1"]], ["operation"]], [[["Trick-or-treating-1"]], [["Halloween-11"]], [["New Year's Eve-36"]], ["operation"]], [[["Trick-or-treating-1"]], [["Halloween-1"]], [["New Year's Eve-1"]], ["operation"]]]}
{"id": 499, "term": "Poseidon", "description": "Ancient Greek god of the sea, earthquakes and horses", "question": "Is Poseidon similar to the god Vulcan?", "answer": false, "facts": ["Poseidon is the Greek god of the sea and water, and is the brother of Zeus.", "Neptune is the Roman god of the sea.", "Hephaestus is the Greek god of fire.", "Hephaestus's ROman equivalent is Vulcan, the Roman god of fire."], "decomposition": ["What are the major characteristics of Poseidon?", "What are the major characteristics of Vulcan?", "Is there a significant overlap between #1 and #2?"], "evidence": [[[["Poseidon-43"]], [["Vulcan (mythology)-44"]], ["operation"]], [[["Poseidon-1"]], [["Vulcan (mythology)-1"]], ["operation"]], [[["Greek sea gods-6"]], [["Vulcan (mythology)-1"]], ["operation"]]]}
{"id": 663, "term": "Cerebral palsy", "description": "A group of disorders affecting the development of movement and posture, often accompanied by disturbances of sensation, perception, cognition, and behavior. It results from damage to the fetal or infant brain.", "question": "Could a young Wizard of Oz Scarecrow have gotten Cerebral palsy?", "answer": false, "facts": ["Cerebral palsy is a disease that results from damage to a young person's brain.", "The Scarecrow in the Wizard of Oz did not have a brain and was on a quest to get one."], "decomposition": ["Which organ of the body can cerebral palsy be traced back to?", "Did the Scarecrow in Wizard of Oz initially have #1 ?"], "evidence": [[[["Cerebral palsy-5"]], [["Scarecrow (Oz)-3"], "operation"]], [[["Cerebral palsy-2"]], [["Scarecrow (Oz)-1"], "operation"]], [[["Cerebral palsy-2"]], [["The Wizard of Oz (1939 film)-6"]]]]}
{"id": 390, "term": "Sirius", "description": "Brightest star in the night sky", "question": "Is Sirius part of a constellation of an animal?", "answer": true, "facts": ["Sirius is the brightest star in the constellation Canis Major.", "Canis Major represents a large dog."], "decomposition": ["What constellation is Sirius a part of?", "What does #1 represent?", "Is #2 an animal?"], "evidence": [[[["Canis Major-2"]], [["Canis Major-1"]], ["operation"]], [[["Sirius-4"]], [["Canis Major-1"]], ["operation"]], [[["Sirius-4"]], [["Canis Major-4"]], [["Animal-4"]]]]}
{"id": 44, "term": "Koala", "description": "An arboreal herbivorous marsupial native to Australia.", "question": "Do Koalas prefer Eucalyptus over meat?", "answer": true, "facts": ["Koalas are herbivores.", "Koalas main dietary staple is eucalyptus "], "decomposition": ["What kind of diet do Koalas follow?", "Are Eucalyptus part of #1?"], "evidence": [[[["Koala-2"]], ["operation"]], [[["Koala-2"]], [["Eucalypt-5", "Koala-2"]]], [[["Koala-2"]], ["operation"]]]}
{"id": 978, "term": "Old English", "description": "Early form of English; Anglo-Saxon", "question": "Did the confederate states speak Old English before the Civil War?", "answer": false, "facts": ["Old English is the earliest form of English during the middle ages.", "Modern English replaced old English during the seventeenth century.", "American English was created and spoken during the formation of the first US colonies. ", "The civil war started in 1861, and was a war between the northern states and southern states. "], "decomposition": ["In approximately which years was Old English spoken?", "In which years did the Confederate States exist? ", "Was any part of #2 within #1?"], "evidence": [[[["Old English-1"]], [["Confederate States of America-1"]], ["operation"]], [[["Old English-6"]], [["Confederate States of America-9"]], ["operation"]], [[["Old English-1"]], [["Confederate States of America-1"]], ["operation"]]]}
{"id": 474, "term": "Eye surgery", "description": "medical specialty", "question": "Would Eye surgery on a fly be in vain?", "answer": true, "facts": ["Researchers at BYU have been developing smaller surgical instruments to improve medical procedures.", "BYU researchers  created robotically-controlled forceps that can pass through a hole about 3 millimeters in size.", "The eye of a fly is considerably small and estimates range from .5mm to 2mm."], "decomposition": ["What levels of precision can be reached by robot-assisted surgery?", "What is the size range of the eye of a fly?", "Is #1 considerably larger than the range of #2?"], "evidence": [[[["Robot-assisted surgery-21"], "no_evidence"], [["Fly-9"], "no_evidence"], ["operation"]], [[["Robot-assisted surgery-28"], "no_evidence"], [["Fly-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Robot-assisted surgery-2"], "no_evidence"], [["Fly-14"], "no_evidence"], ["operation"]]]}
{"id": 520, "term": "Butler", "description": "male domestic worker in charge of all the male household staff", "question": "Do most middle class families have butlers?", "answer": false, "facts": ["Butlers make about $60,000 per year on average for their work.", "Middle class income is between $48,000 and $145,000."], "decomposition": ["What is a butler?", "How much does #1 make per year on average?", "How much is the average middle class income?", "Would #3 be enough to pay #2?"], "evidence": [[[["Butler-1"]], ["no_evidence"], [["Middle class-34"]], ["operation"]], [[["Butler-1"]], [["Butler-15"], "no_evidence"], [["Middle class-24"], "no_evidence"], ["operation"]], [[["Butler-1"]], [["Butler-20"], "no_evidence"], [["Middle class-37"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 911, "term": "Sloth", "description": "tree dwelling animal noted for slowness", "question": "Do moths that live on sloths have family dinners?", "answer": false, "facts": ["Algae grows on sloths", "Sloth moths feed on algae that grows on sloths", "Sloth moth caterpillars feed on sloth dung ", "Sloths defecate far from their ususl abode"], "decomposition": ["What do sloth moths enjoy eating from the body of sloths?", "Where is #1 found on the sloth?", "What do baby or caterpillar sloth moths enjoy eating from the body of sloths?", "Where is #3 found relative to the sloth?", "Is #2 found in the same location as #4?"], "evidence": [[[["Sloth moth-2"], "no_evidence"], [["Sloth moth-3"], "no_evidence"], ["no_evidence"], ["no_evidence"], ["operation"]], [[["Sloth moth-4"]], [["Sloth moth-1"]], [["Sloth moth-2"]], [["Arthropods associated with sloths-12"]], ["operation"]], [[["Sloth moth-1", "Sloth moth-4"]], [["Sloth-2"]], [["Sloth moth-2"], "no_evidence"], ["no_evidence", "operation"], ["operation"]]]}
{"id": 404, "term": "CNES", "description": "French space agency", "question": "Has CNES planted a French flag on the lunar surface?", "answer": false, "facts": ["The lunar surface is on the moon.", "CNES has not sent a person to the moon."], "decomposition": ["Where is the lunar surface?", "What country is the CNES part of?", "Which countries have sent people or probes to #1?", "Is #2 included in #3?"], "evidence": [[[["Geology of the Moon-1"]], [["CNES-1"]], [["Space Race-2"]], ["operation"]], [[["Moon-3"]], [["CNES-1"]], [["Chinese Lunar Exploration Program-3", "Exploration of the Moon-11"]], ["operation"]], [[["Moon-3"]], [["CNES-1"]], ["no_evidence"], ["operation"]]]}
{"id": 804, "term": "PlayStation 4", "description": "Sony's eighth-generation home video game console", "question": "Did Tom Bosley enjoy video games on the PlayStation 4?", "answer": false, "facts": ["The PlayStation 4 was launched in 2013.", "Tom Bosley died in 2010."], "decomposition": ["What year did Tom Bosley die?", "What year was the PlayStation 4 Launched?", "Is #2 before #1?"], "evidence": [[[["Tom Bosley-13"]], [["PlayStation 4-1"]], ["operation"]], [[["Tom Bosley-13"]], [["PlayStation 4-1"]], ["operation"]], [[["Tom Bosley-1"]], [["PlayStation 4-1"]], ["operation"]]]}
{"id": 356, "term": "University of Pittsburgh", "description": "American state-related research university located in Pittsburgh, Pennsylvania", "question": "Did University of Pittsburgh founder have great deal in common with Judith Sheindlin?", "answer": true, "facts": ["Hugh Henry Brackenridge founded University of Pittsburgh in 1787.", "Judith Sheindlin is a judge, lawyer, and author.", "Hugh Henry Brackenridge was a writer, lawyer, judge, and Justice of the Supreme Court of Pennsylvania."], "decomposition": ["Who was the founder of University of Pittsburgh?", "What are the major things #1 is known for?", "What are the major things Judith Sheindlin is known for?", "Is there an overlap between #2 and #3?"], "evidence": [[[["History of the University of Pittsburgh-2"]], [["Hugh Henry Brackenridge-4"]], [["Judy Sheindlin-1"]], [["Judge-5"], "operation"]], [[["University of Pittsburgh-1"]], [["Hugh Henry Brackenridge-1"]], [["Judy Sheindlin-1"]], ["operation"]], [[["History of the University of Pittsburgh-2"]], [["Hugh Henry Brackenridge-1"]], [["Judy Sheindlin-1"]], ["operation"]]]}
{"id": 601, "term": "Freemasonry", "description": "group of fraternal organizations", "question": "Has Freemasonry been represented on the Moon?", "answer": true, "facts": ["Freemasonry is a group of fraternal organizations rooted in fraternities of stonemasons of the fourteenth century.", "Buzz Aldrin was initiated into the Freemason fraternity in 1955", "Buzz Aldrin and Neil Armstrong were the first men to land on the moon in 1969."], "decomposition": ["What occupation goes into space?", "Have any #1 been Free Masons?", "Have any people listed in #2 been to the moon?"], "evidence": [[[["Astronaut-1"]], [["James Irwin-1", "James Irwin-23"]], [["James Irwin-1"]]], [[["Astronaut-1"]], [["Buzz Aldrin-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Astronaut-1"]], [["John Glenn-62"]], [["John Glenn-3"], "operation"]]]}
{"id": 425, "term": "Grief", "description": "reaction to loss of someone or something close or important", "question": "Is grief always obvious when it is being experienced?", "answer": false, "facts": ["Grief has no set external representation. ", "People who are grieving may laugh, cry, or even seem angry."], "decomposition": ["What are the ways a person may express their grief?", "Based on #1, can one always tell when someone is grieving?"], "evidence": [[[["Grief-10"]], [["Grief-10"]]], [[["Grief-1"], "no_evidence"], [["Grief-59"], "no_evidence", "operation"]], [["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 516, "term": "Underworld", "description": "The mythic Relm of the Dead, located far underground (aka, Hades; Underworld)", "question": "Can you get a ride on Amtrak to the Underworld?", "answer": false, "facts": ["Amtrak is a passenger railroad service operating in North America", "The Underworld is a fictional location from mythology and religion"], "decomposition": ["Which major regions are covered by the passenger railroad service 'Amtrak'?", "Is the Underworld part of #1?"], "evidence": [[[["Amtrak-1"]], [["Underworld-1"], "operation"]], [[["Amtrak-1"]], [["Underworld-1"]]], [[["Amtrak-1"]], [["Underworld-1"], "operation"]]]}
{"id": 715, "term": "King Kong (2005 film)", "description": "2005 film directed by Peter Jackson", "question": "Was King Kong (2005 film) solvent?", "answer": true, "facts": ["Solvent refers to the assets of a project being greater than the liabilities.", "The assets of a movie film are the box office receipts, and the liabilities is the budget.", "King Kong (2005) had box office receipts of 562 million.", "King Kong (2005) had a budget of 207 million."], "decomposition": ["What does it mean to be solvent in business/finance?", "What was the budget (liabilities) of the 2005 movie King Kong?", "How much did 2005 movie King Kong gross (assets) worldwide?", "Does #3 compare favorably with #2 as defined in #1?"], "evidence": [[[["Solvency-1"]], [["King Kong (2005 film)-2"]], [["King Kong (2005 film)-2"]], ["operation"]], [[["Solvency-1"]], [["King Kong (2005 film)-2"]], [["King Kong (2005 film)-2"]], ["operation"]], [[["Solvency-1"]], [["King Kong (2005 film)-2"]], [["King Kong (2005 film)-2"]], ["operation"]]]}
{"id": 650, "term": "Astrology", "description": "Pseudoscience claiming celestial objects influence human affairs", "question": "Does Capricorn astrology symbol have all of the parts of a chimera?", "answer": false, "facts": ["The Capricorn astrology symbol is a sea goat which consists of: a goat, and a fish.", "A chimera is a legendary beast that is made up of: a lion, a goat, and a snake."], "decomposition": ["What are the parts of the capricorn symbol?", "What is the chimera made up of?", "Does #1 include all of #2?"], "evidence": [[[["Capricorn (astrology)-1"]], [["Chimera (mythology)-1"]], ["operation"]], [[["Capricorn (astrology)-2"]], [["Chimera (mythology)-1"]], ["operation"]], [[["Capricorn (astrology)-2"]], [["Chimera (mythology)-3"]], ["operation"]]]}
{"id": 503, "term": "Bucharest", "description": "Capital of Romania", "question": "Could a wandering albatross fly from Bucharest to New York City without a rest?", "answer": true, "facts": ["Wandering albatross can travel at least 15,000 km (just under 10,000 miles) over the sea before returning to land. ", "It's 4766 miles or 7670 km from Bucharest to New York City."], "decomposition": ["How far can a Wandering albatross travel over the sea before returning to land?", "How far is it from Bucharest to New York City", "Is #2 less than #1?"], "evidence": [[[["Wandering albatross-4"], "no_evidence"], ["no_evidence"], ["operation"]], [[["Wandering albatross-8"], "no_evidence"], [["Bucharest-1", "New York City-1"], "no_evidence", "operation"], ["no_evidence", "operation"]], [[["Wandering albatross-5"]], ["no_evidence"], ["operation"]]]}
{"id": 779, "term": "Sony", "description": "Japanese multinational conglomerate corporation", "question": "Did Sony definitively win the video game war against Sega?", "answer": true, "facts": ["Sony is the maker of the Playstation which has sold over 108 million PS4 units by March 2020.", "Sega's last console, the Sega Dreamcast, was discontinued in 2001.", "Sony Playstation competed with Sega's Dreamcast and Saturn systems in the 1990s.", "Sega now makes games for its former competitor, Sony, including Team Sonic Racing in 2019.", "At the height of the console wars, Sega Saturn sold 9.5 million units while Sony Playstation sold 102 million units."], "decomposition": ["How many console did Sega Saturn sell?", "How many console did Sony Playstation?", "Is #2 greater than #1?"], "evidence": [[[["Sega Saturn-25"], "no_evidence"], [["PlayStation-2"]], ["operation"]], [[["Sega Saturn-3"]], [["PlayStation-81"]], [["PlayStation-81"]]], [[["Sega Saturn-3"]], [["PlayStation (console)-2"]], ["operation"]]]}
{"id": 885, "term": "Lionel Richie", "description": "American singer-songwriter, musician, record producer and actor", "question": "Does  Lionel Richie believe in holistic medicine?", "answer": true, "facts": ["Lionel Richie suffered prolonged throat problems and had surgery four times in four years before being told by conventional doctors that he could lose his singing career. ", "Lionel Richie finally turned to a holistic doctor who said that the problem was simply acid reflux caused by foods he was eating before going to bed."], "decomposition": ["Which doctor diagnosed Lionel Richie satisfactorily after he had surgeries for a prolonged throat problem?", "Is #1 a holistic doctor?"], "evidence": [[["no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], ["operation"]], [["no_evidence"], ["operation"]]]}
{"id": 727, "term": "Football War", "description": "1969 War between Honduras and El Salvador", "question": "Did the Football War last at least a month?", "answer": false, "facts": ["The Football War began on July 14 1969.", "It ended on July 20 1969.", "Therefore, it did not even last a whole week."], "decomposition": ["How long did the Football War last?", "Is #1 greater than or equal to a month?"], "evidence": [[[["Football War-1"]], ["operation"]], [[["Football War-1"]], ["operation"]], [[["Football War-1"]], ["operation"]]]}
{"id": 302, "term": "Carl Friedrich Gauss", "description": "German mathematician and physicist", "question": "Could Carl Friedrich Gauss speak to someone 100 miles away?", "answer": false, "facts": ["Carl Friedrich Gauss was born in 1777.", "Speaking to someone 100 miles away requires a telephone.", "The telephone was invented in 1876."], "decomposition": ["What device allows people to speak to each other even if they are 100 miles apart?", "When was #1 invented?", "When did Carl Friedrich Gauss die?", "Is #2 before #3?"], "evidence": [[[["Telephone-1"]], [["Telephone-19"]], [["Carl Friedrich Gauss-13"]], ["operation"]], [[["Telephone-1"]], [["Telephone-22"]], [["Carl Friedrich Gauss-13"]], ["operation"]], [[["Telephone-1"]], [["Alexander Graham Bell-31"]], [["Carl Friedrich Gauss-1"]], ["operation"]]]}
{"id": 849, "term": "Dr. Seuss", "description": "American children's writer and illustrator", "question": "Did Dr. Seuss make himself famous?", "answer": false, "facts": ["Dr. Seuss's wife was Helen Palmer.", "Helen Palmer suggested that Dr. Seuss become an artist rather than a professor.", "Helen Palmer inspired much of Dr. Seuss's work."], "decomposition": ["Who was Dr. Seuss' wife?", "Did #1 not serve as inspiration and give key suggestions to Dr. Seuss?"], "evidence": [[[["Dr. Seuss-7"]], [["Dr. Seuss-7"], "no_evidence", "operation"]], [[["Helen Palmer (author)-1"]], [["Helen Palmer (author)-5"]]], [[["Helen Palmer (author)-1"]], [["Helen Palmer (author)-3"], "operation"]]]}
{"id": 639, "term": "Honey bee", "description": "Eusocial flying insect of genus Apis, producing surplus honey", "question": "Can a honey bee sting a human more than once?", "answer": false, "facts": ["Human skin is tough, and the bee's stinger gets lodged in the skin.", "The stinger becomes separated from the bee which dies soon after."], "decomposition": ["What happens to a bee's stinger when it stings a human?", "Are bees able to survive if #1 happens?"], "evidence": [[[["Bee sting-6"], "no_evidence"], ["no_evidence", "operation"]], [[["Stinger-7"]], [["Stinger-7"]]], [[["Honey bee-61"]], ["operation"]]]}
{"id": 788, "term": "Bohai Sea", "description": "The innermost gulf of the Yellow Sea and Korea Bay on the coast of Northeastern and North China", "question": "Could Rhode Island sink into the Bohai Sea?", "answer": true, "facts": ["The Bohai Sea is 30,000 square miles", "Rhode Island is 1,214 square miles"], "decomposition": ["How many square miles is the Bohai Sea?", "How many square miles is Rhode Island?", "Is #1 greater than or equal to #2?"], "evidence": [[[["Bohai Sea-1"]], [["Rhode Island-29"]], [["Rhode Island-29"], "operation"]], [[["Bohai Sea-1"]], [["Rhode Island-29"]], ["operation"]], [[["Bohai Sea-1"]], [["Rhode Island-29"]], ["operation"]]]}
{"id": 371, "term": "Holy Land", "description": "Term used by Jews, Christians, and Muslims to describe the Land of Israel and Palestine", "question": "Did Holy Land belong to Adamu's tribe?", "answer": true, "facts": ["The Holy Land is a place that Jews, Muslims, and Christians revere.", "Adamu was an early king of Assyria.", "The Assyrians were in regions of the Holy Land as far back as 2600 BC.", "The predecessors to the Assyrians were in regions of the Holy Land as far back as 3500 BC."], "decomposition": ["Which place is referred to as the Holy Land?", "Which tribe was Adamu a leader of?", "Did #2 occupy #1?"], "evidence": [[[["Holy Land-1"]], [["Adamu (Assyrian king)-1"]], [["Adamu (Assyrian king)-4", "Assyria-1", "Mesopotamia-1"]]], [[["Holy Land-1"]], [["Adamu (Assyrian king)-1", "Assyrian people-1", "Assyrian people-2", "Assyrian people-51"]], ["no_evidence", "operation"]], [[["Holy place-8"], "operation"], [["Adamu Adamu-2"], "no_evidence"], ["no_evidence"]]]}
{"id": 702, "term": "Portuguese people", "description": "ethnic group", "question": "Did King of Portuguese people in 1515 have familial ties to the Tudors?", "answer": true, "facts": ["Manuel I was King of Portugal from 1495 to 1521.", "Manuel I of Portugal married Maria of Aragon.", "Maria of Aragon was the sister of Catherine of Aragon.", "Catherine of Aragon was the first wife of Henry VIII and was one of a handful that he did not behead."], "decomposition": ["Who was the King of Portugal in 1515?", "Who were in #1's immediate family?", "Were any of #2 related to the Tudors?"], "evidence": [[[["Manuel I of Portugal-1"]], [["Manuel I of Portugal-5"], "no_evidence"], ["no_evidence", "operation"]], [[["Manuel I of Portugal-1"]], [["Isabella of Portugal-4"]], [["Mary I of England-1", "Philip II of Spain-1", "Philip II of Spain-2"], "operation"]], [[["Manuel I of Portugal-1"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 596, "term": "Crucifixion", "description": "Method of capital punishment in which the victim is tied or nailed to a large wooden beam and left to hang until eventual death", "question": "If it socially acceptable to wear an icon depicting crucifixion? ", "answer": true, "facts": ["The crucifixion of Jesus is a common sign used by Catholics and Christian denominations. ", "Many jewelry stores offer necklaces with the Crucifixion of Jesus Christ."], "decomposition": ["Which common symbol is used by Catholics to depict crucifixion?", "Is #1 commonly found in jewelry stores?"], "evidence": [[[["Christian symbolism-6"], "no_evidence"], [["Christian cross variants-3"], "operation"]], [[["Crucifix-2"]], [["Crucifix-12"], "no_evidence", "operation"]], [[["Crucifixion-2"]], ["no_evidence"]]]}
{"id": 139, "term": "Zebra", "description": "Black and white striped animals in the horse family", "question": "Are black and white prison uniforms made to resemble a zebra?", "answer": false, "facts": ["Prison stripes are made of parallel lines.", "Zebra stripes are jagged in appearance. "], "decomposition": ["What is the design on a prison uniform?", "What is the pattern on a zebra?", "Is #1 the same as #2?"], "evidence": [[[["Prison uniform-28"], "no_evidence"], [["Plains zebra-13"]], ["operation"]], [[["Prison uniform-2"], "no_evidence"], [["Zebra-2"]], ["no_evidence", "operation"]], [[["Prison uniform-24", "Prison uniform-26"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 179, "term": "Butter", "description": "dairy product", "question": "Would toast for a vegan have margarine instead of butter?", "answer": true, "facts": ["Margarine is typically made without the use of dairy ingredients.", "Vegans do not eat any animal products, including dairy and eggs."], "decomposition": ["Which products are avoided in vegan diet?", "Is margarine free of #1?"], "evidence": [[[["Veganism-1"]], [["Margarine-36"]]], [[["Veganism-1"]], [["Margarine-2"], "operation"]], [[["Veganism-1"]], [["Margarine-2"]]]]}
{"id": 190, "term": "Snickers", "description": "brand name chocolate bar made by Mars, Incorporated", "question": "Is Snickers helpful for weight loss?", "answer": false, "facts": ["Weight loss is best achieved through watching the calories and sugar in the food you eat.", "Snickers is high in fat, sugar, and calories, while being low in nutritional value."], "decomposition": ["What must you avoid to best achieve weight loss?", "Are snickers avoid of those #1?"], "evidence": [[[["Dieting-1"]], [["Snickers-8"], "operation"]], [[["Dieting-1"]], [["Snickers-1", "Snickers-11"], "no_evidence", "operation"]], [[["Weight loss-12"]], [["Snickers-10"], "operation"]]]}
{"id": 170, "term": "Alice in Wonderland (1951 film)", "description": "1951 American animated musical fantasy film produced by Walt Disney Productions", "question": "Was milliner in Alice in Wonderland (1951 film) likely in need of succimer?", "answer": true, "facts": ["A milliner is someone who makes hats.", "The character of the Mad Hatter was a milliner in the 1951 Alice in Wonderland film.", "The phrase, Mad as a Hatter, comes from the fact that hat makers used mercury to line their hats and often suffered mercury poisoning.", "Succimer is a chemical that is used to treat lead, mercury, and arsenic poisoning."], "decomposition": ["What does a milliner do?", "Which Alice in Wonderland (1951 film) character did #1?", "Which element did #2 use for work that could be harmful to their mental health?", "Is succimer useful for treatment of the effects of #3?"], "evidence": [[[["Hatmaking-1"]], [["Alice in Wonderland (1951 film)-7"]], [["Erethism-1"]], [["Dimercaptosuccinic acid-1"], "operation"]], [[["Hatmaking-1"]], [["Hatter (Alice's Adventures in Wonderland)-1"]], [["Hatter (Alice's Adventures in Wonderland)-5"]], [["Dimercaptosuccinic acid-1"]]], [[["Hatmaking-1"]], [["Hatter (Alice's Adventures in Wonderland)-1"]], [["Hatter (Alice's Adventures in Wonderland)-5"]], [["Dimercaptosuccinic acid-1"]]]]}
{"id": 933, "term": "Smooth jazz", "description": "category of music", "question": "Are you likely to hear Rammstein playing in smooth jazz clubs?", "answer": false, "facts": ["Smooth jazz is a combination of jazz with easy-listening pop music and lightweight R&B.", "Smooth jazz began in the United States in the 1970s.", "Rammstein is a German band that plays heavy metal music."], "decomposition": ["What kinds of music is played at a smooth jazz club?", "What kinds of music does Rammstein play?", "Is there an overlap between #1 and #2?"], "evidence": [[[["Jazz club-2"]], [["Rammstein-55"]], ["operation"]], [[["Smooth jazz-2"]], [["Rammstein-45"]], ["operation"]], [[["Jazz club-2"], "operation"], ["no_evidence"], ["no_evidence"]]]}
{"id": 508, "term": "Spider wasp", "description": "family of insects", "question": "Do spider wasps have eight legs?", "answer": false, "facts": ["A spider wasp is a kind of wasp, which is an insect.", "Insects all have six legs."], "decomposition": ["What kind of animal is a spider wasp?", "Do #1's have eight legs?"], "evidence": [[[["Spider wasp-1"]], [["Spider wasp-5"]]], [[["Spider wasp-1", "Wasp-1"]], [["Insect-1"], "operation"]], [[["Spider wasp-1"]], ["no_evidence"]]]}
{"id": 588, "term": "Halloween", "description": "Holiday celebrated October 31", "question": "Will Chick Fil A be open on Halloween 2021?", "answer": false, "facts": ["Chick Fil A restaurants close on Sundays.", "Halloween 2021 falls on a Sunday."], "decomposition": ["What day of the week does Halloween fall on in 2021?", "What days of the week is Chick Fil A closed?", "Is #1 included in #2?"], "evidence": [[["no_evidence"], [["Chick-fil-A-18"]], ["no_evidence", "operation"]], [["no_evidence"], [["Chick-fil-A-2"]], ["operation"]], [["no_evidence"], [["Chick-fil-A-2"]], ["operation"]]]}
{"id": 524, "term": "Tax collector", "description": "person who collects taxes", "question": "Does Kenny G hold the qualifications to be a tax collector?", "answer": true, "facts": ["The qualifications to be a tax collector in the US inlude a bachelor's degree in accounting.", "Kenny G studied accounting at the University of Washington and graduated magna cum laude."], "decomposition": ["What are the qualifications to be a tax collector?", "Does Kenny G possess #1?"], "evidence": [[["no_evidence"], ["no_evidence"]], [[["Certified Public Accountant-16"], "no_evidence"], [["Kenny G-5"], "operation"]], [[["Audit-1", "Tax collector-1"], "no_evidence"], [["Kenny G-5"], "operation"]]]}
{"id": 481, "term": "Mini", "description": "British car model made by the British Motor Corporation (BMC) and its successors from 1959 until 2000", "question": "Was the British car, the Mini, the first car manufactured?", "answer": false, "facts": ["The first car widely manufactured was the Model T.", "The Model T was manufactured in 1908.", "The Mini was made beginning in 1959."], "decomposition": ["When was the first car manufactured?", "When was the Mini first manufactured?", "Is #2 the same as #1?"], "evidence": [[[["Nicolas-Joseph Cugnot-3"]], [["Mini-1"]], ["operation"]], [[["Car-24"]], [["Mini-1"]], ["operation"]], [[["Car-2"]], [["Mini-1"]], ["operation"]]]}
{"id": 197, "term": "Düsseldorf", "description": "Place in North Rhine-Westphalia, Germany", "question": "Can you see Stonehenge from a window in Dusseldorf?", "answer": false, "facts": ["Dusseldorf is a city in Germany.", "Stonehenge is a prehistoric monument in Wiltshire, England.", "Wiltshire England is around seven hours away from Dusseldorf Germany by car."], "decomposition": ["Where is Stonehenge located?", "Where is Düsseldorf located?", "Is #1 geographically close to #2?"], "evidence": [[[["Stonehenge-1"]], [["Düsseldorf-1"]], ["no_evidence"]], [[["Stonehenge-69"], "operation"], [["Düsseldorf-36"], "operation"], ["no_evidence"]], [[["Stonehenge-1"]], [["Düsseldorf-1"]], ["operation"]]]}
{"id": 759, "term": "Sudoku", "description": "Logic-based number-placement puzzle", "question": "Could an infant solve a sudoku puzzle?", "answer": false, "facts": ["Solving a sudoku puzzle requires the use of logic and a basic understanding of numbers.", "Infants are too young to understand the numerical system involved in sudoku."], "decomposition": ["What is the skill set of an infant?", "What skills are required for sudoku?", "Is #2 included in #1?"], "evidence": [[[["Infant-2"], "no_evidence"], [["Sudoku-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Sudoku-11"]], [["Logic puzzle-1"]], [["Sudoku-1"]]], [[["Infant cognitive development-12"]], [["Sudoku code-6"]], [["Infant cognitive development-12", "Sudoku code-6"], "operation"]]]}
{"id": 236, "term": "Jack Black", "description": "American actor, comedian, musician, music producer and youtuber.", "question": "Is Jack Black's height enough to satisfy Coronavirus distancing?", "answer": false, "facts": ["Jack Black is 5'6\" tall.", "The CDC recommends people stay 6 feet apart."], "decomposition": ["How tall is Jack Black?", "What is the minimum recommended length for social distancing?", "Is #1 at least #2?"], "evidence": [[["no_evidence"], [["Social distancing-9"]], ["operation"]], [["no_evidence"], [["Social distancing-9"]], ["no_evidence", "operation"]], [[["Jack Black-1"], "no_evidence"], [["Social distancing-9"]], ["no_evidence", "operation"]]]}
{"id": 979, "term": "Ivan the Terrible", "description": "Grand Prince of Moscow and 1st Tsar of Russia", "question": "Did Ivan the Terrible's father and grandfather have nicer nicknames?", "answer": true, "facts": ["Ivan the Terrible was nicknamed terrible because of his harsh rule.", "Ivan the Terrible's father, Vasili III Ivanovich, was nicknamed Vasili the Adequate.", "Ivan the Terrible's grandfather, Ivan III Vasilyevich, was nicknamed Ivan the Great."], "decomposition": ["Who was Ivan the Terrible's father?", "Who was the father of #1?", "Do #1 and #2 have nicer nicknames than \"the Terrible\"?"], "evidence": [[[["Vasili III of Russia-1"]], [["Ivan III of Russia-1", "Vasili III of Russia-1"]], ["operation"]], [[["Vasili III of Russia-1"]], [["Vasili III of Russia-1"]], [["Vasili III of Russia-1"], "operation"]], [[["Vasili III of Russia-1"]], [["Ivan III of Russia-1"]], ["operation"]]]}
{"id": 122, "term": "Monarch", "description": "Person at the head of a monarchy", "question": "Does Canada have a relationship with a monarch?", "answer": true, "facts": ["Canada is a constitutional monarchy.", "The head of the monarchy that rules Canada is Queen Elizabeth."], "decomposition": ["What system of government does Canada follow?", "Who is the head of #1?", "Is #2 a monarch?"], "evidence": [[[["Government of Canada-6"]], ["no_evidence"], [["Records of heads of state-7"]]], [[["By the Grace of God-10", "Constitutional monarchy-1"], "no_evidence"], [["Monarchy-1"]], ["operation"]], [[["Government of Canada-1"]], [["Government of Canada-1"]], [["Government of Canada-1"]]]]}
{"id": 280, "term": "Bern", "description": "Place in Switzerland", "question": "Are Citizens of Bern Switzerland are descendants of Genghis Khan?", "answer": true, "facts": ["Genghis Khan had sixteen children.", "1 in 200 men are direct descendants of Genghis Khan.", "Switzerland has a large Asian immigration population which was around 19,000 in 2018."], "decomposition": ["What ethnic groups contain much of Genghis Khan's descendants?", "Is there a large population of any of #1 in Bern?"], "evidence": [[[["Descent from Genghis Khan-2"], "no_evidence"], [["Bern-39"], "no_evidence"]], [[["Descent from Genghis Khan-2", "Descent from Genghis Khan-22"]], ["no_evidence"]], [[["Genghis Khan-2"], "no_evidence"], [["Bern-39"], "no_evidence", "operation"]]]}
{"id": 638, "term": "Justin Bieber", "description": "Canadian singer-songwriter and actor", "question": "Did U.S. soldiers listen to Justin Bieber's Believe album during the Battle of Baghdad?", "answer": false, "facts": ["The Battle of Baghdad was the U.S. invasion of Baghdad in the year 2003.", "Justin Bieber's album Believe was released in 2012."], "decomposition": ["When did the Battle of Baghdad take place?", "When was the Justin Bieber album Believe released?", "Is #2 before #1?"], "evidence": [[[["Battle of Baghdad (2003)-1"]], [["Believe (Justin Bieber album)-1"]], ["operation"]], [[["Battle of Baghdad (2003)-1"]], [["Believe (Justin Bieber album)-1"]], ["operation"]], [[["Battle of Baghdad (2003)-1"]], [["Believe (Justin Bieber album)-1"]], ["operation"]]]}
{"id": 360, "term": "Great Depression", "description": "20th-century worldwide economic depression", "question": "Can the Great Depression be treated with Prozac?", "answer": false, "facts": ["Prozac is a pharmaceutical antidepressant for treatment of psychological disorders", "The Great Depression was an economic phenomenon occurring in the early 20th century"], "decomposition": ["What conditions can be treated with Prozac?", "The conditions in #1 are inflicted upon what?", "Does the Great Depression have #2?"], "evidence": [[[["Fluoxetine-1"]], [["Depression (mood)-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Fluoxetine-1"]], [["Major depressive disorder-1"]], [["Great Depression-1"], "operation"]], [[["Fluoxetine-6"]], ["no_evidence"], ["no_evidence"]]]}
{"id": 844, "term": "Do it yourself", "description": "building, modifying, or repairing something without the aid of experts or professionals", "question": "Do Do It Yourself channels online always show realistic projects?", "answer": false, "facts": ["The Youtube channel '5 Minute Crafts' specializes in DIY projects for all ages.", "\"5 Minute Crafts\" has come under fire for posting videos that were fraudulent or dangerous in nature. "], "decomposition": ["What are some popular Do It Yourself media?", "Of #1, which are YouTube channels?", "Are all of #2  regarded as realistic projects?"], "evidence": [[[["Do it yourself-13"]], ["no_evidence"], ["operation"]], [[["Do it yourself-13", "Do it yourself-6"]], ["no_evidence"], ["no_evidence"]], [[["Do it yourself-10", "Do it yourself-11", "Do it yourself-12", "Do it yourself-6"], "no_evidence"], ["operation"], ["no_evidence", "operation"]]]}
{"id": 994, "term": "Selfie", "description": "Photographic self-portrait", "question": "Are selfies more dangerous than plague in modern times?", "answer": true, "facts": ["There are an average of 7 human plague cases reported each year according to the CDC.", "Selfies have caused people to fall off of cliffs while trying to get the perfect picture.", "From October 2011 and November 2017, there were 259 selfie deaths in 137 incidents."], "decomposition": ["How many cases of the plague are there yearly?", "How many people die yearly while taking selfies?", "Is #2 greater than #1?"], "evidence": [[[["Epidemiology of plague-23"]], ["no_evidence"], ["operation"]], [[["Epidemiology of plague-23"], "operation"], ["no_evidence"], ["no_evidence"]], [[["Epidemiology of plague-1"]], [["Selfie-53"], "no_evidence"], ["operation"]]]}
{"id": 401, "term": "Giant squid", "description": "Deep-ocean dwelling squid in the family Architeuthidae", "question": "Can you house a giant squid at Soldier Field?", "answer": true, "facts": ["Soldier Field is a football stadium", "Football fields are 120 yards long, or 360 feet", "The maximum length of a giant squid is 43 feet"], "decomposition": ["How long are giant squid?", "What type of field is Soldier Field?", "How long are #2?", "Is #3 equal to or greater than #1?"], "evidence": [[[["Giant squid-1"]], [["Soldier Field-1"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Giant squid-1"]], [["Soldier Field-1"]], [["American football-36"]], ["operation"]], [[["Giant squid-1"]], [["Soldier Field-1"]], [["Gridiron football-7"]], ["operation"]]]}
{"id": 523, "term": "Odyssey", "description": "Epic poem attributed to Homer", "question": "In baseball, is a \"Homer\" named after the poet Homer who wrote the Odyssey?", "answer": false, "facts": ["Homer is a famous poet who wrote the epic poem the Odyssey.", "The Odyssey is about a character Odysseus on an epic journey home after the fall of Troy.", "In baseball a trip around all the bases is called a Home Run.", "\"Homer\" is a shortened name for Home Run."], "decomposition": ["What does the baseball term homer mean?", "Is #1 the same thing as the poet Homer?"], "evidence": [[[["Home run-1", "Home run-15"]], [["Homer-1"], "operation"]], [[["Home run-1", "Home run-35"]], [["Homer-1"], "operation"]], [[["Home run-1", "Home run-14", "Home run-2"]], [["Homer-1"], "operation"]]]}
{"id": 543, "term": "Kanji", "description": "adopted logographic Chinese characters used in the modern Japanese writing system", "question": "Can a person who knows only English read Kanji?", "answer": false, "facts": ["Kanji is a Japanese language.", "People who only know English can't read Japanese."], "decomposition": ["Is knowledge of Kanji included in English language?"], "evidence": [[[["Kanji-1"]]], [[["Kanji-1"]]], [[["Kanji-1"]]]]}
{"id": 418, "term": "Dominican Order", "description": "Roman Catholic religious order", "question": "Could the Dominican Order hypothetically defeat Blessed Gerard's order?", "answer": false, "facts": ["The Dominican Order is a Catholic group of friars that several priestly vows.", "Blessed Gerard was the founder of the Order of St John of Jerusalem (Knights Hospitaller).", " The Order of St John of Jerusalem (Knights Hospitaller) were a well trained Catholic military order that fought in the Crusades."], "decomposition": ["To what order did Blessed Gerard belong?", "What is the purpose of members of #1?", "Do members of the Dominican Order have training similar to #2?"], "evidence": [[[["Blessed Gerard-1"]], [["Benedictines-30"], "no_evidence"], [["Dominican Order-1"], "no_evidence", "operation"]], [[["Blessed Gerard-1"]], [["Knights Hospitaller-1"]], [["Dominican Order-2"], "operation"]], [[["Blessed Gerard-1"]], [["Knights Hospitaller-2", "Knights Hospitaller-3"]], [["Dominican Order-2"], "operation"]]]}
{"id": 506, "term": "Petroleum", "description": "Naturally occurring hydrocarbon liquid found underground", "question": "Can petroleum jelly be used as fuel in a car?", "answer": false, "facts": ["Petroleum is a highly reactive liquid used to power cars.", "Petroleum jelly is a solid substance used as an ointment on cuts and scrapes to promote healing.", "Petroleum jelly does not oxidize on exposure to the air and is not readily acted on by chemical reagents."], "decomposition": ["What is petroleum jelly used for?", "Does #1 include fueling cars?"], "evidence": [[[["Petroleum jelly-8"]], [["Petroleum jelly-8"]]], [[["Petroleum jelly-2"]], [["Gasoline-1"], "operation"]], [[["Petroleum jelly-15", "Petroleum jelly-23", "Petroleum jelly-24", "Petroleum jelly-26", "Petroleum jelly-8"]], ["operation"]]]}
{"id": 487, "term": "Fantasy", "description": "Genre of literature, film, television and other artforms", "question": "Would J.K Rowling's top sellers be on a fantasy shelf?", "answer": true, "facts": ["J.K Rowling's top sellers are her Harry Potter series.", "Harry Potter is a series about a boy who goes to a magical school to learn wizardry."], "decomposition": ["What is J. K. Rowling's top selling book?", "Is #1 fantasy?"], "evidence": [[[["J. K. Rowling-1"]], [["Harry Potter-1"], "operation"]], [[["J. K. Rowling-1"]], [["J. K. Rowling-1"]]], [[["J. K. Rowling-22"]], ["operation"]]]}
{"id": 726, "term": "Glutamic acid", "description": "amino acid", "question": "Does Masaharu Morimoto rely on glutamic acid?", "answer": true, "facts": ["Masaharu Morimoto is a Japanese chef", "Japanese cuisine relies on several forms of seaweed as ingredients and flavorings for broth like kombu dashi", "Glutamic acid has been identified as the flavoring component in kombu seaweed"], "decomposition": ["What is Masaharu Morimoto's profession?", "What cuisine does #1 make?", "What is a main ingredient in #2?", "Is glutamic acid a flavoring component in #3?"], "evidence": [[[["Masaharu Morimoto-1"]], [["Masaharu Morimoto-2"]], [["Monosodium glutamate-2"]], [["Glutamic acid-3"]]], [[["Masaharu Morimoto-1"]], [["Masaharu Morimoto-1"]], [["Rice-8"]], ["no_evidence"]], [[["Masaharu Morimoto-1"]], [["Masaharu Morimoto-1"]], [["Japanese cuisine-2", "Soy sauce-6"], "no_evidence"], [["Glutamic acid-22"], "operation"]]]}
{"id": 925, "term": "Citrus", "description": "genus of fruit-bearing plants (source of fruit such as lemons and oranges)", "question": "Can citrus grow in Ulaanbaatar?", "answer": false, "facts": ["Citrus can withstand short periods down to as cold as −10 °C (14 °F), but realistically temperatures not falling below −2 °C (28 °F) are required for successful cultivation.", "Ulaanbaatar has an average annual temperature of −0.4 °C or 31.3 °F."], "decomposition": ["What climates are suitable for growing citrus?", "What is the climate of Ulaanbaatar?", "Is #2 similar to #1?"], "evidence": [[[["Citrus-34"]], [["Ulaanbaatar-39"]], [["Citrus-34"]]], [[["Citrus-26", "Citrus-31"]], [["Ulaanbaatar-39"]], ["operation"]], [[["Citrus-31"]], [["Ulaanbaatar-40"]], ["operation"]]]}
{"id": 152, "term": "Albatross", "description": "Large seabirds in the order Procellariiformes found in the Southern Ocean and the North Pacific", "question": "Do mollymawks live where albatrosses cannot?", "answer": false, "facts": ["A mollymawk is a type of albatross", "Any place inaccessible to albatrosses in general is inaccessible to specific types of albatross"], "decomposition": ["Mollymawks are a type of which animal?", "Is #1 different from an albatross?"], "evidence": [[[["Mollymawk-1"]], ["operation"]], [[["Mollymawk-4"]], [["Mollymawk-4"]]], [[["Mollymawk-1"]], ["operation"]]]}
{"id": 40, "term": "Separation of church and state", "description": "principle to separate religious and civil institutions", "question": "Does USA fail separation of church and state in multiple ways?", "answer": true, "facts": ["Separation of church ad state refers to keeping God and religion out of state matters.", "Presidents of the United States are sworn in by placing their hand on a bible.", "The US currency contains the words, \"In God We Trust.\"", "The Pledge of Allegiance states, \"One Nation Under God.\""], "decomposition": ["How are US Presidents sworn in?", "What is the inscription on the US currency?", "What does the Pledge of Allegiance state?", "Do #1, #2 and #3 contain references to religion/the chuch?"], "evidence": [[[["President of the United States-46"]], [["In God We Trust-2"]], [["Pledge of Allegiance-1"]], ["operation"]], [[["United States presidential inauguration-23"]], [["In God We Trust-15"]], [["Pledge of Allegiance-1"]], ["operation"]], [[["Oath of office of the President of the United States-12"]], [["In God We Trust-3"]], [["Pledge of Allegiance-43"]], ["operation"]]]}
{"id": 668, "term": "Audiobook", "description": "recording of a text being read", "question": "Do Youtube viewers get unsolicited audiobook advice often?", "answer": true, "facts": ["Audible is one of the most common sponsors for Youtubers to have.", "Audible is an audiobook subscription service. ", "Audible ads typically involve discussing a book that the speaker has recently listened to."], "decomposition": ["What company is one of the most common sponsors for Youtubers to have?", "What do the ads for #1 typically involve?", "Does #2 involve someone giving audiobook advice?"], "evidence": [[[["Audible (store)-1"], "no_evidence"], [["Audible (store)-11"], "no_evidence"], ["operation"]], [[["YouTube-3"], "no_evidence"], [["YouTube-3"]], ["no_evidence"]], [[["Audible (store)-16"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 118, "term": "Blues", "description": "Musical form and music genre", "question": "Were Depeche Mode heavily influenced by blues music?", "answer": false, "facts": ["Blues incorporated spirituals, work songs, field hollers, shouts, chants, and rhymed simple narrative ballads and was derived from African-Americans.", "Blues music uses instruments like slide guitar, harmonica, piano, and bass drums.", "Depeche Mode are a British pop synth group.", "Depeche Mode uses computer synthesizers to create their unique sound as well as heavy rock guitars.", "Depeche Mode was influenced by The Cure, and Ultravox, new wave rock bands."], "decomposition": ["What kind of songs and instruments are associated with Blues?", "What kind of musical instruments does the Depeche Mode use to create music?", "Is #2 very similar to #1?"], "evidence": [[[["Blues-37"]], [["Depeche Mode-35"]], ["operation"]], [[["Blues-1"]], [["Depeche Mode-1"]], ["operation"]], [[["Blues-1"], "no_evidence"], [["Depeche Mode-6"]], ["operation"]]]}
{"id": 435, "term": "Crucifixion", "description": "Method of capital punishment in which the victim is tied or nailed to a large wooden beam and left to hang until eventual death", "question": "Does crucifixion violate US eighth amendment?", "answer": true, "facts": ["The eighth amendment prohibits cruel and unusual punishment.", "Crucifixion was particularly barbaric as people do not die instantly and live for several days."], "decomposition": ["What does the Eighth Amendment say about punishment measures?", "What are the features of crucifixion as a method of punishment?", "Is #1 contradicted by #2?"], "evidence": [[[["Eighth Amendment to the United States Constitution-1"]], [["Crucifixion-1"]], ["operation"]], [[["Eighth Amendment to the United States Constitution-1"]], [["Crucifixion-1"]], [["Crucifixion-1", "Eighth Amendment to the United States Constitution-1"], "operation"]], [[["United States constitutional sentencing law-4"]], [["Cruel and unusual punishment-6"]], ["operation"]]]}
{"id": 988, "term": "Yellow pages", "description": "Telephone directory of businesses by category", "question": "Is the Yellow Pages the fastest way to find a phone number?", "answer": false, "facts": ["The Yellow Pages is a book that contains alphabetized phone listings.", "Yellow pages involves going through many listings and remembering your alphabet.", "Google allows a person to type in a name quickly and look for a phone number.", "Household AI assistants like Echo allow people to merely speak a name and ask for number."], "decomposition": ["How are the phone numbers organized in the Yellow Pages?", "To find a phone number in #1, what does one have to do?", "To find a phone number on Google, what does one have to do?", "Is #2 faster than #3?"], "evidence": [[[["Yellow pages-1"]], [["Yellow pages-5"], "no_evidence"], [["Google Search-3"]], ["operation"]], [[["Yellow pages-1"]], [["Yellow pages-5"]], [["Google Search-16"]], ["operation"]], [[["Yellow pages-1"]], ["no_evidence"], [["Web search engine-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 56, "term": "Tenth Amendment to the United States Constitution", "description": "says powers not Constitutionally granted to the Federal Government belong to States or the People", "question": "Was the tenth Amendment to the Constitution written using Pitman shorthand?", "answer": false, "facts": ["Pitman shorthand was invented in 1837.", "The tenth Amendment to the Constitution was added in 1791."], "decomposition": ["When was Pitman shorthand invented?", "When was the  tenth Amendment to the Constitution added?", "Did #1 happen before #2?"], "evidence": [[[["Pitman shorthand-1"]], [["Tenth Amendment to the United States Constitution-1"]], ["operation"]], [[["Pitman shorthand-5"]], [["Tenth Amendment to the United States Constitution-1"]], ["operation"]], [[["Pitman shorthand-1"]], [["Tenth Amendment to the United States Constitution-1"]], ["operation"]]]}
{"id": 98, "term": "Hair", "description": "protein filament that grows from follicles found in the dermis, or skin", "question": "Can furniture be made of hair?", "answer": true, "facts": ["Hair is a protein filament that grows from living bodies.", "Hair is durable when woven together. ", "Furniture cushions can be maid from horse hair. "], "decomposition": ["What is hair?", "Can #1 be woven together securely?"], "evidence": [[[["Hair-2"]], ["no_evidence", "operation"]], [[["Hair-2"]], [["Alpha-keratin-4"], "operation"]], [[["Hair-2"]], [["Braid-2", "Cushion-1"], "no_evidence"]]]}
{"id": 619, "term": "Monkey", "description": "Animal of the \"higher primates\" (the simians), but excluding the apes", "question": "Would a monkey outlive a human being on average?", "answer": false, "facts": ["The average human lifespan is 79 years.", "The longest-lived monkey species have a lifespan about 45-50 years in captivity."], "decomposition": ["How long does the average human live?", "What is the longest lifespan of a monkey?", "Is #2 larger than #1?"], "evidence": [[[["Life expectancy-2"]], [["Monkey-20"], "no_evidence"], ["operation"]], [[["Old age-99"]], [["Night monkey-9"], "no_evidence"], ["operation"]], [[["Life expectancy-2"]], [["Little Mama-2"]], ["operation"]]]}
{"id": 562, "term": "The Dark Knight (film)", "description": "2008 film directed by Christopher Nolan", "question": "Was the death of Heath Ledger caused by his work on The Dark Knight?", "answer": false, "facts": ["Heath Ledger accidentally overdosed on prescription medication.", "Heath Ledger's overdose led to his death. "], "decomposition": ["What was the cause of Heath Ledger's death?", "Is #1 related to his work on the The Dark Knight?"], "evidence": [[[["Heath Ledger-3"]], [["Heath Ledger-21", "Heath Ledger-22", "Heath Ledger-30"]]], [[["Heath Ledger-29"]], [["Heath Ledger-29"], "no_evidence"]], [[["Heath Ledger-3"]], [["Heath Ledger-3"]]]]}
{"id": 417, "term": "Snow White", "description": "fairy tale", "question": "Can all of Snow White's dwarfs play a game of 7 Wonders simultaneously?", "answer": true, "facts": ["The fairy tale character Snow White was friends with seven dwarfs.", "The board game 7 Wonders is for 2 to 7 players."], "decomposition": ["How many players can participate in a game of 7 Wonders?", "How many dwarfs are in the story of Snow White?", "Is #2 less than or equal to #1?"], "evidence": [[[["7 Wonders (board game)-1"], "no_evidence"], [["Snow White and the Seven Dwarfs (1937 film)-1"]], ["no_evidence", "operation"]], [[["7 Wonders (board game)-14"], "no_evidence"], [["Snow White and the Seven Dwarfs (1937 film)-7"]], ["operation"]], [[["7 Wonders (board game)-21"]], [["Snow White-3"]], ["operation"]]]}
{"id": 648, "term": "Shiva", "description": "One of the principal deities of Hinduism.", "question": "Does Sam Harris worship Shiva?", "answer": false, "facts": ["Sam Harris is an atheist.", "Atheism is, in the broadest sense, an absence of belief in the existence of deities."], "decomposition": ["What is Sam Harris' religious affiliation?", "Does a #1 worship any gods?"], "evidence": [[[["Sam Harris-1"]], [["Atheism-1"]]], [[["Sam Harris-1"]], [["Atheism-1"]]], [[["Sam Harris-12"]], ["operation"]]]}
{"id": 386, "term": "Psychotherapy", "description": "clinically applied psychology for desired behavior modification", "question": "Do some psychotherapy patients have no mental illness?", "answer": true, "facts": ["Psychotherapy is useful for couples navigating relationship issues.", "Grief is a common reason that people seek psychotherapy. "], "decomposition": ["What are some common issues that make people seek psychotherapy?", "Does #1 not always involve mental illness?"], "evidence": [[[["Psychotherapy-1"]], ["operation"]], [[["Psychotherapy-1"]], [["Psychotherapy-4"], "operation"]], [[["Psychotherapy-1"]], [["Psychotherapy-32"], "operation"]]]}
{"id": 938, "term": "Ronda Rousey", "description": "American professional wrestler, actress, author, mixed martial artist and judoka", "question": "Will Ronda Rousey hypothetically defeat X-Men's Colossus in a fight?", "answer": false, "facts": ["Ronda Rousey is a mixed martial artist and wrestler.", "Ronda Rousey relies on striking moves and submission tactics to dominate her opponents.", "X-Men's Colossus has the ability to change his appearance.", "Colossus's mutation allows him to create an organic steel layer, that acts as an impenetrable external shell."], "decomposition": ["What type of profession is Ronda Rousey in?", "What moves do #1 use to beat their opponents?", "What special ability does X-men have?", "Can someone with #2 easily beat someone with #3?"], "evidence": [[[["Ronda Rousey-1"]], [["Ronda Rousey-43"]], [["X-Men-2"]], ["no_evidence"]], [[["Ronda Rousey-1"]], [["Professional wrestling-1"]], [["Colossus (comics)-55"]], ["operation"]], [[["Ronda Rousey-1"]], [["Grappling position-5"], "no_evidence"], [["Colossus (comics)-2"]], ["operation"]]]}
{"id": 169, "term": "Saint Vincent and the Grenadines", "description": "Country in the Caribbean", "question": "Was Saint Vincent and the Grenadines named by an Italian explorer?", "answer": true, "facts": ["Christopher Columbus, an Italian explorer, was the first European to discover the islands.", "He named them after St. Vincent because he first saw the island on the saint's feast day, and the Spanish city of Granada."], "decomposition": ["Who discovered Saint Vincent and the Grenadines?", "Was #1 from Italy?"], "evidence": [[[["Saint Vincent and the Grenadines-7"]], [["Christopher Columbus-1"], "operation"]], [[["Saint Vincent and the Grenadines-7"]], [["Christopher Columbus-1"]]], [[["Saint Vincent and the Grenadines-7"]], [["Christopher Columbus-1"]]]]}
{"id": 133, "term": "Ivan the Terrible", "description": "Grand Prince of Moscow and 1st Tsar of Russia", "question": "Was 847 Pope Leo same iteration of his name as Ivan the Terrible?", "answer": true, "facts": ["Pope Leo in 847 AD was the fourth Leo to have that name and was called Leo IV.", "Ivan the Terrible was the 4th Tsar to have the name Ivan and was known as Ivan IV Vasilyevich."], "decomposition": ["Which Pope Leo is associated with the year 847 AD?", "How many similarly named popes were before #1?", "What was Ivan the Terrible's title as a ruler?", "How many similarly named #3 ruled before him?", "Is #2 equal to #4?"], "evidence": [[[["Pope Leo IV-1"]], [["Pope Leo I-1", "Pope Leo II-1", "Pope Leo III-1"]], [["Ivan the Terrible-1"]], [["Ivan I of Moscow-1", "Ivan II of Moscow-1", "Ivan III of Russia-1"]], ["operation"]], [[["Pope Leo IV-1"]], ["operation"], [["Ivan the Terrible-1"]], ["operation"], ["operation"]], [[["Pope Leo IV-1"]], ["operation"], [["Ivan the Terrible-1"]], ["operation"], ["operation"]]]}
{"id": 877, "term": "Molière", "description": "17th-century French playwright and actor", "question": "Was Moliere Queen Margot's ill fated lover?", "answer": false, "facts": ["Queen Margot is a character in Alexande Dumas's La Reine Margot.", "Queen Margot keeps the head of her executed lover.", "Joseph Boniface de La Môle, nicknamed La Mole, was executed as a conspirator against Queen Margot's kingdom.", "Queen Margot is set during the St. Bartholomew's Day Massacre which occurred in 1572.", "Moliere was born in 1622."], "decomposition": ["In what work by Alexande Dumas does Queen Margot appear?", "When was #1 written?", "In what year was Moliere born?", "Is #3 before #2?"], "evidence": [[[["La Reine Margot (novel)-1"]], [["La Reine Margot (novel)-1"]], [["Molière-1"]], ["operation"]], [[["La Reine Margot (novel)-1", "La Reine Margot (novel)-3"]], [["La Reine Margot (novel)-1", "La Reine Margot (novel)-3"]], [["Molière-1"]], ["operation"]], [[["La Reine Margot (novel)-1", "La Reine Margot (novel)-5"]], [["La Reine Margot (novel)-1"]], [["Molière-1"]], ["operation"]]]}
{"id": 153, "term": "Year", "description": "Orbital period of the Earth around the Sun", "question": "Can you listen to the entire Itunes song catalog in one year?", "answer": false, "facts": ["Itunes has around 43 million songs as of 2017.", "The average length of a song is 3 minutes.", "There are 525,600 minutes in a year."], "decomposition": ["How many songs are on iTunes?", "What is the average song length?", "What is #1 multiplies by #2?", "How many minutes are in a year?", "Is #4 greater than #3?"], "evidence": [[[["ITunes Store-2"]], [["Popular music-19"]], ["operation"], [["Year-57"]], ["operation"]], [[["ITunes-20"]], ["no_evidence"], ["no_evidence", "operation"], [["Seasons of Love-1"]], ["no_evidence", "operation"]], [[["ITunes Store-2"]], [["Justin Bieber-29"], "no_evidence"], ["operation"], [["Year-19"], "no_evidence"], ["operation"]]]}
{"id": 72, "term": "Lobster", "description": "family of crustaceans", "question": "Can lobster breathe in the desert?", "answer": false, "facts": ["Lobsters use gills to breathe.", "Gills require water to breathe.", "There is no water in the desert. "], "decomposition": ["Which part of their body do lobsters breathe with?", "Where does #1 obtain oxygen from?", "Is #2 easily found in the desert?"], "evidence": [[[["Gill-1", "Lobster-14"]], [["Aquatic respiration-2"]], [["Desert-3"], "operation"]], [[["Lobster-14"], "no_evidence"], [["Lobster-2"], "no_evidence"], [["Desert-1"], "operation"]], [[["Gill-1", "Lobster-14"]], [["Gill-1"]], [["Desert-1", "Precipitation-1"]]]]}
{"id": 191, "term": "Fair trade", "description": "form of trade", "question": "Is the United States the largest exporter of Fair Trade products?", "answer": false, "facts": ["Fair trade is an arrangement designed to help producers in developing countries achieve good trading.", "The United States is not considered a developing country."], "decomposition": ["What countries can use the designation \"fair trade\" for their goods? ", "Does the US have the designation in #1?"], "evidence": [[[["European Fair Trade Association-1"], "no_evidence"], ["operation"]], [[["Fair trade-5"], "no_evidence"], ["no_evidence", "operation"]], [[["Fair trade-1"]], [["Developed country-3", "Developing country-1"]]]]}
{"id": 94, "term": "Polymath", "description": "Individual whose knowledge spans a significant number of subjects", "question": "Would Tony Stark be considered a polymath?", "answer": true, "facts": ["A polymath is a person who has knowledge in a wide variety of subjects.", "Tony Stark is considered a genius in mathematics, engineering, computer science, and physics, as well as demonstrating skills in metalworking, engine design, and genetics."], "decomposition": ["What does one have to have to be considered a polymath?", "Does Tony Stark have #1?"], "evidence": [[[["Polymath-1"]], [["Iron Man-2"], "operation"]], [[["Polymath-1"]], [["Tony Stark (Marvel Cinematic Universe)-1"]]], [[["Polymath-1"]], [["Iron Man-71"], "operation"]]]}
{"id": 809, "term": "Zucchini", "description": "Edible summer squash, typically green in color", "question": "Can the original name of the zucchini be typed on the top row of a QWERTY keyboard?", "answer": false, "facts": ["The original name for the zucchini in Mexican language or Nahuatl is ayokonetl.", "The top row of a QWERTY keyboard contains the keys q, w, e, r, t, y, u, i , o, and p."], "decomposition": ["What is the original name of the zucchini?", "What keys are on the top row of a QWERTY keyboard?", "Is every letter in #1 present in #2?"], "evidence": [[[["Zucchini-7"]], [["QWERTY-9"]], [["QWERTY-9", "Zucchini-7"], "no_evidence"]], [[["Zucchini-4"]], [["QWERTY-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Zucchini-1"]], [["QWERTY-1"]], ["operation"]]]}
{"id": 110, "term": "Tourism", "description": "travel for recreational or leisure purposes", "question": "Is the Jurassic era a tourist destination?", "answer": false, "facts": ["The Jurassic era is a period of time in the past.", "Time travel does not currently exist. "], "decomposition": ["When did the Jurassic era occur?", "Can tourist travel to #1?"], "evidence": [[[["Jurassic-1"]], [["Time travel-2"]]], [[["Jurassic-1"]], ["operation"]], [[["Jurassic-1"]], ["operation"]]]}
{"id": 176, "term": "Forbidden City", "description": "Art museum, Imperial Palace, Historic site in Beijing, China", "question": "Is the Forbidden City host to a wooden rollercoaster?", "answer": false, "facts": ["Wooden rollercoasters are relatively modern.", "The Forbidden City is an ancient historic site."], "decomposition": ["When were wooden rollercoasters first built?", "What is the Forbidden City?", "When was #2 built?", "Did #3 come before #1?"], "evidence": [[[["Wooden roller coaster-3"]], [["Forbidden City-1"]], [["Forbidden City-2"]], ["operation"]], [[["Wooden roller coaster-3"]], [["Forbidden City-1"]], [["Forbidden City-2"]], ["operation"]], [[["History of the roller coaster-8"]], [["Forbidden City-1"]], [["Forbidden City-2"]], ["operation"]]]}
{"id": 278, "term": "Ringo Starr", "description": "British musician, drummer of the Beatles", "question": "Would Ringo Starr avoid the pot roast at a restaurant?", "answer": true, "facts": ["Ringo Starr is a vegetarian.", "Vegetarianism is the practice of abstaining from the consumption of meat.", "Pot roast is a braised beef dish made by browning a roast-sized piece of beef before slow cooking the meat in a covered dish, sometimes with vegetables, in or over liquid."], "decomposition": ["What dietary system does Ringo Starr follow?", "What type of foods are not allowed to be eaten by someone following #1?", "What is pot roast made of?", "Is #3 part of #2?"], "evidence": [[[["Ringo Starr-71"]], [["Vegetarianism-1"]], [["Pot roast-1"]], ["operation"]], [[["Ringo Starr-71"]], [["Vegetarianism-1"]], [["Pot roast-1"]], [["Beef-1"], "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence"], ["no_evidence"]]]}
{"id": 19, "term": "Saudi Aramco", "description": "Saudi Arabian petroleum and natural gas company", "question": "Was Saudi Aramco started due to an assassination?", "answer": true, "facts": ["Saudi Aramco was formed in response to oil shortages during World War I", "The origins of World War I can be traced to the assassination of Archduke Franz Ferdinand in Sarajevo"], "decomposition": ["Saudi Aramco was formed in response to oil shortages during what major conflict?", "What event is widely acknowledged to have started #1?", "Is #2 an assassination?"], "evidence": [[[["Saudi Aramco-7"]], [["Paris in the Belle Époque-96"]], [["Assassination-1"]]], [[["Saudi Aramco-7"]], [["Assassination of Archduke Franz Ferdinand-1"]], ["operation"]], [[["Saudi Aramco-7"]], [["Assassination of Archduke Franz Ferdinand-1"]], ["operation"]]]}
{"id": 448, "term": "The Jungle Book", "description": "1894 children's book by Rudyard Kipling", "question": "Does The Jungle Book contain racist subtext?", "answer": true, "facts": ["Baloo, the father character in The Jungle Book, refers to the money characters as \"flat-nosed flaky creeps\" mocking a common black feature feature.", "The antagonist snake character was made to sound like an Indian mag, and was said to hate men.", "King Louie is viewed socially as a racist archetype of a black man."], "decomposition": ["What term did Baloo use to refer to the monkey characters in \"The Jungle Book\"?", "What sentiment did the antagonistic snake express towards men?", "Do #1 and #2 have racist connotation?"], "evidence": [[[["Bandar-log-1"]], [["Kaa-3"]], [["Bandar-log-1"], "no_evidence"]], [[["The Jungle Book-1"], "no_evidence"], [["The Jungle Book (2016 film)-6"], "no_evidence"], [["The Jungle Book (1967 film)-26"], "operation"]], [["no_evidence"], ["no_evidence"], [["The Jungle Book-18"], "no_evidence", "operation"]]]}
{"id": 917, "term": "Shaggy (musician)", "description": "Reggae singer and former U.S. Marine", "question": "Would Shaggy and Redenbacher popcorn founder both raise hand during first name roll call?", "answer": true, "facts": ["Roll call is when teachers call the names of students and they raise their hand to show they are present.", "The founder of Redenbacher popcorn was Orville Redenbacher.", "Reggae musician Shaggy was born Orville Richard Burrell."], "decomposition": ["What is the first name of the person who founded Redenbacher popcorn?", "What is the first name of Reggae musician Shaggy?", "Is #1 the same as #2?"], "evidence": [[[["Orville Redenbacher-1"]], [["Shaggy (musician)-1"]], ["operation"]], [[["Orville Redenbacher-1"]], [["Shaggy (musician)-1"]], ["operation"]], [[["Orville Redenbacher-1"]], [["Shaggy (musician)-1"]], ["operation"]]]}
{"id": 287, "term": "Statue of Freedom", "description": "19th-century statue by Thomas Crawford on top of the US Capitol", "question": "Can you see the Statue of Freedom from the Statue of Liberty?", "answer": false, "facts": ["The Statue of Freedom is in Washington, D.C. on the Capitol Building", "The Statue of Liberty is in New York City"], "decomposition": ["Where is the Statue of Freedom located?", "Where is the Statue of Liberty located?", "Is #1 within reasonable range of visibility from #2?"], "evidence": [[[["Statue of Freedom-2"]], [["Statue of Liberty-1"]], [["Statue of Freedom-2"]]], [[["Statue of Freedom-1"]], [["Statue of Liberty-1"]], ["operation"]], [[["Statue of Freedom-1"]], [["Statue of Liberty-1"]], ["operation"]]]}
{"id": 540, "term": "U2", "description": "Four-member Irish rock band, from Dublin", "question": "Could someone listen to the entire U2 debut studio album during an episode of Peppa Pig?", "answer": false, "facts": ["U2's debut studio album was titled Boy.", "The album, Boy, is 42 minutes and 52 seconds long.", "An episode of Peppa Pig has a running time of approximately 5 minutes."], "decomposition": ["What is the title of U2's debut studio album?", "How long is #1?", "How long is Peppa Pig episodes?", "Is #3 longer than #2?"], "evidence": [[[["Boy (album)-1"]], ["no_evidence"], [["Peppa Pig-4"]], ["no_evidence", "operation"]], [[["Boy (album)-1"]], ["no_evidence"], [["Peppa Pig-6"]], ["operation"]], [[["Disco Boy-5"], "no_evidence"], ["operation"], [["Peppa Pig-8"], "no_evidence"], ["operation"]]]}
{"id": 587, "term": "Drag king", "description": "female performance artists who dress and behave in masculine way for performance", "question": "Do drag kings take testosterone to look masculine?", "answer": false, "facts": ["Drag Kings will use contouring and makeup to make their facial features appear more masculine and chiseled. ", "Testosterone is prescribed for transgender men to help with transitioning and dysphoria.", "Drag kings often identify as women, but dress as men for show."], "decomposition": ["Which features of themselves do drag kings modify to look masculine?", "Would #1 require testosterone intake?"], "evidence": [[[["Passing (gender)-31"], "no_evidence"], [["Transgender hormone therapy (male-to-female)-42"], "operation"]], [[["Drag king-1"]], ["operation"]], [[["Drag king-1"]], [["Testosterone-1"], "operation"]]]}
{"id": 840, "term": "Cinco de Mayo", "description": "Annual celebration held on May 5", "question": "Would Emmanuel Macron celebrate Cinco de Mayo?", "answer": false, "facts": ["Cinco de Mayo is observed to commemorate the Mexican Army's victory over the French Empire at the Battle of Puebla, on May 5, 1862.", "Emmanuel Macron is the current president of France.", "Emmanuel Macron was born in France and his ancestry traces back to France.", "People do not typically celebrate events in which their country was defeated."], "decomposition": ["Which countries usually celebrate the Cinco de Mayo?", "Which country is Emmanuel Macron from?", "Is #2 included in any of #1?"], "evidence": [[[["Cinco de Mayo-17"]], [["Amiens-1", "Emmanuel Macron-5"]], ["operation"]], [[["Battle of Puebla-11"]], [["Emmanuel Macron-1"]], ["operation"]], [[["Cinco de Mayo-12"], "no_evidence"], [["Emmanuel Macron-63"], "operation"], ["no_evidence"]]]}
{"id": 490, "term": "Judo", "description": "modern martial art, combat and Olympic sport", "question": "Do silicone suits make judo difficult?", "answer": true, "facts": ["Judo is a martial art that requires combatants to grip their opponents and throw them in various ways.", "Judo practitioners traditionally wear an outfit called a gi, which opponents use to grip and throw.", "Silicone is one of the slipperiest substances on the planet."], "decomposition": ["What maneuvers are required to do Judo?", "What characteristics does an article of clothing need to have in order to do #1 effectively?", "What characteristics does a silicone suit have? ", "Is #3 excluded from #2?"], "evidence": [[[["Judo-1"]], [["Keikogi-1"], "no_evidence"], [["Silicone rubber-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Leopold's maneuvers-6"], "no_evidence"], ["no_evidence"], [["Silicone-47"]], ["operation"]], [[["Judo-1"]], [["Judo-48"]], [["Silicone-1"]], ["operation"]]]}
{"id": 819, "term": "Snowdon", "description": "highest mountain in Wales", "question": "Would Snowdon mountain be a piece of cake for Tenzing Norgay?", "answer": true, "facts": ["Tenzing Norgay was a mountaineer that climbed Mount Everest in 1953.", "Snowdon Mountain has a peak of 3,560 feet.", "Mount Everest has a peak of over 29,000 feet."], "decomposition": ["How high is Snowdon Mountain?", "What was the highest peak ever climbed by Tenzing Norgay", "How high is #2?", "Is #3 greater than #1?"], "evidence": [[[["Snowdon-1"]], [["Tenzing Norgay-1"]], [["Mount Everest-2"]], ["operation"]], [[["Snowdon-1"]], [["Mount Everest-1", "Tenzing Norgay-1"]], [["Mount Everest-2"]], ["operation"]], [[["Snowdon-1"], "no_evidence"], [["Tenzing Norgay-1"]], [["Mount Everest-2"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 151, "term": "Snickers", "description": "brand name chocolate bar made by Mars, Incorporated", "question": "Would 2019 Natalie Portman avoid a Snickers bar due to her diet?", "answer": true, "facts": ["Actress Natalie Portman resumed her vegan diet in 2018 after giving birth, and has been vegan ever since.", "Vegans do not eat animal products.", "Snickers contains egg whites as an ingredient."], "decomposition": ["What foods has Natalie Portman avoided since 2018?", "What are the ingredients in a Snickers bar?", "Is anything from #2 also in #1?"], "evidence": [[[["Natalie Portman-30", "Veganism-1"]], [["Snickers-1"]], [["Nougat-1", "Types of chocolate-6"], "operation"]], [[["Natalie Portman-27", "Veganism-1"]], [["Snickers-1"]], ["operation"]], [[["Natalie Portman-27"], "no_evidence"], [["Snickers-7"]], ["operation"]]]}
{"id": 627, "term": "PayPal", "description": "Online financial services company based in San Jose, California", "question": "Would it be unusual to use paypal for drug deals?", "answer": true, "facts": ["Paypal prohibits the use of their platform for drugs or drug paraphernalia. ", "Using paypal leaves a digital footprint of any drug purchase."], "decomposition": ["Which kind of payments are prohibited on Paypal?", "Does #1 include payment for drug deals?"], "evidence": [[["no_evidence"], ["operation"]], [[["PayPal-55"]], ["operation"]], [[["Reception of WikiLeaks-37"], "no_evidence"], ["operation"]]]}
{"id": 274, "term": "Electronic dance music", "description": "broad category of electronic music", "question": "Did Beethoven enjoy listening to EDM?", "answer": false, "facts": ["Ludwig van Beethoven died in 1827.", "EDM originated in the mid-to-late 20th century."], "decomposition": ["When did Ludwig van Beethoven die?", "When did EDM originate?", "Is #1 after #2?"], "evidence": [[[["Death of Ludwig van Beethoven-15"]], [["Trap music (EDM)-1"]], ["operation"]], [[["Ludwig van Beethoven-61"]], [["Electronic dance music-2"]], ["operation"]], [[["Ludwig van Beethoven-1"]], [["Electronic dance music-2"]], ["operation"]]]}
{"id": 580, "term": "Hypothermia", "description": "A human body core temperature below 35.0°C", "question": "Would someone on Venus be unlikely to experience hypothermia?", "answer": true, "facts": ["Hypothermia typically occurs from exposure to extreme cold.", "The average surface temperature on Venus is 863°F.", "A warmer surface temperature on the planet will result in a higher body temperature for people on that planet."], "decomposition": ["What is the average surface temperature on Venus?", "In order for the human body to experience hypothermia, it would have to be exposed to temperature that are what in relation to body temp?", "What is human body temperature?", "Does #1 meet the condition of #2 relative to #3?"], "evidence": [[[["Venus-23"]], [["Hypothermia-1"]], [["Human body temperature-4"]], ["operation"]], [[["Venus-2"]], [["Hypothermia-2"]], [["Human body temperature-7"]], ["operation"]], [[["Venus-19"]], [["Hypothermia-5"]], [["Human body temperature-4"]], ["operation"]]]}
{"id": 430, "term": "Romani people", "description": "Ethnic group living mostly in Europe and the Americas", "question": "Is the use of the word Gypsy by non-Romani people considered okay?", "answer": false, "facts": ["'Gypsy' is considered a slur in the Americas by Romani people.", "Lady Gaga has faced online criticism regarding her use of the word 'Gypsy' as the title and lyrics of a song."], "decomposition": ["What kind of word is Gypsy considered in the Americas by Romani people?", "Would using #1 types of words be considered okay?"], "evidence": [[[["Names of the Romani people-11"], "no_evidence"], [["Antiziganism-1"]]], [[["Names of the Romani people-11"]], ["operation"]], [[["Names of the Romani people-11"]], [["Pejorative-1"], "operation"]]]}
{"id": 774, "term": "Walt Disney", "description": "American entrepreneur, animator, voice actor and film producer", "question": "Was Walt Disney ever interviewed by Anderson Cooper?", "answer": false, "facts": ["Walt Disney died on Dec 15, 1966", "Anderson Cooper was born on Jun 03, 1967"], "decomposition": ["When did Walt Disney pass away?", "When was Anderson Cooper born?", "Is #2 before #1?"], "evidence": [[[["Walt Disney-1"]], [["Anderson Cooper-1"]], ["operation"]], [[["Walt Disney-36"]], [["Anderson Cooper-1"]], ["operation"]], [[["Walt Disney-1"]], [["Anderson Cooper-1"]], ["operation"]]]}
{"id": 251, "term": "NATO", "description": "Intergovernmental military alliance of Western states", "question": "NATO doesn't recognize double triangle flag countries?", "answer": true, "facts": ["NATO is a members only alliance of several countries.", "Nepal has a double triangle flag.", "Nepal has not been recognized as a member of NATO."], "decomposition": ["What country has a flag with double triangles on it?", "Which countries are part of NATO?", "Is #1 not included in #2?"], "evidence": [[[["Flag of Nepal-5"]], [["Member states of NATO-3"]], ["operation"]], [[["Flag of Nepal-5"]], [["Member states of NATO-2"]], ["operation"]], [[["Flag of Nepal-1"]], [["NATO-30"]], ["operation"]]]}
{"id": 87, "term": "Constitution of the Philippines", "description": "Supreme law of the Republic of the Philippines", "question": "Does the Constitution of the Philippines copy text from the British constitution?", "answer": false, "facts": ["The Constitution of the Philippines is a document ratified in 1987", "The British constitution is not an actual document, but a collection of legal statutes, precedent, political custom and social convention"], "decomposition": ["What was the British Constitution?", "What kind of document was the Constitution of the Philippines?", "Can #1 copy something from #2"], "evidence": [[[["Constitution of the United Kingdom-1"]], [["Constitution of the Philippines-1"]], ["operation"]], [[["Constitution of the United Kingdom-1"]], [["Constitution of the Philippines-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Constitution of the United Kingdom-5"]], [["Constitution of the Philippines-1"]], ["no_evidence"]]]}
{"id": 637, "term": "Black Sea", "description": "Marginal sea of the Atlantic Ocean between Europe and Asia", "question": "Can sunlight travel to the deepest part of the Black Sea?", "answer": false, "facts": ["The Black Sea has a maximum depth of 2,212 meters", "Sunlight does not penetrate water below 1000 meters"], "decomposition": ["What is the maximum depth of the Black Sea?", "How deep can sunlight penetrate a sea?", "Is #1 less than #2?"], "evidence": [[[["Black Sea-2"]], [["Deep sea-1"]], ["operation"]], [[["Black Sea-2"]], [["Photic zone-5"]], ["operation"]], [[["Black Sea-2"]], [["Photic zone-5"]], ["operation"]]]}
{"id": 66, "term": "2000", "description": "Year", "question": "Was there fear leading up to the year 2000?", "answer": true, "facts": ["Many computer programs were not designed with the year 2000 in mind.", "People were worried that computers would crash all over the world when the year 2000 arrived.", "Financial and electrical systems require computers to function.", "Without financial and electrical systems there could be global chaos."], "decomposition": ["What concerns did people have about computing systems as 2000 approached?", "Did #1 involve a widespread fear of malfunction?"], "evidence": [[[["Year 2000 problem-1"]], [["Year 2000 problem-23"], "operation"]], [[["Year 2000 problem-1"]], [["Year 2000 problem-15"], "operation"]], [[["Year 2000 problem-1"]], [["Year 2000 problem-23"]]]]}
{"id": 303, "term": "Brazilian Navy", "description": "Naval warfare branch of Brazil's military forces", "question": "Are some Brazilian Navy ships built in Britian?", "answer": true, "facts": ["The Brazilian Navy stated in 2018 that they had purchased the helicopter carrier ship HMS Ocean.", "HMS stands for \"His/Her Majesty's Ship\", which is emblazoned on ships of the British Royal Navy. ", "Some of the ships in the Brazilian Navy are guided missile frigates built in Britian."], "decomposition": ["Which helicopter carrier ship did the Brazilian Navy announce that they had acquired in 2018?", "Was #1 built in Britain?"], "evidence": [[[["Brazilian Navy-62"]], [["HMS Ocean (L12)-1"]]], [[["HMS Ocean (L12)-2"]], [["HMS Ocean-1"]]], [[["Aircraft carrier-43"]], ["operation"]]]}
{"id": 464, "term": "Osama bin Laden", "description": "Co-founder of al-Qaeda", "question": "Does Osama bin Laden put a wafer on his tongue every Sunday?", "answer": false, "facts": ["Osama bin Laden was an Islamic fundamentalist", "The practice of putting a wafer on your tongue is called Communion", "Communion is a Christian religious practice", "Christians commonly attend religious services on Sunday"], "decomposition": ["What is the practice of putting a wafer on your tongue called?", "What religion practices #1 on Sundays?", "Does Osama bin Laden practice #2?"], "evidence": [[[["Eucharist-1"]], [["Christianity-37"]], [["Osama bin Laden-1"]]], [[["Eucharist-65"]], [["Eucharist-1"]], [["Osama bin Laden-1"], "operation"]], [[["Eucharist-95"]], [["Eucharist-1"]], [["Osama bin Laden-10"], "operation"]]]}
{"id": 837, "term": "Moulin Rouge", "description": "cabaret in Paris, France", "question": "Could Moulin Rouge have been hypothetically used as Spain's Spanish American War triage center?", "answer": true, "facts": ["The Moulin Rouge cabaret in France had a capacity of 850 people.", "Spain had 700-800 injured during Spanish American War."], "decomposition": ["How many people can be seated in Moulin Rouge?", "How many Spaniards were injured during the Spanish American War?", "Ia #1 greater than #2?"], "evidence": [[[["Moulin Rouge-2"], "no_evidence"], [["Spanish–American War-55"]], ["operation"]], [[["Moulin Rouge-2"], "no_evidence"], [["Spanish–American War-57"], "no_evidence"], ["no_evidence", "operation"]], [[["Moulin Rouge! (musical)-3"], "no_evidence"], [["Spanish–American War-55"], "no_evidence"], ["operation"]]]}
{"id": 432, "term": "E.T. the Extra-Terrestrial", "description": "1982 American science fiction film directed by Steven Spielberg", "question": "Would E.T. the Extra-Terrestrial alien hypothetically love Friendly's?", "answer": true, "facts": ["E.T., the main alien from E.T. the Extra-Terrestrial, loved Reese's Pieces candy.", "Friendly's is a restaurant that serves dinner entrees and ice cream dishes.", "Friendly's has several desserts with Reese's candy including the Reese's Peanut Butter Cup Sundae, and Reese's Pieces Sundae."], "decomposition": ["What is E.T. the Extra-Terrestrial's favorite food?", "Does Friendly's serve dishes made with #1?"], "evidence": [[[["E.T. the Extra-Terrestrial-6"]], [["Friendly's-4", "Reese's Pieces-1"]]], [[["E.T. the Extra-Terrestrial-6"]], [["Friendly's-1"], "no_evidence", "operation"]], [[["E.T. the Extra-Terrestrial-6"]], ["no_evidence", "operation"]]]}
{"id": 322, "term": "History of art", "description": "history of human creation of works for aesthetic, communicative, or expressive purposes", "question": "Can the history of art be learned by an amoeba?", "answer": false, "facts": ["The history of art is the academic study of the development of human artistic expression over time", "Academic study requires human-level intelligence", "An amoeba is a single-celled organism "], "decomposition": ["What intellectual ability is necessary to study the history of art?", "Does an amoeba possess #1?"], "evidence": [[[["Human brain-66", "Human brain-67"]], [["Amoeba-1", "Cell (biology)-1", "Cell (biology)-16"], "operation"]], [[["Learning-1"], "no_evidence"], [["Amoeba-1"], "no_evidence", "operation"]], [[["Art history-6"]], [["Amoeba-25"]]]]}
{"id": 753, "term": "Julia Roberts", "description": "American actress and producer", "question": "Does Julia Roberts lose the prolific acting contest in her family?", "answer": true, "facts": ["As of May 2020, Julia Roberts has acted in 64 projects.", "Julia Roberts has a brother in acting, Eric Roberts, and a niece in acting, Emma Roberts.", "As of May 2020, Eric Roberts has acted in 577 projects."], "decomposition": ["Who is Julia Roberts brother?", "Is #1 an actor?", "How many projects has #2 appeared in?", "How many projects has Julia Roberts acted in?", "Is #3 larger than #4?"], "evidence": [[[["Julia Roberts-4"]], [["Eric Roberts-1"]], [["Eric Roberts-2"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Eric Roberts-1"]], [["Eric Roberts-1"]], [["Eric Roberts filmography-4"], "no_evidence"], [["Julia Roberts-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Eric Roberts-3"]], [["Eric Roberts-1"]], [["Eric Roberts-2"]], [["Julia Roberts filmography-1"], "no_evidence"], ["operation"]]]}
{"id": 626, "term": "Cucumber", "description": "species of plant", "question": "Is growing seedless cucumber good for a gardener with entomophobia?", "answer": true, "facts": ["Seedless cucumber fruit does not require pollination", "Cucumber plants need insects to pollinate them", "Entomophobia is a fear of insects"], "decomposition": ["What are people with Entomophobia fearful of?", "How do #1's usually help in the process of gardening?", "Do seedless cucumbers not require #2?"], "evidence": [[[["Entomophobia-1"]], [["Pollination-4"]], [["Cucumber-3"], "operation"]], [[["Entomophobia-1"]], [["Pollination-1"], "no_evidence"], [["Cucumber-3"], "operation"]], [[["Entomophobia-1"]], [["Cucumber beetle-1"]], [["Cucumber-4"], "operation"]]]}
{"id": 604, "term": "Goldstone Deep Space Communications Complex", "description": "United States historic place", "question": "Do the telescopes at Goldstone Deep Space Communications Complex work the night shift?", "answer": true, "facts": ["The night shift is considered to be the hours of 11pm - 7am.", "The telescopes at Goldstone Deep Space Communications Complex are running 24 hours a day."], "decomposition": ["What hours are typically considered the night shift?", "What hours do the telescopes at Goldstone Deep Space Communications Complex run?", "Is there any overlap between #1 and #2?"], "evidence": [[[["Shift work-11"]], [["Goldstone Deep Space Communications Complex-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Shift work-11"], "no_evidence"], ["no_evidence"], ["operation"]], [["no_evidence"], [["Astronomy-2", "Goldstone Deep Space Communications Complex-1"], "no_evidence"], ["no_evidence"]]]}
{"id": 782, "term": "Radioactive waste", "description": "wastes that contain nuclear material", "question": "Does the United States Navy create radioactive waste?", "answer": true, "facts": ["Radioactive waste is created by nuclear material processing", "The United States Navy uses many nuclear submarines"], "decomposition": ["Radioactive waste is a byproduct of what process?", "Does the US Navy engage in any of the activities in #1?"], "evidence": [[[["Radioactive waste-1"]], [["Nuclear submarine-4"]]], [[["Radioactive waste-1"]], [["United States Navy Nuclear Propulsion-1"], "operation"]], [[["Radioactive waste-1"]], [["United States Navy-5"], "no_evidence", "operation"]]]}
{"id": 597, "term": "Brake", "description": "mechanical device that inhibits motion", "question": "Can people die from brake failure?", "answer": true, "facts": ["Brake failure is the inability of brakes to function.", "When vehicles experience brake failure, they cannot be stopped safely, which results in a crash.", "People die in vehicular crashes."], "decomposition": ["What is a brake failure?", "What can #1 lead to in a car?", "Have people died from #2?"], "evidence": [[[["Disc brake-63"]], [["Traffic collision-1", "Traffic collision-50"]], [["Falco (musician)-22"], "operation"]], [[["Brake-1"], "no_evidence"], [["Traffic collision-1", "Traffic collision-24"], "no_evidence"], [["Traffic collision-3"], "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence"]]]}
{"id": 829, "term": "Rick and Morty", "description": "Animated sitcom", "question": "Can you watch Rick and Morty in Mariana Trench?", "answer": true, "facts": ["Rick and Morty is available in blu-ray format.", "You can play blu-ray on a laptop computer ", "It is possible to go to Mariana Trench inside a deep-diving submersible vehicle with a laptop."], "decomposition": ["What portable media format is Rick and Morty available in?", "What electronics do deep-diving submersibles have?", "Can any of #1 be played on any of #2?"], "evidence": [[[["Rick and Morty-28"]], [["Deep-submergence vehicle-1"], "no_evidence"], ["operation"]], [[["Rick and Morty-27"]], [["DVD player-1", "Submersible-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Rick and Morty-28"]], [["Deep diving-11"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 4, "term": "Double-slit experiment", "description": "Physics experiment, showing light can be modelled by both waves and particles", "question": "Can a minor replicate the double-slit experiment?", "answer": true, "facts": ["A minor is a human child.", "The double-slit experiment can theoretically be replicated by any human."], "decomposition": ["What species of living things does 'minor' refer to?", "Can #1 replicate the double-slit experiment?"], "evidence": [[[["Minor (law)-1"]], [["Double-slit experiment-2"]]], [[["Minor (law)-1"]], [["Double-slit experiment-1"], "operation"]], [[["Age of majority-1"]], [["Double-slit experiment-2"], "operation"]]]}
{"id": 308, "term": "Giraffe", "description": "Tall African ungulate", "question": "Is it foolish to stand on giraffe's head to see over Eiffel Tower?", "answer": true, "facts": ["The neck of a giraffe can be up to 7 feet in length.", "Including their necks, giraffes can be as tall as 20 feet.", "The Eiffel Tower is 1,063 feet tall."], "decomposition": ["How tall is a giraffe?", "How tall is the Eiffel Tower?", "Is #1 greater than #2?"], "evidence": [[[["Giraffe-16"]], [["Eiffel Tower-3"]], ["operation"]], [[["Giraffe-16"]], [["Eiffel Tower-3"]], ["operation"]], [[["Giraffe-16"]], [["Eiffel Tower-3"]], ["operation"]]]}
{"id": 99, "term": "March", "description": "third month in the Julian and Gregorian calendars", "question": "Is March named after Jupiter's son in Roman mythology?", "answer": true, "facts": ["March is named after the Roman god Mars.", "Mars was the son of the Roman gods Jupiter and Juno."], "decomposition": ["Who are the sons of Jupiter in Roman mythology?", "Who is the month of March named after?", "Is #2 included in #1?"], "evidence": [[[["Hercules-1", "Mars (mythology)-1", "Vulcan (mythology)-41"]], [["March-1"]], ["operation"]], [[["Jupiter (mythology)-106"]], [["Apollo-25"], "no_evidence"], ["operation"]], [[["Mars (mythology)-7"]], [["Martius (month)-1"]], ["operation"]]]}
{"id": 552, "term": "B", "description": "letter in the Latin alphabet", "question": "Could B be mistaken for an Arabic numeral?", "answer": true, "facts": ["The letter 'B' resembles a figure-8 with a flattened left side.", "The Arabic numeral '8' is drawn as one large circle and a smaller circle immediately on top, intersecting each other. ", "A 'figure-8' is a shape consisting of two intersecting circles, the larger on the bottom."], "decomposition": ["Which figure is the letter B similar in appearance to?", "Is #1 an Arabic numeral?"], "evidence": [[[["8-1", "B-1"]], [["Arabic numerals-1"], "operation"]], [[["B-1", "Beta-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Bet (letter)-3"], "no_evidence"], ["no_evidence"]]]}
{"id": 150, "term": "Mayor", "description": "head of municipal government such as a town or city", "question": "Are Mayors safe from harm from the federal government?", "answer": false, "facts": ["The Mayor of Portland is Ted Wheeler.", "Ted Wheeler was tear-gassed by federal troops sent to his state."], "decomposition": ["Who is the mayor of Portland?", "Has #1 been able to avoid harm when federal troops were sent to his state"], "evidence": [[[["Ted Wheeler-1"]], ["no_evidence", "operation"]], [[["Government of Portland, Oregon-3"], "no_evidence"], ["no_evidence"]], [[["Ted Wheeler-1"]], ["no_evidence"]]]}
{"id": 192, "term": "The Matrix", "description": "1999 science fiction action film directed by the Wachowskis", "question": "Was Harry Potter a better investment than The Matrix for Warner Bros.?", "answer": true, "facts": ["Warner Bros. distributes several movie franchises including The Matrix, Harry Potter, and The Dark Knight.", "The Matrix had 2 sequels.", "Harry Potter had 7 sequels and several spin-offs.", "Harry Potter and the Deathly Hallows – Part 2 is Warner Bros. highest grossing film worldwide with a box office gross of $1,342,932,398."], "decomposition": ["How much did the Harry Potter (film series) gross?", "How much did the The Matrix (franchise) gross?", "Is #1 greater than #2?"], "evidence": [[[["Harry Potter (film series)-4"]], [["The Matrix (franchise)-4"]], ["operation"]], [[["Harry Potter (film series)-4"]], [["The Matrix (franchise)-4"]], ["operation"]], [[["Harry Potter-3"], "no_evidence"], [["The Matrix-36"]], ["operation"]]]}
{"id": 333, "term": "Chiropractic", "description": "form of alternative medicine", "question": "Are some chiropractic manipulations dangerous?", "answer": true, "facts": ["Manipulations of the neck can lead to complications such as stroke or paralysis.", "Manipulation of the lower back can lead to herniated disks."], "decomposition": ["What body parts do chiropractors manipulate?", "Are any of #1 prone to damage if mishandled?"], "evidence": [[[["Chiropractic-18"]], [["Chiropractic controversy and criticism-34"]]], [[["Chiropractic-1"]], ["operation"]], [[["Chiropractic-1"]], [["Chiropractic-2"], "operation"]]]}
{"id": 330, "term": "Supreme Court of the United States", "description": "Highest court in the United States", "question": "Do members of the Supreme Court of the United States have longer terms than most senators?", "answer": true, "facts": ["Senators, on average, serve for 10 years.", "Supreme Court Justices serve for their entire life.", "The average term for a Supreme court justice is 16 years."], "decomposition": ["How many years is in a term for a U.S. Senator?", "What is the term for a Supreme Court justice?", "Is #1 a shorter term than #2?"], "evidence": [[[["United States Senate-2"]], [["Supreme Court of the United States-31"]], ["operation"]], [[["United States Senate-16"]], [["Supreme Court of the United States-2"]], ["operation"]], [[["Member of Congress-3"]], [["Supreme Court of the United States-2"]], ["operation"]]]}
{"id": 119, "term": "Mail carrier", "description": "employee of the post office or postal service, who delivers mail to residences and businesses", "question": "Was being a mail carrier considered one of the most dangerous jobs?", "answer": true, "facts": ["The Pony Express was one of the first mail carrier services.", "The Pony Express operated form 1860 to 1861", "Pony Express riders would have to travel hundreds of miles on horse back through extreme weather and terrain. ", "The Pony Express sought to hire young expert horse riders willing to risk death."], "decomposition": ["What was the name of the mail carrier service that operated from 1860 to 1861?", "What would riders on #1 have to endure?", "Is #2 considered very dangerous?"], "evidence": [[[["Pony Express-1"]], [["Pony Express-31"]], ["operation"]], [[["Pony Express-1"]], [["Pony Express-38", "Pony Express-40"], "no_evidence"], ["operation"]], [[["Pony Express-1"]], [["Pony Express-30", "Pony Express-31"]], [["Pony Express-30", "Pony Express-31"]]]]}
{"id": 295, "term": "Pyrenees", "description": "Range of mountains in southwest Europe", "question": "Can an elite runner circle the Pyrenees in one day?", "answer": false, "facts": ["The Pyrenees mountains are 305 miles wide.", "An elite runner can cover 100 miles in around 12 hours."], "decomposition": ["How many miles can an elite runner cover in one day?", "How far around in miles are The Pyrenees mountains?", "Is #1 more than #2?"], "evidence": [[[["Usain Bolt-106"]], [["Pyrenees-13"], "no_evidence"], ["operation"]], [[["Ultramarathon-9"], "no_evidence"], [["Pyrenees-1"], "no_evidence"], ["operation"]], [[["How Many Miles to Babylon?-7"], "operation"], ["no_evidence"], ["no_evidence"]]]}
{"id": 312, "term": "Cream", "description": "Dairy product", "question": "Would Kylee Jenner ask for no cream in her coffee?", "answer": true, "facts": ["Kylee Jenner is lactose intolerant.", "Lactose intolerance makes it uncomfortable for people to digest foods containing lactose.", "Cream is a dairy product and is rich in lactose."], "decomposition": ["What dietary condition does Kylee (Kylie) Jenner suffer from?", "What do people who have #1 have to avoid?", "Does cream have #2 in it?"], "evidence": [[["no_evidence"], [["Lactose intolerance-1"]], [["Cream-1"], "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence"]], [[["Kylie Jenner-1"]], [["Lactose intolerance-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 583, "term": "Solubility", "description": "Capacity of a designated solvent to hold a designated solute in homogeneous solution under specified conditions", "question": "Does Nigella Lawson care about solubility?", "answer": true, "facts": ["Nigella Lawson is a chef", "Chefs are concerned with cooking processes and nutrition", "Solubility plays a role in both the chemistry of cooking processes as well as the body's interaction with substances that it ingests"], "decomposition": ["What is Nigella Lawson's major occupation?", "What kind of substances and processes is the concept of solubility applicable to?", "What kind of substances and processes are of importance to #1?", "Are any of #2 included in #3?"], "evidence": [[[["Nigella Lawson-1"]], [["Solubility-1"], "no_evidence"], [["Cooking-34"], "no_evidence"], ["operation"]], [[["Nigella Lawson-1"]], [["Solubility-1"]], [["Cooking-17"]], ["operation"]], [[["Nigella Lawson-1"]], [["Solubility-1"], "no_evidence"], [["Cooking-14"], "no_evidence"], ["operation"]]]}
{"id": 586, "term": "Penny", "description": "unit of currency in various countries", "question": "Are pennies commonly used in Canada?", "answer": false, "facts": ["Canada used pennies historically as one cent coins.", "Canada stopped minting pennies in 2012. "], "decomposition": ["What coins are used in Canada?", "Are pennies among #1?"], "evidence": [[[["Canadian dollar-16"]], ["operation"]], [[["Coins of the Canadian dollar-2"]], [["Coins of the Canadian dollar-2"]]], [[["Canadian dollar-16"]], ["operation"]]]}
{"id": 202, "term": "Israelis", "description": "Ethnic group", "question": "Have the Israelis played the Hammerstein Ballroom?", "answer": false, "facts": ["The Israelis are an ethnic group", "The Hammerstein Ballroom is a venue for concerts and musical performances"], "decomposition": ["What kind of groups play in the Hammerstein Ballroom?", "What kind of a group is the Israelis?", "Is #2 included in #1?"], "evidence": [[[["Hammerstein Ballroom-1", "Hammerstein Ballroom-4"]], [["Israelis-1"]], ["operation"]], [[["Hammerstein Ballroom-4"]], [["Israelis-4"]], ["operation"]], [[["Hammerstein Ballroom-1"]], [["Israelis-1"]], ["operation"]]]}
{"id": 862, "term": "Hyphen", "description": "Punctuation mark used to join words", "question": "Is Olivia Newton-John hyphenated celebrity name with most letters?", "answer": false, "facts": ["Olivia Newton-John has sixteen letters in her name.", "Actress Catherine Zeta-Jones has 18 letters in her name.", "Actor Joseph Gordon-Levitt has 18 letters in his name."], "decomposition": ["How many letters are in the name Olivia Newton-John?", "How many letters are in the name Catherine Zeta-Jones?", "How many letters are in the name Joseph Gordon-Levitt?", "Is #1 greater than both #2 and #3?"], "evidence": [[["operation"], ["operation"], ["operation"], [["Letter (alphabet)-3"], "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Olivia Newton-John-46"], "no_evidence"], [["Catherine Zeta-Jones-8"], "no_evidence"], [["Joseph Gordon-Levitt-5"], "no_evidence"], ["no_evidence"]]]}
{"id": 951, "term": "Lapidary", "description": "gemstone cutter", "question": "Does a lapidary work with items that are studied by geologists?", "answer": true, "facts": ["Some of the things geologists study include gemstones, minerals, and stone", "Lapidarists work with stone, minerals and gemstones"], "decomposition": ["What are the materials a lapidary works with?", "What do geologists study?", "Is any of #1 derived from #2?"], "evidence": [[[["Lapidary-1"]], [["Geologist-9"]], ["operation"]], [[["Lapidary-1"]], [["Geology-1"]], ["operation"]], [[["Lapidary-1"]], [["Geology-1"]], ["operation"]]]}
{"id": 17, "term": "Olympia, Washington", "description": "State capital and city in Washington, United States", "question": "Does Olympia Washington share name with Hephaestus's workshop location?", "answer": true, "facts": ["Olympia Washington, is named after Mount Olympus.", "Mount Olympus is a mountain range in Washington named after the ancient Greek Mount Olympus.", "Hephaestus was the ancient Greek god of the forge and had a workshop on Mount Olympus."], "decomposition": ["Where did Hephaestus have his workshop?", "Olympia, Washington derived it's name from what mountain?", "Is #2 the same as #1?"], "evidence": [[[["Hephaestus-5"]], [["Olympia, Washington-3"]], ["operation"]], [[["Hephaestus-2"]], [["Mount Olympus-1"]], ["operation"]], [[["Hephaestus-5"], "operation"], [["Hephaestus-5"], "operation"], ["operation"]]]}
{"id": 745, "term": "Super Mario", "description": "platform video game series from Nintendo's Mario franchise", "question": "Does Super Mario require electricity to play?", "answer": true, "facts": ["Super Mario is a video game.", "Video games are played on electronic devices.", "Electronic devices require electricity to function."], "decomposition": ["What is Super Mario?", "Where are #1 played?", "Do #2 require electricity?"], "evidence": [[[["Super Mario-1"]], [["Nintendo video game consoles-1"]], [["Nintendo video game consoles-1"]]], [[["Super Mario-1"]], [["Nintendo Entertainment System-2"]], [["Nintendo Entertainment System-12"], "operation"]], [[["Super Mario-1"]], [["Super Mario-1", "Video game console-3"]], [["Video game console-3"]]]]}
{"id": 592, "term": "Frost", "description": "coating or deposit of ice that may form in humid air in cold conditions, usually overnight", "question": "Would it be unusual to see frost in September in Texas?", "answer": true, "facts": ["Texas is a Southern state of the United States, known for high heat.", "On average, Texas is between 68 and 89 degrees during the month of September.", "Frost forms at 32 degrees or lower."], "decomposition": ["What are the average temperatures in Texas during the month of September?", "What temperature does frost form at?", "Is #1 warmer than #2?"], "evidence": [[[["Climate of Dallas-3"], "no_evidence"], [["Frost (temperature)-1", "Frost-1"]], ["operation"]], [[["Texas-29", "Texas-30", "Texas-31"]], [["Dew point-1", "Frost-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Climate of Texas-3"], "no_evidence"], [["Dew point-1", "Frost-20", "Frost-5"]], ["operation"]]]}
{"id": 993, "term": "Breast cancer", "description": "cancer that originates in the mammary gland", "question": "Are amoebas safe from breast cancer?", "answer": true, "facts": ["Breast cancer is a disease that occurs in the mammary tissues of mammals.", "Amoebas are single cell organisms that lack mammary tissue."], "decomposition": ["What tissue does breast cancer affect?", "Is having #1 a necessary condition for breast cancer?", "By #2, is it the case that if an organism lacks #1 they cannot get breast cancer?"], "evidence": [[[["Breast cancer-1"]], [["Breast cancer-2"]], [["Breast cancer-2"]]], [[["Breast cancer-1"]], ["operation"], ["operation"]], [[["Breast cancer-2"]], [["Breast cancer-8"]], ["operation"]]]}
{"id": 872, "term": "Pelvis", "description": "lower part of the trunk of the human body between the abdomen and the thighs (sometimes also called pelvic region of the trunk", "question": "Is cycling a high-risk activity for pelvis fractures?", "answer": false, "facts": ["Cycling is a low-impact activity ", "Stress fractures in a pelvic bone often develop as a result of repetitive, high-impact activity that puts stress on the pelvis, such as long-distance running or ballet"], "decomposition": ["What type of activity can result in stress fractures?", "Would cycling be considered #1?"], "evidence": [[[["Stress fracture-6"]], [["Stationary bicycle-7"], "no_evidence", "operation"]], [[["Stress fracture-1"]], ["operation"]], [[["Pelvic fracture-20"]], ["operation"]]]}
{"id": 102, "term": "J. D. Salinger", "description": "American writer", "question": "Is J.D. Salinger's most successful work influential to killers?", "answer": true, "facts": ["J.D. Salinger's most popular work was Catcher in the Rye.", "John Hinckley Jr. tried to assassinate Ronald Reagan after reading Catcher in the Rye.", "Mark David Chapman had a copy of Catcher in the Rye when he assassinated John Lennon.", "Robert John Bardo carried a copy of Catcher in the Rye when he murdered actress Rebecca Schaeffer."], "decomposition": ["Which of J.D. Salinger's novels was most popular?", "has #1 been associated with inspiring murder?"], "evidence": [[[["J. D. Salinger-1"]], [["The Catcher in the Rye-26"]]], [[["J. D. Salinger-1"]], [["The Catcher in the Rye-26"]]], [[["J. D. Salinger-1"]], [["The Catcher in the Rye-26"]]]]}
{"id": 263, "term": "Common warthog", "description": "Wild member of the pig family", "question": "Could common warthog be useful for scrimshaw?", "answer": true, "facts": ["Scrimshaw is the process of carving designs or symbols into materials such as ivory, whalebone, and tusks.", "The common warthog has two sets of long tusks.", "The common warthog has large teeth that are harnessed for ivory.", "The common warthog is not an endangered species."], "decomposition": ["What materials can be used in scrimshaw?", "Do warthogs have any of the things in #1?"], "evidence": [[[["Scrimshaw-1"]], [["Phacochoerus-2"], "operation"]], [[["Scrimshaw-1"]], [["Phacochoerus-2"]]], [[["Scrimshaw-1"]], [["Common warthog-3"]]]]}
{"id": 377, "term": "Markhor", "description": "species of mammal", "question": "Could a markhor give birth three times in a single year?", "answer": false, "facts": ["The gestation period of a markhor lasts 135–170 days.", "There are 365 days in a year."], "decomposition": ["What is the gestation period of a Markhor?", "How many days are in a year?", "Can #1 be divided into #2 at least 3 times"], "evidence": [[[["Markhor-6"]], [["Calendar year-2"]], [["Calendar year-2", "Markhor-6"], "operation"]], [[["Markhor-6"]], [["Year-3"]], ["operation"]], [[["Markhor-6"]], [["Year-3"]], ["operation"]]]}
{"id": 731, "term": "Kurt Cobain", "description": "American singer, composer, and musician", "question": "Did Kurt Cobain's music genre survive after his death?", "answer": true, "facts": ["Kurt Cobain was the lead singer of Nirvana.", "Nirvana's music is classified as Grunge rock.", "Kurt Cobain died on April 5, 1994.", "Some of the major Grunge rock bands included Alice in Chains, Pearl Jam, and Soundgarden.", "Alice in Chains and Pearl Jam released their latest albums in 2018 and 2020 respectively."], "decomposition": ["What is the musiucal genre associated with both Kurt Cobain and Pearl Jam?", "What year did Kurt Cobain die? ", "Did Pearl Jam release a #1 genre album after #2?", "Is #3 yes?"], "evidence": [[[["Grunge-2"]], [["Kurt Cobain-1"]], [["No Code-1"]], [["No Code-1"]]], [[["Kurt Cobain-2", "Pearl Jam-2"]], [["Kurt Cobain-55"]], [["Vitalogy-9"], "no_evidence"], ["operation"]], [[["Grunge-2"]], [["Kurt Cobain-1"]], [["Lightning Bolt (Pearl Jam album)-11"]], ["operation"]]]}
{"id": 512, "term": "Friday", "description": "day of the week", "question": "Does 2015 have more unlucky Friday's than usual?", "answer": true, "facts": ["Friday the 13th is known as an unlucky Friday because of the number 13.", "A year can have as many as three Friday the 13ths.", "One Friday the 13th is the average per year.", "There were 3 Friday the 13ths in 2015."], "decomposition": ["How many Friday the 13ths were in 2015?", "What is the usual number of Friday the 13ths per year?", "Is #1 more than #2?"], "evidence": [[[["Friday the 13th-1"]], [["Friday the 13th-1"]], ["operation"]], [[["Friday the 13th-1"]], [["Friday the 13th-1"]], ["operation"]], [[["Friday the 13th-25"]], [["Friday the 13th-1"]], ["operation"]]]}
{"id": 675, "term": "Florence", "description": "Capital and most populous city of the Italian region of Tuscany", "question": "Was Florence a Theocracy during Italian Renaissance?", "answer": true, "facts": ["The Italian Renaissance was a period of history from the 13th century to 1600.", "A theocracy is a type of rule in which religious leaders have power.", "Friar Girolamo Savonarola was the ruler of Florence, after driving out the Medici family, from November 1494 – 23 May 1498."], "decomposition": ["When was the Italian Renaissance?", "When did Friar Girolamo Savonarola rule Florence?", "Is #2 within the span of #1?", "Did Friar Girolamo Savonarola belong to a religious order during #3?"], "evidence": [[[["Italian Renaissance-1"]], [["Girolamo Savonarola-1"], "no_evidence"], ["operation"], [["Girolamo Savonarola-1"]]], [[["Italian Renaissance-1"]], [["Republic of Florence-38", "Republic of Florence-39", "Republic of Florence-40"]], ["operation"], [["Girolamo Savonarola-1"], "operation"]], [[["Italian Renaissance-1"]], [["Girolamo Savonarola-2", "Girolamo Savonarola-3"]], ["operation"], [["Dominican Order-1", "Girolamo Savonarola-1"], "operation"]]]}
{"id": 352, "term": "Elon Musk", "description": "American industrialist and investor", "question": "Has Elon Musk's hairline changed?", "answer": true, "facts": ["When Elon Musk was much younger, he was clearly balding.", "Elon Musk does not show any signs of balding as of 2020."], "decomposition": ["What feature of Elon Musk's hair was notable when he was younger?", "Is #1 no longer observable in present times?"], "evidence": [[[["Elon Musk-5"], "no_evidence"], ["no_evidence", "operation"]], [[["Elon Musk-1"], "no_evidence"], [["Hair loss-4"], "no_evidence", "operation"]], [["no_evidence"], ["no_evidence"]]]}
{"id": 318, "term": "Bulk carrier", "description": "merchant ship specially designed to transport unpackaged bulk cargo", "question": "Is the average bulk carrier ideal for transporting bromine at room temperature?", "answer": false, "facts": ["Bulk carriers are defined as a ship that carries nonliquid cargoes such as grain or ore in bulk.", "Bromine is a liquid at room temperature.", "The average bulk carrier is used for unpackaged bulk cargo, such as grains, coal, ore, steel coils and cement."], "decomposition": ["What are the kinds of cargo that a typical bulk carrier can transport?", "What kind of substance is bromine at room temperature?", "Can any of #1 be classified as #2?"], "evidence": [[[["Bulk carrier-1"]], [["Bromine-1"]], ["operation"]], [[["Bulk carrier-4"], "operation"], [["Bromine-26"]], ["no_evidence"]], [[["Bulk carrier-1"]], [["Bromine-1"]], ["operation"]]]}
{"id": 149, "term": "Red panda", "description": "Mammal of the family Ailuridae", "question": "Is it normal to see a red panda in Shanghai outside of a zoo?", "answer": false, "facts": ["The red panda is endemic to the temperate forests of the Himalayas, and ranges from the foothills of western Nepal to China in the east.", "The red panda lives between 2,200 and 4,800 m (7,200 and 15,700 ft) altitude, inhabiting areas of moderate temperature between 10 and 25 °C (50 and 77 °F) with little annual change.", "Shanghai is located on an alluvial plain, as such the vast majority of its land area is flat, with an average elevation of 4 m (13 ft)."], "decomposition": ["At what elevations are red pandas found?", "What is the elevation of Shanghai?", "Is there an overlap between #1 and #2?"], "evidence": [[[["Red panda-7"]], [["Shanghai-27"]], ["operation"]], [[["Red panda-8"], "no_evidence"], [["Shanghai-27"], "no_evidence"], ["no_evidence", "operation"]], [[["Red panda-7"]], [["Shanghai-27"]], ["operation"]]]}
{"id": 985, "term": "Second Coming", "description": "Christian and Islamic belief regarding the future (or past) return of Jesus after his ascension", "question": "Does Woody Allen await the Second Coming?", "answer": false, "facts": ["The Second Coming refers to Jesus Christ returning to earth", "Christians and Muslims believe in Jesus Christ", "Woody Allen is Jewish"], "decomposition": ["Which religious groups believe in the second coming?", "Does Woody Allen belong to any of #1?"], "evidence": [[[["Second Coming-1"]], [["Woody Allen-4"], "operation"]], [[["Second Coming-1"]], ["no_evidence", "operation"]], [[["Second Coming-1"]], [["Woody Allen-4"]]]]}
{"id": 243, "term": "Maize", "description": "Cereal grain", "question": "Did Demi Lovato's ancestors help turn maize into popcorn?", "answer": true, "facts": ["Demi Lovato's father is Mexican.", "Maize is another word for corn.", "Corn was first domesticated in southern Mexico about 10,000 years ago.", "Popcorn is made from kernels of corn."], "decomposition": ["Where is popcorn from originally?", "Where is Demi Lovato's ancestors from?", "Are #1 and #2 the same?"], "evidence": [[[["Popcorn-5"]], [["Demi Lovato-5"]], ["operation"]], [[["Popcorn-5"]], [["Demi Lovato-5"]], ["operation"]], [[["Popcorn-5"]], [["Demi Lovato-5"]], ["operation"]]]}
{"id": 382, "term": "Scottish people", "description": "ethnic inhabitants of Scotland", "question": "Does the Pixar film Brave feature Scottish people?", "answer": true, "facts": ["The movie Brave is set in the Scottish highlands.", "Merida, the main character of Brave, is a Princess of Medieval Scotland "], "decomposition": ["Who are the main characters of the Pixar film Brave?", "Are any of #1 from Scotland?"], "evidence": [[[["Brave (2012 film)-4"]], ["operation"]], [[["Brave (2012 film)-4"]], [["Brave (2012 film)-4"], "operation"]], [[["Brave (2012 film)-1", "Brave (2012 film)-4"]], ["operation"]]]}
{"id": 936, "term": "French toast", "description": "bread soaked in beaten eggs and then fried", "question": "Can French Toast hypothetically kill a Lannister?", "answer": true, "facts": ["The Lannister's are a wealthy family in the Song of Ice and Fire book series.", "French Toast is made from bread dipped in an egg batter.", "Salmonella is a deadly bacteria that can be carried by spoiled eggs."], "decomposition": ["What are the ingredients in French toast?", "Which things in #1 can spoil?", "What diseases can be carried by spoiled #2?", "What species are susceptible to #3?", "Are the Lannisters members of a species listed in #4?"], "evidence": [[[["French toast-1"]], [["Egg as food-35"]], [["Salmonella enterica-3"]], [["Salmonella-18"]], [["World of A Song of Ice and Fire-44"], "operation"]], [[["French toast-1"]], [["French toast-1"]], [["Dairy-58"], "no_evidence"], [["Raw milk-14"], "no_evidence"], [["World of A Song of Ice and Fire-44"], "no_evidence", "operation"]], [[["French toast-7"]], [["Milk-118"]], [["Foodborne illness-6"]], [["Foodborne illness-31"]], [["Game of Thrones-10"], "operation"]]]}
{"id": 815, "term": "Gettysburg Battlefield", "description": "site of the Battle of Gettysburg during the American Civil War", "question": "Would a Superbowl Football Game be crowded on the Gettysburg Battlefield?", "answer": false, "facts": ["Football fields used in the Super Bowl are 100 yards long. ", "The Gettysburg Battlefield is over 5 miles long.", "There are 1760 yards in a mile."], "decomposition": ["How long is the football field superbowl?", "How long is the Gettysburg Battlefield?", "Is #1 the same as #2?"], "evidence": [[[["Comparison of American football and rugby league-6"]], [["Gettysburg Battlefield-2"]], ["operation"]], [[["Football pitch-4"]], [["Gettysburg Battlefield-2"]], ["operation"]], [[["American football-11"]], [["Gettysburg Battlefield-1"], "no_evidence"], ["operation"]]]}
{"id": 445, "term": "Foot (unit)", "description": "customary unit of length", "question": "When en route from China to France, must pilots know their altitude in the imperial foot?", "answer": true, "facts": ["Most international airports and aviators use the foot to measure altitude ", "China and North Korea require pilots to use meters for altitude", "Pilots must communicate their altitude with local air traffic control "], "decomposition": ["Which unit of altitude does France require pilots to use?", "Which unit of altitude does China require pilots to use?", "Is #1 or #2 the imperial foot?"], "evidence": [[[["Foot (unit)-2"]], [["Foot (unit)-2"]], ["operation"]], [[["Foot (unit)-26"], "no_evidence"], [["Foot (unit)-3"]], ["operation"]], [[["Foot (unit)-3"], "no_evidence"], [["Foot (unit)-3"], "no_evidence"], ["operation"]]]}
{"id": 42, "term": "Gorilla", "description": "Genus of mammals", "question": "Are gorillas closely related to humans?", "answer": true, "facts": ["Gorillas are part of the animal family Hominidae.", "Hominidae also includes the genus Homo, which only contains the human species."], "decomposition": ["What animal family are Gorillas part of?", "Are humans also part of #1?"], "evidence": [[[["Hominidae-1"]], ["operation"]], [[["Gorilla-1"]], [["Primate-2"]]], [[["Hominidae-1"]], [["Hominidae-1"]]]]}
{"id": 973, "term": "Mona Lisa", "description": "Painting by Leonardo da Vinci", "question": "After viewing the Mona Lisa, could you get lunch nearby on foot?", "answer": true, "facts": ["The Mona Lisa is housed in The Louvre.", "There are many restaurants within walking distance of The Louvre."], "decomposition": ["Where is the Mona Lisa located?", "Is #1 a place likely to have at least a restaurant/hotel nearby?"], "evidence": [[[["Mona Lisa-54"]], [["Louvre-60"]]], [[["Mona Lisa-29"]], [["Louvre-60"]]], [[["Louvre-1", "Mona Lisa-2"]], ["operation"]]]}
{"id": 969, "term": "Chinese Americans", "description": "Ethnic group", "question": "Do Chinese Americans face discrimination at a Federal level in the US?", "answer": true, "facts": ["The President of the United States frequently referred to the COVID-19 pandemic as a 'Chinese Virus' and 'Kung Flu', encouraging the use of derogatory language towards Chinese Americans.", "The President of the United States has not called for the violence and hate towards Chinese Americans in response to COVID-19 to end."], "decomposition": ["Who is the head of the US Federal Government?", "Does #1 behave in a discriminatory way toward Chinese Americans?"], "evidence": [[[["Federal government of the United States-17"]], [["Anti-Chinese sentiment in the United States-28"], "no_evidence"]], [[["Donald Trump-1"]], [["Donald Trump-128"], "no_evidence", "operation"]], [[["Donald Trump-1"]], [["Donald Trump-128", "Donald Trump-154"], "operation"]]]}
{"id": 861, "term": "Godzilla", "description": "Giant monster or kaiju", "question": "Is Godzilla's image likely grounds for a lawsuit in 2050?", "answer": false, "facts": ["The copyright for Godzilla is owned by Toho Company Limited.", "The first Godzilla film was released by Toho in 1954.", "Works that are significantly old enter the public domain and can be used without copyright permission.", "Godzilla will enter the public domain in the year 2049."], "decomposition": ["When can a copyrighted item be used without permission?", "In what year will Godzilla as a creative piece of work attain #1 status?", "Is #2 after 2050?"], "evidence": [[[["Copyright term-2"]], ["operation"], ["operation"]], [[["Copyright-4"]], [["Godzilla-1", "Tomoyuki Tanaka-1"]], ["operation"]], [[["Public domain-16"]], [["Godzilla-1"], "no_evidence"], ["operation"]]]}
{"id": 120, "term": "Leopard seal", "description": "Species of mammal", "question": "Is Sea World hazardous to leopard seal's health?", "answer": true, "facts": ["Leopard seals have only one natural predator, the killer whale.", "Sea World is an aquatic show that involves many water animals.", "Killer Whales, such as Tilikum, are headliners at Sea World."], "decomposition": ["What is the leopard seals's predator?", "Would one find a #1 at Sea World?"], "evidence": [[[["Leopard seal-1"]], [["Kamogawa Sea World-15"]]], [[["Leopard seal-1"]], [["Shamu-1"], "operation"]], [[["Killer whale-7", "Leopard seal-1"]], [["SeaWorld-1"], "operation"]]]}
{"id": 690, "term": "Jackson Pollock", "description": "American painter", "question": "Were Jackson Pollock's parents not required to say The Pledge of Allegiance as children?", "answer": true, "facts": ["Jackson Pollock's parents were both born and grew up in Tingley, Iowa.", "All states except California, Hawaii, Iowa, Vermont, and Wyoming require a regularly scheduled recitation of the pledge in public schools."], "decomposition": ["What state did Jackson Pollock's parents grow up in?", "What states do not require the pledge to be recited in school?", "Is #1 in the list in #2?"], "evidence": [[[["Jackson Pollock-4"]], [["Pledge of Allegiance-2"]], ["operation"]], [[["Jackson Pollock-4"]], [["Pledge of Allegiance-2"]], ["operation"]], [[["Jackson Pollock-4"]], [["Pledge of Allegiance-2"]], ["operation"]]]}
{"id": 810, "term": "Rice pudding", "description": "Dish made from rice mixed with water or milk", "question": "Would Cyndi Lauper use milk substitute in her rice pudding?", "answer": true, "facts": ["Cyndi Lauper wrote a song about lactose intolerance.", "Lactose intolerance leads to gastrointestinal discomfort upon eating dairy."], "decomposition": ["What conditions lead people to using milk substitutes?", "Does Cyndi Lauper suffer from any conditions listed in #1?"], "evidence": [[[["Lactose intolerance-1", "Veganism-1"]], [["Cyndi Lauper-1"], "no_evidence", "operation"]], [[["Milk allergy-9"]], [["Cyndi Lauper-76"], "no_evidence"]], [[["Milk substitute-17"]], ["no_evidence"]]]}
{"id": 105, "term": "Flying fish", "description": "Family of marine fish that can make powerful, self-propelled leaps out of water", "question": "Do flying fish have good eyesight?", "answer": true, "facts": ["Flying fish  are commonly found in the epipelagic zone, the top layer of the ocean to a depth of about 200 m (656 ft). ", "The epipelagic zone is the illuminated zone at the surface of the sea where enough light is available for photosynthesis. ", "Good eyesight is a necessary survival trait for animals living in well-lit areas."], "decomposition": ["Which layer of the ocean are flying fish usually found?", "What are the lighting conditions characteristic of #1?", "Would good eyesight be necessary for organisms in #2 environment?"], "evidence": [[[["Flying fish-6"]], [["Photic zone-1"]], [["Photic zone-3"], "no_evidence"]], [[["Flying fish-6"]], [["Photic zone-1"]], [["Photic zone-1"], "operation"]], [[["Flying fish-6"]], [["Photic zone-1"]], ["operation"]]]}
{"id": 104, "term": "Justin Bieber", "description": "Canadian singer-songwriter and actor", "question": "Does Justin Bieber vote in October?", "answer": true, "facts": ["Justin Bieber is a Canadian citizen", "Canadian elections are held on the third Monday in October"], "decomposition": ["What country is Justin Bieber a citizen of?", "When does #1 hold its national elections?", "Is #2 October?"], "evidence": [[[["Justin Bieber-1", "Justin Bieber-51"]], [["Fixed election dates in Canada-13"]], ["operation"]], [[["Justin Bieber-1"]], [["Elections in Canada-23"]], ["operation"]], [[["Justin Bieber-1"]], [["Elections in Canada-13"]], ["operation"]]]}
{"id": 749, "term": "Chinese New Year", "description": "traditional Chinese holiday", "question": "Are any mollusks on Chinese New Year calendar?", "answer": false, "facts": ["A mollusk is an invertebrate animal such as snails, slugs, mussles, and octopuses.", "The animals on Chinese New Year calendar are: rat, ox, tiger, rabbit, dragon, snake, horse, goat, monkey, rooster, dog, and pig."], "decomposition": ["What are the animals on the Chinese New Year calendar?", "Is a mollusk part of #1?"], "evidence": [[[["Chinese zodiac-4", "Chinese zodiac-5"]], [["Marine invertebrates-26"], "operation"]], [[["Chinese New Year-6", "Chinese zodiac-17", "Chinese zodiac-18", "Chinese zodiac-19", "Chinese zodiac-20"]], ["operation"]], [[["Chinese zodiac-5"]], ["operation"]]]}
{"id": 834, "term": "Wednesday", "description": "Day of the week", "question": "Will Communion be denied to Wednesday name origin followers?", "answer": true, "facts": ["Communion is the body and blood of Christ given out during mass.", "Communion is only given to believers baptized in the Christian Church.", "Wednesday comes from Old English Wodnesdaeg referring to Woden, also called Odin.", "Odin was the pagan god of Norse mythology.", "Vikings, believers in Norse mythology, clashed with Christians in Wessex and Northumbria for hundreds of years."], "decomposition": ["Which deity is related to the origin of the name 'Wednesday'?", "Who are the worshipers of #1?", "Which group of people are allowed to take the Communion?", "Are #2 included in #3?"], "evidence": [[[["Odin-2"]], [["Odin-2"], "no_evidence"], [["Eucharist-1"]], ["operation"]], [[["Wednesday-1"]], [["Odin-2"]], [["First Communion-1"]], ["operation"]], [[["Wednesday-1"]], [["Anglo-Saxon paganism-1"]], [["Eucharist-1"]], ["operation"]]]}
{"id": 683, "term": "Prophet", "description": "person claiming to speak for divine beings", "question": "Did Disney's second film rip off a prophet story?", "answer": true, "facts": ["Disney's second film, Pinocchio, was released in 1940.", "The biblical prophet Jonah was swallowed by a whale.", "In Pinocchio, Gepetto is swallowed by a giant whale while searching for Pinocchio."], "decomposition": ["What is Disney's second film?", "In #1, what happens to Gepetto while searching for Pinocchio?", "In a biblical prophet, what happens to Jonah?", "Is #2 the same as #3?"], "evidence": [[[["Pinocchio (1940 film)-1"]], [["Pinocchio (1940 film)-9"]], [["Jonah-1"]], ["operation"]], [[["Pinocchio (1940 film)-1"]], [["Pinocchio (1940 film)-9"]], [["Jonah-4"]], ["operation"]], [[["Pinocchio (1940 film)-1"]], [["Pinocchio (1940 film)-9"]], [["Jonah-1"]], ["operation"]]]}
{"id": 780, "term": "Winter", "description": "one of the Earth's four temperate seasons, occurring between autumn and spring", "question": "Is winter associated with hot temperatures?", "answer": false, "facts": ["Winter is the season that occurs when a hemisphere is tilted away from the sun during Earth's orbit.", "During this season, that hemisphere gets less sunshine and is further from the sun than the other hemisphere.", "As a result, temperatures in that hemisphere are much colder during that season."], "decomposition": ["What is earth's primary source of heat energy?", "Which parts of the earth experience winters?", "What is the relative orientation of #2 with respect to #1 during winters?", "Will #3 result in hot temperatures in #2?"], "evidence": [[[["Earth-15"], "no_evidence"], [["Winter-1"]], [["Winter-4"]], ["operation"]], [[["Sun-1"]], [["Winter-1"]], [["Winter-1"]], ["operation"]], [[["The Sun-1"]], [["Winter-8"]], [["Winter-8"]], ["operation"]]]}
{"id": 629, "term": "Al-Farabi", "description": "Philosopher in 10th century Central Asia", "question": "Would ISIS agree with Al-Farabi's religious sect?", "answer": false, "facts": ["The philosopher Al-Farabi was believed to be a Shia Muslim.", "ISIS is an extremist Sunni Muslim group.", "The Sunni and Shia are constantly at war—Sunni often use car bombs, while Shia favor death squads."], "decomposition": ["What religious sect did Al-Farabi belong to?", "What religious sect does ISIS belong to?", "Do #1 and #2 avoid conflict with each other?"], "evidence": [[[["Al-Farabi-11"]], [["Islamic State of Iraq and the Levant-1"]], ["no_evidence", "operation"]], [[["Al-Farabi-11"]], [["Islamic State of Iraq and the Levant-1"]], [["Shia–Sunni relations-4"]]], [[["Al-Farabi-11"], "no_evidence"], [["Islamic State of Iraq and the Levant-64"]], [["Shia–Sunni relations-1"], "operation"]]]}
{"id": 301, "term": "Porch", "description": "a room or gallery at the front entrance of a building forming a low front", "question": "In Hey Arnold, did any characters stay on a porch all the time?", "answer": true, "facts": ["Hey Arnold was an animated children's series.", "Hey Arnold featured 'Stoop Kid', a character who never left the front stoop of his home.", "A stoop is the city equivalent of a porch."], "decomposition": ["Where is 'Stoop Kid' in Hey Arnold known to never leave?", "Is #1 in the series equivalent to a porch in real life?"], "evidence": [[[["Hey Arnold!-7"], "no_evidence"], [["Porch-1", "Stoop (architecture)-1"], "no_evidence", "operation"]], [["no_evidence"], [["Stoop (architecture)-2"]]], [[["Hey Arnold!-1"], "no_evidence"], [["Stoop (architecture)-2"]]]]}
{"id": 676, "term": "Beauty and the Beast", "description": "traditional fairy tale", "question": "Were Beauty and the Beast adaptations devoid of Kurt Sutter collaborators?", "answer": false, "facts": ["Beauty and the Beast is a fairy tale adapted into several movie and TV shows.", "Kurt Sutter created the TV series Sons of Anarchy and The Shield.", "Charlie Hunnam and Ron Perlman starred in Sons of Anarchy.", "Ron Perlman starred in the TV series Beauty and the Beast which aired from 1987-1990."], "decomposition": ["Which characters were featured in Kurt Sutter's Sons of Anarchy and The Shield?", "Which characters were featured in TV series Beauty and the Beast?", "Is there no character common to #1 and #2?"], "evidence": [[[["Clay Morrow-1", "The Shield-1"], "no_evidence"], [["Beauty and the Beast (1987 TV series)-13"]], [["Ron Perlman-1"], "operation"]], [[["Clay Morrow-1"], "no_evidence"], [["Ron Perlman-5"], "no_evidence"], ["operation"]], [[["Ron Perlman-1", "The Shield-1"]], [["Beauty and the Beast (1987 TV series)-1"]], ["operation"]]]}
{"id": 913, "term": "Caracal", "description": "Small wild cat", "question": "Would a caracal be defeated by Javier Sotomayor in a high jump competition?", "answer": false, "facts": ["The caracal can leap higher than 12 feet in the air.", "Javier Sotomayor is the current men's high jump record holder with a jump of 2.45 m (8 ft 1⁄4 in)."], "decomposition": ["How high was Javier Sotomayor's highest jump?", "How high are caracals known to jump?", "Is #1 greater than #2?"], "evidence": [[[["Javier Sotomayor-11"]], [["Caracal-24"]], ["operation"]], [[["Javier Sotomayor-1"]], [["Caracal-2"]], ["operation"]], [[["Javier Sotomayor-1"]], [["Caracal-2"]], ["operation"]]]}
{"id": 103, "term": "Ice", "description": "water frozen into the solid state", "question": "Did Ice make people rich?", "answer": true, "facts": ["Trading ice was common in the 1800s.", "People created industries harvesting and selling ice.", "Some ice sellers became extremely rich. "], "decomposition": ["In the 1800's, what item was commonly traded?", "Did some people become rich off of selling #1?"], "evidence": [[[["Ice trade-1"]], [["Ice trade-10"]]], [[["Ice-48"], "no_evidence"], [["Ice-49"], "operation"]], [[["Ice trade-1"]], [["Ice trade-2"]]]]}
{"id": 54, "term": "Super Mario", "description": "platform video game series from Nintendo's Mario franchise", "question": "Does Super Mario protagonist hypothetically not need continuing education classes in Illinois?", "answer": false, "facts": ["Mario, the protagonist of Super Mario, is a plumber by profession.", "Continuing education classes are required for certain professions in certain jurisdictions.", "Plumbers are required in Illinois to take continuing education classes."], "decomposition": ["Who is the protagonist of Super Mario?", "What is #1's profession? ", "In Illinois, can #2's avoid taking continuing education classes?"], "evidence": [[[["Super Mario-2"]], [["Kill the Plumber-2"]], ["no_evidence", "operation"]], [[["Super Mario Bros.-4"]], ["no_evidence"], [["Plumber-9"], "operation"]], [[["Mario-1"]], [["Mario-1"]], [["Continuing education-9"], "no_evidence", "operation"]]]}
{"id": 238, "term": "Hotel manager", "description": "person managing a hotel", "question": "Could Charlie Bucket be a hotel manager?", "answer": false, "facts": ["Charlie Bucket is a fictional character from \"Charlie and the Chocolate Factory\", portrayed as a child.", "Children cannot be hotel managers."], "decomposition": ["How was Charlie Bucket portrayed in Charlie and the Chocolate Factory?", "Is #1 as an adult?"], "evidence": [[[["Charlie and the Chocolate Factory (film)-6"], "no_evidence"], ["no_evidence"]], [[["Charlie and the Chocolate Factory-4"]], ["operation"]], [[["Charlie and the Chocolate Factory-27"]], [["Boy-1"], "operation"]]]}
{"id": 454, "term": "1980 United States presidential election", "description": "49th quadrennial presidential election in the United States", "question": "Were there greater landslides than 1980 United States presidential election?", "answer": true, "facts": ["A landslide refers to a competitor beating their opponent by a wide margin.", "Ronald Reagan defeated Jimmy carter in the 1980 United States presidential election by around 8 million votes.", "Franklin D. Roosevelt won the 1936 United States presidential election over Alf Landon by more than 11 million votes.", "In 1804 Thomas Jefferson received 162 (92%) of the electoral votes while Charles Cotesworth Pinckney received only 14 (8%)."], "decomposition": ["By what votes margin did Ronald Reagan defeat Jimmy Carter in the 1980 US Presidential election?", "By how many votes was Franklin D. Roosevelt leading Alf Landon in the 1936 US Presidential election?", "How many more votes did Thomas Jefferson receive than Charles Cotesworth Pinckney in the 1804 United States presidential election?", "Are #2 and #3 greater individually than #1?"], "evidence": [[[["Ronald Reagan-50"]], [["Franklin D. Roosevelt-52"]], [["Thomas Jefferson-73"], "no_evidence"], ["operation"]], [[["1980 United States presidential election-50"]], [["1936 United States presidential election-4"]], [["1804 United States presidential election-3", "Thomas Jefferson-73"]], ["operation"]], [[["1980 United States presidential election-4"]], [["1936 United States presidential election-4"]], [["1804 United States presidential election-3"]], ["operation"]]]}
{"id": 472, "term": "Pottery", "description": "Craft of making objects from clay", "question": "Are all types of pottery safe to cook in?", "answer": false, "facts": ["Some types of pottery glaze are unsafe for contact with food meant for human consumption. ", "Antique pottery pieces may have hazardous levels of lead in them."], "decomposition": ["Are all antique or glazed pottery safe to cook in?"], "evidence": [[[["Pottery-35"], "no_evidence"]], [[["Pottery-4"], "no_evidence", "operation"]], [[["Pottery-62"], "no_evidence"]]]}
{"id": 940, "term": "Wheelchair", "description": "chair with wheels, used by people for whom walking is difficult or impossible due to illness, injury, or disability", "question": "Do American wheelchair users know what the ADA is?", "answer": true, "facts": ["The ADA is the Americans with Disabilities Act.", "Non-ADA compliant businesses include those without wheelchair access points."], "decomposition": ["Which areas of interest are affected by the ADA?", "Is any of #1 of particular interest to wheelchair users in America?"], "evidence": [[[["Americans with Disabilities Act of 1990-1"]], [["Disability-4"], "operation"]], [[["American Association of People with Disabilities-1"]], [["American Association of People with Disabilities-1"]]], [[["Americans with Disabilities Act of 1990-6"]], [["Americans with Disabilities Act of 1990-6"]]]]}
{"id": 710, "term": "Eric Clapton", "description": "English musician, singer, songwriter, and guitarist", "question": "Could Eric Clapton's children play a regulation game of basketball among themselves?", "answer": false, "facts": ["NBA regulations require two teams of five players each for a game, for a total of 10 players.", "Eric Clapton has 5 children."], "decomposition": ["How many players are required for a regulation game of basketball?", "How many children does Eric Clapton have?", "Is #2 greater than or equal to #1?"], "evidence": [[[["Basketball-1"]], [["Eric Clapton-78", "Eric Clapton-79", "Eric Clapton-80"]], ["operation"]], [[["Basketball-1"]], [["Eric Clapton-78", "Eric Clapton-79", "Eric Clapton-80"]], ["operation"]], [[["Basketball-1"]], [["Eric Clapton-78", "Eric Clapton-79", "Eric Clapton-80"]], ["operation"]]]}
{"id": 974, "term": "Aloe", "description": "genus of plants", "question": "Do all parts of the aloe vera plant taste good?", "answer": false, "facts": ["There is a layer of yellow latex liquid between the outside of an aloe leaf and the gel inside.", "The latex inside aloe tastes very bitter."], "decomposition": ["How do the various parts of the Aloe vera taste?", "Is all of #1 pleasant?"], "evidence": [[[["Aloe vera-1"], "no_evidence"], [["Aloe vera-16"], "no_evidence", "operation"]], [[["Aloe vera-21"], "no_evidence"], ["operation"]], [[["Aloe vera-17"], "no_evidence"], [["Aloe vera-21"], "no_evidence", "operation"]]]}
{"id": 196, "term": "Reiki", "description": "Pseudoscientific healing technique", "question": "Can Reiki be stored in a bottle?", "answer": false, "facts": ["Reiki practitioners use a technique called palm healing or hands-on healing through which a \"universal energy\" is said to be transferred through the palms of the practitioner to the patient in order to encourage emotional or physical healing.", "Medications are typically stored in pill bottles."], "decomposition": ["What basic property must a thing have to be able to be stored in a bottle?", "By definition, Reiki is a pseudoscientific healing what?", "Do #2's have the property stated in #1?"], "evidence": [[[["Bottle-1"]], [["Reiki-2"]], ["operation"]], [["no_evidence"], [["Reiki-1"]], ["operation"]], [[["Bottle-1"]], [["Reiki-1"]], ["operation"]]]}
{"id": 686, "term": "Lemon", "description": "citrus fruit", "question": "Can a lemon aggravate dyspepsia?", "answer": true, "facts": ["Dyspepsia is a condition where the stomach is irritated.", "Lemons are highly acidic fruits.", "Common stomach irritants include alcohol, coffee, and acidic foods."], "decomposition": ["Which condition is referred to as dyspepsia?", "What are some common irritants that could aggravate #1?", "Is lemon an example of #2?"], "evidence": [[[["Indigestion-1"]], [["Indigestion-9"], "no_evidence"], ["no_evidence", "operation"]], [[["Indigestion-1"]], [["Indigestion-15"], "no_evidence"], [["Indigestion-25"], "no_evidence", "operation"]], [[["Indigestion-11"]], [["Indigestion-12"]], [["Lemon-17"]]]]}
{"id": 987, "term": "Intel", "description": "American semiconductor chip manufacturer", "question": "Could Intel products be purchased at McDonald's?", "answer": false, "facts": ["Intel is a technology company that produces computer products such as processors, chipsets, and GPUs.", "McDonald's is a fast food franchise that sells food and beverage products."], "decomposition": ["What type of products does Intel produce?", "What kind of products does McDonald's sell?", "Is #1 included in #2?"], "evidence": [[[["Intel-1"]], [["McDonald's-2"]], ["operation"]], [[["Intel-44"], "no_evidence"], [["McDonald's-29"], "operation"], ["no_evidence"]], [[["Intel-1"]], [["McDonald's-2"]], ["operation"]]]}
{"id": 453, "term": "Southern United States", "description": "Cultural region of the United States", "question": "Can you hunt Iberian wolves in the Southern United States?", "answer": false, "facts": ["The Iberian wolf inhabits northern Portugal and northwestern Spain.", "Portugal and Spain are not located in the Southern United States."], "decomposition": ["What is the range of the Iberian wolf?", "Is #1 located in the Southern United States?"], "evidence": [[[["Iberian wolf-1"]], ["operation"]], [[["Iberian wolf-1"]], [["United States-1", "Western Europe-1"]]], [[["Iberian wolf-1"]], [["Iberian Peninsula-64", "United States-1"]]]]}
{"id": 128, "term": "Johann Sebastian Bach", "description": "German composer", "question": "Did Johann Sebastian Bach influence heavy metal?", "answer": true, "facts": ["Johann Sebastian Bach was a classical German composer born in 1685.", "Lead singer of heavy metal band Skid Row, Sebastian Bach, took his name from German composer Johann Sebastian Bach.", "Heavy Metal band Metallica released a live album with the San Francisco Symphony.", "Deep Purple, n English hard rock/heavy metal band has cited classical musicians as their inspiration.", "Deep Purple's keyboard and guitar solos on \"Highway Star,\" have been called Bach-like in harmonic progression and virtuosic arpeggio figuration."], "decomposition": ["Who is the lead singer of \"Skid Row\"?", "Who did #1 name himself after?", "Which classic musician's work have Deep Purple's solo on \"Highway Star\" been compared with?", "Are #2 and #3 Johann Sebastian Bach and both bands heavy metal?"], "evidence": [[[["Sebastian Bach-1"]], [["Johann Sebastian Bach-1"], "no_evidence"], [["Highway Star (song)-4"]], [["Deep Purple-1", "Skid Row (American band) discography-2"], "operation"]], [[["Skid Row (American band)-1"]], [["Johann Sebastian Bach-1"]], [["Highway Star (song)-3"]], ["operation"]], [[["Sebastian Bach-1"]], [["Johann Sebastian Bach-1"]], [["Highway Star (song)-3"]], [["Deep Purple-1", "Skid Row (American band)-1"], "operation"]]]}
{"id": 878, "term": "Hypothermia", "description": "A human body core temperature below 35.0°C", "question": "Would you be more likely to die of hypothermia in New York than Florida?", "answer": true, "facts": ["Central New York Winters are between 12-30 degrees Fahrenheit.", "Florida winters are between 65 and 77 degrees Fahrenheit."], "decomposition": ["What is the typical temperature range of the coldest time of the year in New York?", "What is the typical temperature range of the coldest time of the year in Florida?", "Is #1 lower than #2?"], "evidence": [[[["New York City-62"], "no_evidence"], [["Climate of Florida-7", "Climate of Florida-8"], "no_evidence"], ["operation"]], [[["New York (state)-43"]], [["Florida-45"]], ["operation"]], [[["New York (state)-43"]], [["Geography of Florida-5"]], ["operation"]]]}
{"id": 521, "term": "C", "description": "Letter of the Latin alphabet", "question": "Is letter C crucial to spelling the two most common words in English language?", "answer": false, "facts": ["The most common word in the English language is \"the\".", "The second most common word in the English language is \"be\"."], "decomposition": ["What is the most common word in the English language?", "What is the second most common word in the English language?", "What letters make up #1?", "What letters make up #2?", "Is the letter \"c\" found in both #3 and #4?"], "evidence": [[["no_evidence"], ["no_evidence"], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Most common words in English-5"], "no_evidence"], [["Most common words in English-5"], "no_evidence"], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Most common words in English-5"], "no_evidence"], [["Most common words in English-5"], "no_evidence"], ["operation"], ["operation"], ["operation"]]]}
{"id": 828, "term": "Elizabeth II", "description": "Queen of the United Kingdom and the other Commonwealth realms", "question": "Did Elizabeth II frequently visit Queen Victoria?", "answer": false, "facts": ["Queen Victoria died in 1901.", "Elizabeth II was born in 1926."], "decomposition": ["When did Queen Victoria die?", "When was Queen Elizabeth II born?", "Is #2 before #1?"], "evidence": [[[["Queen Victoria-1"]], [["Elizabeth II-1"]], ["operation"]], [[["Queen Victoria-1"]], [["Elizabeth II-1"]], ["operation"]], [[["Queen Victoria-53"]], [["Elizabeth II-5"]], ["operation"]]]}
{"id": 995, "term": "Catfish", "description": "order of fishes", "question": "Is a cory catfish likely to eat another living fish?", "answer": false, "facts": ["The cory catfish is a fish that is described as a bottom feeder.", "The cory catfish feeds on food located at the bottom of an ocean.", "Fish cannot live too deep in oceans for very long because of the intense water pressure.", "The bottom of oceans is populated by algae, coral, and microorganisms."], "decomposition": ["What do cory catfish eat?", "Is fish part of #1?"], "evidence": [[[["Corydoras-5"]], [["Corydoras-5"], "operation"]], [[["Corydoras-5"]], ["operation"]], [[["Corydoras-4", "Corydoras-5"]], ["operation"]]]}
{"id": 735, "term": "Queen Elizabeth The Queen Mother", "description": "Queen consort of King George VI, mother of Queen Elizabeth II", "question": "Did Queen Elizabeth The Queen Mother and her daughter share name with Tudor queen?", "answer": true, "facts": ["Queen Elizabeth the Queen Mother gave birth to Queen Elizabeth II in 1926.", "The Tudor dynasty had a number of Queens including: Mary I of England, Elizabeth I of England, and Margaret Tudor, Queen of Scots."], "decomposition": ["Which name did the Queen Mother and Queen Elizabeth have in common?", "What are the names of some queens from the Tudor dynasty?", "Is #1 included in any of #2?"], "evidence": [[[["Elizabeth II-1", "Queen Elizabeth The Queen Mother-1"]], [["House of Tudor-1"]], ["operation"]], [[["Queen Elizabeth The Queen Mother-1"]], [["Elizabeth I of England-1", "Mary I of England-1"]], ["operation"]], [[["Queen Elizabeth The Queen Mother-1"]], [["House of Tudor-1"]], ["operation"]]]}
{"id": 764, "term": "Learning disability", "description": "Range of neurodevelopmental conditions", "question": "Do placozoa get learning disabilities?", "answer": false, "facts": ["Learning disabilities are neurodevelopmental conditions afflicting a portion of the human population", "Neurodevelopmental conditions affect the nervous system", "Placozoa are multicellular microscopic organisms which do not have a nervous system"], "decomposition": ["What bodily system do learning disabilities affect?", "Do placozoa possess #1?"], "evidence": [[[["Learning disability-1"]], [["Placozoa-7"], "operation"]], [[["Learning disability-1", "Learning disability-3"], "no_evidence"], [["Placozoa-1"], "operation"]], [[["Learning disability-5"]], [["Placozoa-7"], "operation"]]]}
{"id": 423, "term": "Yeti", "description": "Folkloric ape-like creature from Asia", "question": "Is there a Yeti associated with Disney theme parks?", "answer": true, "facts": ["In the 1960s, an attraction called Matterhorn featuring a cartoon version of the Yeti opened in Disneyland.", "Later in 2005, Expedition Everest opened at Animal Kingdom in Disney World, featuring a much scarier version of the Yeti."], "decomposition": ["What 1960s attraction featured a cartoon version of the Yeti?", "Is #1 part of a Disney park?"], "evidence": [[[["Matterhorn Bobsleds-1", "Matterhorn Bobsleds-8"]], ["operation"]], [[["Expedition Everest-12"]], [["Disney's Animal Kingdom-1"]]], [[["Matterhorn Bobsleds-23"]], [["Disney's Animal Kingdom-1"]]]]}
{"id": 879, "term": "Nintendo", "description": "Japanese multinational consumer electronics company", "question": "Did original Nintendo have games in same format as Playstation 3?", "answer": false, "facts": ["Nintendo was originally released in 1983 and used games that were in a cartridge format.", "Sony Playstation 3 was released in 2006 and had games in a CD format."], "decomposition": ["What format were Nintendo games originally released in?", "What format were PlayStation 3 games released in?", "Is #1 the same as #2?"], "evidence": [[[["Video game console-11"]], [["PlayStation 3-23"]], ["operation"]], [[["Nintendo Entertainment System-3"]], [["PlayStation 3-2"]], ["operation"]], [[["Nintendo Entertainment System-27"]], [["PlayStation 3-2"]], ["operation"]]]}
{"id": 855, "term": "Euro", "description": "European currency", "question": "Would someone pay for a coffee in NYC with Euros?", "answer": false, "facts": ["New York City is located within the United States.", "The currency used in the United States is the United States dollar, not the Euro."], "decomposition": ["In what country is New York City?", "What is the currency for #1?", "Is #2 the Euro?"], "evidence": [[[["New York City-1"]], [["United States dollar-1"]], ["operation"]], [[["New York City-1"]], [["United States dollar-1"]], ["operation"]], [[["New York City-1"]], [["United States dollar-1"]], ["operation"]]]}
{"id": 682, "term": "Alan Alda", "description": "American actor, director, and writer", "question": "Is Alan Alda old enough to have fought in the Vietnam War?", "answer": true, "facts": ["Alan Alda was born in 1936.", "The Vietnam War was from 1955 to 1975, with American involvement from 1965 to 1973.", "American soldiers must be at least 18 years old.", "Alan Alda was 29 in 1965."], "decomposition": ["When were US forces first involved in the Vietnam war?", "When was Alan Alda born?", "What is the minimum age required to join the US Army?", "What is #1 minus #2?", "Is #4 greater than or equal to #3?"], "evidence": [[[["Vietnam War-58"]], [["Alan Alda-2"]], [["United States Army Recruiting Command-13"]], ["operation"], ["operation"]], [[["Vietnam War-2"]], [["Alan Alda-2"]], ["no_evidence"], ["operation"], ["no_evidence", "operation"]], [[["Vietnam War-1"]], [["Alan Alda-2"]], [["United States Armed Forces-3"]], ["operation"], ["operation"]]]}
{"id": 814, "term": "Taco Bell", "description": "American fast-food chain", "question": "Can you purchase a dish with injera at Taco Bell?", "answer": false, "facts": ["Taco Bell serves a variety of Mexican and Tex-Mex foods that include tacos, burritos, quesadillas, and nachos.", "Injera is a sour fermented flatbread with a slightly spongy texture, traditionally made out of teff flour.", "Injera is part of Ethiopian cuisine."], "decomposition": ["What kind of food is Taco Bell known to serve?", "Which country is #1 most associated with?", "Which country is Injera native to?", "Is #2 the same as #3?"], "evidence": [[[["Taco Bell-1"]], [["Taco Bell-1"]], [["Injera-1"]], ["operation"]], [[["Taco Bell-1"]], [["Taco Bell-1"]], [["Injera-1"]], ["operation"]], [[["Taco Bell-1"]], [["Mexican cuisine-6", "Tex-Mex-1"]], [["Pancake-7"]], ["operation"]]]}
{"id": 396, "term": "Honey", "description": "Sweet food made by bees mostly using nectar from flowers", "question": "Is honey associated with queens?", "answer": true, "facts": ["Honey is made by bees.", "Each bee hive is led by a queen bee."], "decomposition": ["What produces honey?", "Do #1 have queens?"], "evidence": [[[["Honey-1"]], [["Honey bee-53"], "operation"]], [[["Honey-1"]], [["Honey bee-53"], "operation"]], [[["Honey-1"]], [["Queen bee-1"]]]]}
{"id": 838, "term": "Metallica", "description": "American heavy metal band", "question": "Did Metallica band members cutting their hair hurt their sales?", "answer": true, "facts": ["Metallica famously cut their hair in 1996 which caused a huge divide in their fanbase.", "Metallica's best selling album, The Black Album, was released in 1991 and has sold over 20 million copies.", "Since 1996, Metallica have released 5 studio albums.", "Metalica's 5 studio albums since 1996 have sold around a combined 14 million copies"], "decomposition": ["When did Metallica band members cut their hair?", "How many copies of their best selling album has been sold?", "How many copies of their last five albums have been sold altogether?", "Is #1 after the release date of #2 and before those of #3, and #2 greater than #3?"], "evidence": [[[["Metallica-25"]], [["Metallica (album)-22"]], [["Death Magnetic-44", "Death Magnetic-45", "Hardwired... to Self-Destruct-15", "Load (album)-2", "Reload (Metallica album)-6", "St. Anger-3"], "no_evidence"], ["operation"]], [[["Metallica-25"]], [["Metallica discography-1"], "no_evidence"], ["no_evidence"], ["operation"]], [[["Load (album)-1", "Load (album)-13"], "no_evidence"], [["Metallica (album)-3"]], [["Death Magnetic-45", "Hardwired... to Self-Destruct-2", "Load (album)-2", "Reload (Metallica album)-6", "St. Anger-3"], "no_evidence"], ["no_evidence", "operation"]], [[["Metallica-25"]], [["Metallica (album)-22"]], [["Death Magnetic-47", "Hardwired... to Self-Destruct-15", "Lulu (Lou Reed and Metallica album)-16", "Reload (Metallica album)-1", "St. Anger-3"], "no_evidence"], ["operation"]]]}
{"id": 930, "term": "Viscosity", "description": "Resistance of a fluid to shear deformation", "question": "Is viscosity unimportant in making jello shots?", "answer": false, "facts": ["Jello shots are a combination of alcohol and jello to create an edible intoxicant. ", "If the liquid for the Jello shots has too low a viscosity, it will not become a semi-solid. "], "decomposition": ["What are the ingredients used in making jello shots?", "Which properties of liquids among #1 are important for good results?", "Is viscosity not included in #2?"], "evidence": [[[["Jell-O-30"]], [["Mixed drink-1"], "no_evidence"], [["Viscosity-1"], "operation"]], [[["Jell-O-30"]], [["Jell-O-30"], "no_evidence"], ["no_evidence"]], [[["Jell-O-30"]], [["Jell-O-29"]], ["operation"]]]}
{"id": 380, "term": "Fax", "description": "method of transmitting images, often of documents", "question": "Do most college students own a fax machine?", "answer": false, "facts": ["College students typically must submit assignments via email, web portal, or on paper.", "Most colleges have on-campus fax machines available for student use."], "decomposition": ["How do college students typically submit their assignments nowadays?", "Does #1 require a fax machine?"], "evidence": [[[["Student-54"], "no_evidence"], [["Fax-1"], "no_evidence"]], [[["Educational technology-1", "Educational technology-14"], "no_evidence"], [["Fax-1"], "operation"]], [[["Email-1", "Email-45"], "no_evidence"], ["operation"]]]}
{"id": 903, "term": "Pink (singer)", "description": "American singer, songwriter, and actress", "question": "Are there Pink music videos that are triggering for eating disorder patients?", "answer": true, "facts": ["The video for 'Stupid Girls' features a scene where Pink and a woman share a toothbrush to induce vomiting in the bathroom.", "Images or discussion of purging activity can be triggering for people with Eating Disorders."], "decomposition": ["What are the depictions in Pink's music video 'Stupid Girls'?", "What are some situations that can be triggering for people with eating disorders?", "Are any of #2 included in #1?"], "evidence": [[[["Stupid Girls-12"]], [["Eating disorder-7"], "no_evidence"], ["operation"]], [[["Stupid Girls-12", "Stupid Girls-13"]], [["Eating disorder-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Stupid Girls-13"]], [["Eating disorder-9"]], [["Stupid Girls-13"]]]]}
{"id": 181, "term": "Salsa (sauce)", "description": "Sauce", "question": "Would the chef at La Grenouille find salsa to be a strange request?", "answer": true, "facts": ["La Grenouille is a classic French cuisine restaurant in NYC.", "Salsa is a staple food in Mexican cuisine."], "decomposition": ["What type of cuisine does La Grenouille serve?", "Would you typically find salsa in #1?"], "evidence": [[[["La Grenouille (restaurant)-3"], "operation"], ["no_evidence"]], [[["La Grenouille (restaurant)-1"]], [["Mexican cuisine-28"]]], [[["La Grenouille (restaurant)-3"]], [["La Grenouille (restaurant)-1", "Salsa-1"]]]]}
{"id": 216, "term": "Asteroid", "description": "Minor planet that is not a comet", "question": "Can an asteroid be linked with virginity?", "answer": true, "facts": ["An asteroid discovered in 1807 was named Vesta", "Vesta is the Roman virgin goddess of hearth, home and family"], "decomposition": ["What was the name of the asteroid that was discovered in 1807?", "What did #1 stand for as a Roman goddess?", "Is #2 related to virginity?"], "evidence": [[[["4 Vesta-1"]], [["Vesta (mythology)-1"]], [["Vesta (mythology)-8"]]], [[["4 Vesta-1"]], [["Vesta (mythology)-1"]], ["operation"]], [[["4 Vesta-1"]], [["Vesta (mythology)-1"]], ["operation"]]]}
{"id": 983, "term": "Pound sterling", "description": "Official currency of the United Kingdom and other territories", "question": "Was Emperor Commodus paid tribute in Pound sterling?", "answer": false, "facts": ["Commodus was Roman Emperor until 192 AD.", "Coins featuring the image of Commodus were the currency during the late second century AD.", "The Pound sterling has origins with the fifth century AD Anglo Saxon pound."], "decomposition": ["When was Commodus Roman emperor?", "When did the Pound sterling originate?", "Was #1 before #2?"], "evidence": [[[["Commodus-1"]], [["Pound sterling-19"]], ["operation"]], [[["Commodus-11"]], [["Pound sterling-22"]], ["operation"]], [[["Commodus-1"]], [["Pound sterling-19"]], ["operation"]]]}
{"id": 986, "term": "Lust", "description": "Human emotion", "question": "Do you have to pass through circle of lust to find Saladin in Dante's Inferno?", "answer": false, "facts": ["Dante's Inferno was a book written by Dante Alighieri that outlines 9 circles of hell.", "The circle of lust is the second circle in Dante's Inferno.", "Saladin is placed in the first circle of hell in Dante's Inferno.", "The first circle of hell is limbo which is reserved for virtuous unbaptized pagans."], "decomposition": ["In Dante's Inferno, what circle is for people guilty of lust?", "In Dante's Inferno, what circle is Saladin in?", "Would someone traversing the Inferno pass through #2 before #1?"], "evidence": [[[["Inferno (Dante)-13"]], [["Inferno (Dante)-8", "Inferno (Dante)-9", "Limbo-1"]], ["operation"]], [[["Dante's Inferno (song)-3"]], [["Dante's Inferno: An Animated Epic-5"]], ["operation"]], [[["Inferno (Dante)-13"]], [["Inferno (Dante)-8", "Inferno (Dante)-9"]], ["operation"]]]}
{"id": 313, "term": "Roman numerals", "description": "Numbers in the Roman numeral system", "question": "Does the FDA require sell by dates using Roman Numerals?", "answer": false, "facts": ["There are no requirements for food to have sell by dates. ", "Sell by dates on most food items are written using arabic numerals."], "decomposition": ["Is there any regulation on the sell by dates of food products?"], "evidence": [[["no_evidence"]], [[["Shelf life-1", "Shelf life-31"], "operation"]], [[["Shelf life-31"]]]]}
{"id": 284, "term": "Rahul Dravid", "description": "Indian cricketer", "question": "Does Rahul Dravid belong to the family Gryllidae?", "answer": false, "facts": ["Crickets (also known as \"true crickets\"), of the family Gryllidae, are insects related to bush crickets, and, more distantly, to grasshoppers.", "Cricket is a bat-and-ball game played between two teams of eleven players on a field at the centre of which is a 20-metre (22-yard) pitch with a wicket at each end, each comprising two bails balanced on three stumps.", "Human beings belong to the family Hominidae."], "decomposition": ["What kind of creature is Rahul Dravid?", "Which family does #1 belong to?", "Is #2 the same as Gryllidae?"], "evidence": [[[["Rahul Dravid-1"]], [["Human-6"]], ["operation"]], [[["Homo sapiens-1", "Rahul Dravid-1"]], [["Hominidae-1"]], ["operation"]], [[["Rahul Dravid-1"]], [["Hominidae-20"]], ["operation"]]]}
{"id": 30, "term": "Starch", "description": "glucose polymer used as energy store in plants", "question": "Can a wheelbarrow full of starch kill hyperglycemics?", "answer": true, "facts": ["Hyperglycemia is a condition in which people have higher than normal blood glucose levels.", "Starch is a compound made by plants that is made of numerous glucose units.", "An excess of glucose can lead to diabetic complications and can result ind death.", "The average wheelbarrow can hold up to 1200 pounds."], "decomposition": ["What is hyperglycemia?", "What is starch made of?", "How much can the average wheelbarrow hold?", "Could #3 of #2 potentially be fatal to someone who has #1?"], "evidence": [[[["Hyperglycemia-1"]], [["Starch-1"]], [["Wheelbarrow-2"]], [["Hyperglycemia-21"]]], [[["Hyperglycemia-1"]], [["Starch-1"]], [["Wheelbarrow-2"]], [["Hyperglycemia-2"], "operation"]], [[["Hyperglycemia-1"]], [["Starch-1"]], [["Wheelbarrow-2"]], ["operation"]]]}
{"id": 557, "term": "Fear", "description": "Basic emotion induced by a perceived threat", "question": "Is an espresso likely to assuage fear?", "answer": false, "facts": ["Fear raises heart rate", "Caffeine raises heart rate", "Coffee may also increase symptoms such as jitteriness and nausea "], "decomposition": ["What does fear typically do to a person's heart rate?", "What does espresso typically do to a person's heart rate?", "Is #1 the opposite of #2?"], "evidence": [[[["Fear-4"]], [["Caffeine-32", "Espresso-2"]], ["operation"]], [[["Heart rate-15"]], [["Caffeine-3"]], ["operation"]], [[["Fear-20"]], [["Caffeine-44", "Espresso-2"]], ["operation"]]]}
{"id": 89, "term": "Leaf", "description": "organ of a vascular plant, composing its foliage", "question": "Do oak trees have leaves during winter?", "answer": false, "facts": ["Oak trees are deciduous.", "Deciduous trees lose their leaves during autumn, and they grow back during spring.", "Winter is between autumn and spring."], "decomposition": ["When do oak trees lose their leaves?", "When do oak trees leaves grow back", "Is winter not the season between #1 and #2?"], "evidence": [[[["Deciduous-3", "Oak-1"]], [["Deciduous-9"]], ["operation"]], [[["Oak-2"]], [["Oak-2"]], [["Winter-1"]]], [[["Oak-2"]], [["Oak-2"], "no_evidence"], [["Winter-6"], "operation"]]]}
{"id": 496, "term": "Bengal cat", "description": "Breed of cat", "question": "Can a Bengal cat survive eating only pancakes?", "answer": false, "facts": ["Bengal cats are carnivores.", "Pancakes contain no meat.", "Carnivores eat only meat to survive. "], "decomposition": ["What type of diet does a Bengal cats follow?", "What do #1 mainly eat?", "Do pancakes contain #2?"], "evidence": [[[["Bengal cat-1"]], [["Cat food-9"]], ["operation"]], [[["Bengal cat-1", "Cat-1"]], [["Carnivore-1"]], [["Pancake-1"], "operation"]], [[["Bengal cat-1", "Carnivore-7"]], [["Carnivore-7"]], [["Pancake-1"]]]]}
{"id": 398, "term": "Learning disability", "description": "Range of neurodevelopmental conditions", "question": "Does penicillin cure a learning disability?", "answer": false, "facts": ["Learning disabilities are neurological impairments", "Neurological impairments can result from genetic issues, developmental problems, and accidents like head trauma, malnutrition or exposure to toxins", "Penicillin is an antibiotic that treats bacterial infection"], "decomposition": ["What kind of impairment is a learning disability?", "What are the causes of #1?", "What is Penicillin used to treat?", "Is #3 also listed in #2?"], "evidence": [[[["Learning difficulties-2"]], [["Learning disability-18"]], [["Penicillin-1"]], [["Learning disability-18", "Penicillin-1"]]], [[["Learning disability-1"]], [["Learning disability-17", "Learning disability-18"]], [["Penicillin-1"]], ["operation"]], [[["Learning disability-1"]], [["Learning disability-3"]], [["Side effects of penicillin-1"]], ["operation"]]]}
{"id": 345, "term": "Martyr", "description": "person who suffers persecution and death for advocating, refusing to renounce, and/or refusing to advocate a belief or cause, usually a religious one", "question": "Can a martyr saint have been excommunicated?", "answer": true, "facts": ["Joan of Arc was excommunicated by the Catholic Church in 1431.", "Joan of Arc was declared a martyr in 1456 after an investigation ordered by King Charles VII.", "Joan of Arc was canonized a Saint by the Catholic Church on May 16, 1920."], "decomposition": ["Is Joan of Arc considered a matyr?", "Was she initially excommunicated by the Catholic Church?", "Is #1 or #2 negative?"], "evidence": [[[["Canonization of Joan of Arc-1"]], [["Canonization of Joan of Arc-2"]], ["operation"]], [[["Joan of Arc-3"]], [["Heresy-3", "Joan of Arc-37"], "no_evidence"], ["operation"]], [[["Joan of Arc-3"]], [["Canonization of Joan of Arc-2"]], ["operation"]]]}
{"id": 548, "term": "Pearl hunting", "description": "Collecting pearls from wild mollusks", "question": "Would Michael Phelps be good at pearl hunting?", "answer": true, "facts": ["Pearl hunters swim underwater to collect pearls from oysters.", "Michael Phelps is the most decorated Olympic swimmer of all time."], "decomposition": ["What do pearl hunters do?", "What is Michael Phelps famous for?", "Does #2 help with accomplishing #1?"], "evidence": [[[["Pearl hunting-1"]], [["Michael Phelps-1"]], [["Pearl hunting-2"]]], [[["Pearl hunting-1"]], [["Michael Phelps-1"]], ["operation"]], [[["Pearl hunting-2"]], [["Michael Phelps-1"]], ["operation"]]]}
{"id": 405, "term": "Myth", "description": "Type of traditional narrative", "question": "Was story of Jesus inspired by Egyptian myth?", "answer": true, "facts": ["Jesus was a biblical character that walked on water, was born of a virgin, and was killed beside two thieves.", "Horus was a character in ancient Egyptian myth that walked on water, had a virgin mother, and was executed beside two thieves."], "decomposition": ["What are the main characteristics of the Horus story?", "What are the main characteristics of the Jesus story?", "Is there evidence people believed #1 before #2?", "Is there significant overlap between #1 and #2?", "Are #4 and #3 both \"Yes\"?"], "evidence": [[[["Osiris myth-1"]], [["Jesus-3"]], [["Osiris myth-3"]], [["Jesus-1"]], ["operation"]], [[["Horus-8"], "no_evidence"], [["Jesus-1"], "no_evidence"], [["Ancient Egypt-1"]], ["no_evidence", "operation"], ["operation"]], [[["Horus-11"]], [["Jesus-11"]], [["Jesus-7"], "no_evidence"], [["Horus-1"], "no_evidence"], ["operation"]]]}
{"id": 656, "term": "Tokyo Tower", "description": "observation tower", "question": "Did Tokyo Tower designers appreciate Stephen Sauvestre?", "answer": true, "facts": ["Tokyo Tower is a communications tower in Japan, built in 1958, that was inspired by the Eiffel Tower.", "Stephen Sauvestre was the architect of the the Eiffel Tower which was competed in 1889."], "decomposition": ["Which architectural design is Stephen Sauvestre famous for?", "Was #1 influential in the design of the Tokyo Tower?"], "evidence": [[[["Stephen Sauvestre-1"]], [["Tokyo Tower-1"]]], [[["Stephen Sauvestre-3"]], ["operation"]], [[["Stephen Sauvestre-1"]], [["Tokyo Tower-1"]]]]}
{"id": 61, "term": "Olive", "description": "Species of plant", "question": "Would Bugs Bunny harm an olive tree in the real world?", "answer": true, "facts": ["Bugs Bunny is an anthropomorphic gray and white rabbit.", "Rabbits eat the bark of olive trees and can do considerable damage, especially to young trees."], "decomposition": ["What kind of animal is Bugs Bunny?", "Do #1 eat and damage the bark of olive trees?"], "evidence": [[[["Bugs Bunny-2"]], [["Olive-73"]]], [[["Bugs Bunny-2"]], [["Olive-73"], "operation"]], [[["Bugs Bunny-2"]], [["Olive-73"]]]]}
{"id": 790, "term": "Newcastle, New South Wales", "description": "City in New South Wales, Australia", "question": "Was the MLB World Series held in Newcastle, New South Wales?", "answer": false, "facts": ["The MLB World Series is held annually in a stadium belonging to one of its teams", "MLB teams are located in the United States and Canada", "New South Wales is a state in Australia"], "decomposition": ["In which countries are MLB World Series held?", "Is Australia one of #1?"], "evidence": [[[["MLB International-1"]], ["operation"]], [[["World Series-1"]], ["operation"]], [[["World Series-1"], "no_evidence"], ["operation"]]]}
{"id": 156, "term": "Santa Claus", "description": "Folkloric figure, said to deliver gifts to children on Christmas Eve", "question": "Are most mall Santa Claus actors white?", "answer": true, "facts": ["In 2016, a black man playing Santa Claus at the Mall of America made national headlines.", "There are map websites dedicated to locating black Santa Claus mall actors."], "decomposition": ["What is the ethnicity of the man who made headlines for playing Santa Claus at the Mall of America in 2016?", "Does #1 imply that black Santas are a rare occurrence?"], "evidence": [[["no_evidence"], ["no_evidence"]], [[["Santa Claus-2"], "no_evidence"], ["operation"]], [["no_evidence"], [["Santa Claus-50"], "no_evidence", "operation"]]]}
{"id": 28, "term": "Saint", "description": "one who has been recognized for having an exceptional degree of holiness, sanctity, and virtue", "question": "Can a false pope become a saint?", "answer": true, "facts": ["A false pope, or antipope, is someone that tries to claim they are the true pope but the church rejects them.", "Hippolytus (c. 170–235 AD) headed a schismatic group as a rival to the Bishop of Rome, thus becoming an antipope.", "Hippolytus (c. 170–235 AD) was named a saint in the Roman Catholic Church."], "decomposition": ["Which actions could make the Catholic church consider one a false pope or antipope?", "What role did Hippolytus (c. 170–235 AD) play in the schismatic group against the Bishop of Rome?", "Is #2 a form of #1 and he still became saint?"], "evidence": [[[["Antipope-1"]], [["Hippolytus of Rome-1"]], [["Hippolytus of Rome-24"], "operation"]], [[["Antipope-1"], "no_evidence"], [["Hippolytus of Rome-1"]], [["Hippolytus of Rome-2"], "operation"]], [[["Antipope-1"]], [["Antipope-4"]], [["Antipope-16", "Saint-7"], "no_evidence"]]]}
{"id": 143, "term": "Crucifixion", "description": "Method of capital punishment in which the victim is tied or nailed to a large wooden beam and left to hang until eventual death", "question": "Is Home Depot a one stop shop for crucifixion supplies?", "answer": true, "facts": ["A one stop shop is a store where multiple items are supplied.", "Crucifixion is a form of punishment in which a person is nailed to a wooden cross.", "Home Depot sells numerous supplies including: hammers, nails, and wood."], "decomposition": ["What is the definition of a one stop shop?", "What tools are necessary for Crucifixion?", "Is Home Depot a #1 for all of #2?"], "evidence": [[[["One stop shop-1"]], [["Crucifixion-1"]], ["operation"]], [[["One stop shop-1"]], [["Descriptions in antiquity of the execution cross-6"], "no_evidence"], [["The Home Depot-1"], "operation"]], [[["One stop shop-1"]], [["Crucifixion-1"]], [["The Home Depot-1"], "operation"]]]}
{"id": 569, "term": "Superhero fiction", "description": "Fiction genre", "question": "Was Superhero fiction invented in the digital format?", "answer": false, "facts": ["The Golden Age of comics occurred between the 1930's and the 1950's.", "Shatter was the first digitally drawn, commercially published comic."], "decomposition": ["In which format was superhero fiction first introduced?", "During which period were #1 first published and made popular?", "When was the first digitally drawn #1 published?", "Is #2 after #3?"], "evidence": [[[["Superhero fiction-21"]], [["Comic book-5"]], [["Shatter (digital comic)-2"]], ["operation"]], [[["Superhero fiction-21"]], [["Superhero fiction-21"]], [["Digital comic-4"]], ["operation"]], [[["Superhero-1"]], [["Superhero-1"]], ["no_evidence"], ["operation"]]]}
{"id": 81, "term": "Presidency of Bill Clinton", "description": "1993–2001 U.S. presidential administration", "question": "Did the Presidency of Bill Clinton conclude with his impeachment?", "answer": false, "facts": ["Bill Clinton was impeached in 1998.", "Bill Clinton remained in office until 2001."], "decomposition": ["In what year was Bill Clinton impeached?", "In what year did Bill Clinton's presidency end?", "Is #1 the same as #2?"], "evidence": [[[["Bill Clinton-61"]], [["Bill Clinton-1", "Impeachment of Bill Clinton-29"]], ["operation"]], [[["Impeachment of Bill Clinton-16"]], [["Bill Clinton-1"]], ["operation"]], [[["Bill Clinton-61"]], [["Bill Clinton-61"]], ["operation"]]]}
{"id": 161, "term": "Fair trade", "description": "form of trade", "question": "Did Medieval English lords engage in fair trade with peasants?", "answer": false, "facts": ["Fair trade is a system in which fair prices are paid to the producers of a product.", "English lords had peasants working on their manors and the peasants were indentured servants.", "The peasants had few rights, were unpaid, and had to even ask their lord for permission to marry."], "decomposition": ["What is fair trade?", "Are peasants able to participate in #1 with Lords?"], "evidence": [[[["Fair trade-1"]], [["Peasant-1"], "no_evidence"]], [[["Fair trade-1"], "no_evidence"], [["Peasant-8"], "no_evidence", "operation"]], [[["Fair trade-1"]], ["no_evidence", "operation"]]]}
{"id": 3, "term": "Anchovy", "description": "Family of fishes", "question": "Can an anchovy born in 2020 survive 25th US census?", "answer": false, "facts": ["The US Census takes place every ten years.", "The 24th US Census took place in 2020.", "The 25th US Census will take place in 2030.", "The average lifespan of an anchovy is five years."], "decomposition": ["What is the ordinal number of the 2020 U.S. Census?", "How many years after #1 wll the 25th census occur?", "What is the maximum life span of an anchovy?", "Is #3 greater than #2?"], "evidence": [[[["2020 United States Census-1"]], [["United States Census-1"]], [["Japanese anchovy-1"], "no_evidence"], ["operation"]], [[["2020 United States Census-1"]], [["United States Census Bureau-4"]], [["European anchovy-7", "Japanese anchovy-1"]], ["operation"]], [[["2020 United States Census-1"]], [["United States Census-1"]], [["European anchovy-7"]], ["operation"]]]}
{"id": 666, "term": "Junk (ship)", "description": "Type of boat", "question": "Does Carmen Electra own a junk?", "answer": false, "facts": ["A junk is a boat.", "Boats are sailed on open water.", "Carmen Electra has a fear of open water."], "decomposition": ["What is another name for a junk?", "Where does one use #1?", "Does Carmen Electra like being in #2?"], "evidence": [[[["Junk (ship)-1"]], [["Junk (ship)-6"]], ["no_evidence", "operation"]], [[["Junk (ship)-1"]], [["Junk (ship)-1"]], [["Carmen Electra-1"], "no_evidence", "operation"]], [[["Junk (ship)-1"]], [["Sailing ship-1"]], ["no_evidence"]]]}
{"id": 222, "term": "Kaffir lime", "description": "A citrus fruit native to tropical Southeast Asia and southern China", "question": "Would kaffir lime be good in a White Russian?", "answer": false, "facts": ["A White Russian is a drink containing cream, vodka, and Kahlua.", "Mixing lime and cream results in curdled milk, which is not good to drink."], "decomposition": ["What are the ingredients of a White Russian?", "Do any of #1 curdle when mixed with lime?"], "evidence": [[[["White Russian (cocktail)-1"]], ["no_evidence", "operation"]], [[["White Russian (cocktail)-1"]], [["Citric acid-1", "Curdling-2"], "no_evidence", "operation"]], [[["White Russian (cocktail)-1"]], [["Curdling-3"], "operation"]]]}
{"id": 365, "term": "Cerebral palsy", "description": "A group of disorders affecting the development of movement and posture, often accompanied by disturbances of sensation, perception, cognition, and behavior. It results from damage to the fetal or infant brain.", "question": "Is a slime mold safe from cerebral palsy?", "answer": true, "facts": ["Cerebral palsy is a disorder caused by damage to fetal or infant brains.", "Slime molds are simple organisms that are similar to fungi.", "Slime molds do not possess a brain."], "decomposition": ["Damage to what structure can cause cerebral palsy?", "What structures do slime molds have?", "Is #1 listed in #2?"], "evidence": [[[["Cerebral palsy-2"]], [["Plasmodium (life cycle)-3"]], ["operation"]], [[["Cerebral palsy-2"]], [["Slime mold-18"]], ["operation"]], [[["Cerebral palsy-2"]], [["Slime mold-18"], "no_evidence"], ["operation"]]]}
{"id": 579, "term": "Hunger", "description": "Sustained inability to eat sufficient food", "question": "Was Jean Valjean imprisoned due to hunger?", "answer": true, "facts": ["Jean Valjean was sentenced to imprisonment due to theft of property.", "The item Jean Valjean stole was a loaf of bread for his family."], "decomposition": ["What crime was Jean Valjean convicted of?", "What did Jean Valjean gain from #1?", "Who did he give #2 to?", "Is hunger experienced by #3 the main reason for wanting #2?"], "evidence": [[[["Jean Valjean-1"]], [["Jean Valjean-1"]], [["Jean Valjean-1"]], ["operation"]], [[["Jean Valjean-1"]], [["Jean Valjean-1"]], [["Jean Valjean-1"]], ["operation"]], [[["Jean Valjean-6"]], [["Jean Valjean-7"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 704, "term": "Funeral", "description": "ceremony for a person who has died", "question": "Is it normal to blow out candles during a funeral?", "answer": false, "facts": ["Blowing out candles is typically done during a birthday celebration, prior to eating the birthday cake.", "Funerals are typically very somber events in which cake is not served."], "decomposition": ["Blowing out candles is a typical part of which celebration?", "What kind of aura is naturally associated with #1?", "Is the atmosphere in a funeral typically similar to #2?"], "evidence": [[[["Party-5"]], [["Party-1"]], [["Funeral-88"]]], [[["Birthday cake-7"]], [["Joy-1"]], [["Funeral-1"], "operation"]], [[["Birthday cake-9"]], [["Happy, Happy Birthday Baby-1"]], [["Funeral-1"]]]]}
{"id": 539, "term": "Hanuman", "description": "The divine monkey companion of Rama in Hindu mythology", "question": "Did Hanuman ever experience an orgasm?", "answer": false, "facts": ["Hanuman was a life long celibate.", "Celibates refrain from all sexual activity.", "Orgasms are only experienced during sexual activity."], "decomposition": ["What does one have to do to experience an orgasm?", "Which of Hanuman's characteristics concerned his #1 aspect?", "Do people who identify as #2 engage in #1?"], "evidence": [[[["Sexual intercourse-1"]], [["Hanuman-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Orgasm-1"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Orgasm-1"]], [["Hanuman-1"]], ["operation"]]]}
{"id": 669, "term": "Osama bin Laden", "description": "Co-founder of al-Qaeda", "question": "Did Osama bin Laden likely abstain from alcohol?", "answer": true, "facts": ["Osama bin Laden belonged to the religion of Islam.", "Islam prohibits the consumption of alcohol."], "decomposition": ["What religion was Osama bin Laden?", "Does #1 prohibit consumption of alcohol?"], "evidence": [[[["Osama bin Laden-10"]], [["Alcohol law-14"], "operation"]], [[["Osama bin Laden-10"]], [["Islamic culture-45"]]], [[["Osama bin Laden-16"]], [["Islamic dietary laws-9"], "operation"]]]}
{"id": 289, "term": "Chlorophyll", "description": "group of chemical compounds", "question": "For Hostas to look their best, do they need lots of chlorophyll?", "answer": true, "facts": ["Hostas are characterized by large green striped leaves.", "The green color in plants is attributed to chlorophyll. "], "decomposition": ["What color is a visually appealing hosta?", "Do the get #1 from chlorophyll?"], "evidence": [[[["Hosta-2"]], [["Chlorophyll-2"], "operation"]], [[["Hosta-6"], "no_evidence"], [["Chloroplast-1", "Hosta-2"], "operation"]], [[["Hosta-2"]], [["Chlorophyll-2"], "operation"]]]}
{"id": 908, "term": "Paparazzi", "description": "profession", "question": "Were paparazzi involved in the death of a member of the royal family?", "answer": true, "facts": ["Diana Spencer was being pursued by paparazzi when her vehicle was involved in a fatal accident.", "Diana Spencer was known as 'Princess Diana' and was the Princess of Wales."], "decomposition": ["What were the circumstances surrounding the death of Diana Spencer?", "Is Diana Spencer a member of the royal family?", "Was paparazzi involved in #1?", "Are #2 and #3 positive?"], "evidence": [[[["Diana, Princess of Wales-4"]], [["Diana, Princess of Wales-3"]], [["Death of Diana, Princess of Wales-2"]], ["operation"]], [[["Death of Diana, Princess of Wales-1"]], [["Diana, Princess of Wales-1", "Diana, Princess of Wales-26"]], [["Death of Diana, Princess of Wales-2"]], ["operation"]], [[["Diana, Princess of Wales-53"]], [["Diana, Princess of Wales-1"]], [["Diana, Princess of Wales-53"]], ["operation"]]]}
{"id": 992, "term": "Citrus", "description": "genus of fruit-bearing plants (source of fruit such as lemons and oranges)", "question": "Is there a Marvel villain with the same name as a kind of citrus fruit?", "answer": true, "facts": ["Mandarins are a type of orange popular in Asian cuisine.", "The Mandarin is also the name of a villain associated with Iron Man in the Marvel universe."], "decomposition": ["Which popular villains has Marvel's Ironman faced off against?", "Do any of #1's name also refer to a citrus fruit?"], "evidence": [[[["Iron Man-24"]], [["Mandarin orange-1"]]], [[["Iron Man-24"]], [["Mandarin orange-1"], "operation"]], [[["Captain Citrus-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 752, "term": "Super Mario", "description": "platform video game series from Nintendo's Mario franchise", "question": "Does Super Mario mainly focus on a man in green?", "answer": false, "facts": ["Super Mario follows the adventures of a plumber named Mario.", "Mario wears a red shirt and plumber's overalls."], "decomposition": ["Who is the main character of the game Super Mario?", "Does #1 wear green?"], "evidence": [[[["Super Mario-1"]], [["Mario-29"]]], [[["Super Mario-2"]], [["Mario-6"], "operation"]], [[["Super Mario-1"]], [["Mario-6"]]]]}
{"id": 217, "term": "Sugar Ray Robinson", "description": "American boxer", "question": "Did Sugar Ray Robinson win a fight against Canelo Alvarez?", "answer": false, "facts": ["Sugar Ray Robinson died in 1989", "Canelo Alvarez was born in 1990"], "decomposition": ["In what year did Sugar Ray Robinson die?", "In what year was Canelo Alvarez born?", "Is #2 before #1?"], "evidence": [[[["Sugar Ray Robinson-28"]], [["Canelo Álvarez-1"]], ["operation"]], [[["Sugar Ray Robinson-1"]], [["Canelo Álvarez-1"]], ["operation"]], [[["Sugar Ray Robinson-1"]], [["Canelo Álvarez-1"]], ["operation"]]]}
{"id": 898, "term": "Autumn", "description": "one of the Earth's four temperate seasons, occurring between summer and winter", "question": "Is Autumn a good time to collect bear pelts in US?", "answer": false, "facts": ["Autumn runs from September to the end of December in the US.", "Bears go into hibernation from September through April and are scarcely seen."], "decomposition": ["What months does Autumn occur in the US?", "Where do bear pelts come from?", "What months can #2 be easily seen in the US?", "Do #1 and #3 overlap?"], "evidence": [[[["Autumn-3"]], [["Bear hunting-17"]], [["Brown bear-27"]], [["Autumn-1", "Brown bear-27"]]], [[["Autumn-3"]], [["Bear hunting-23"]], ["no_evidence"], ["operation"]], [[["Autumn-1"]], [["American black bear-1", "Grizzly bear-1"]], [["Bear-39"], "no_evidence"], ["operation"]]]}
{"id": 635, "term": "Curling", "description": "Team sport played on ice", "question": "Are the brooms from curling good for using on house floors?", "answer": false, "facts": ["Curling brooms are designed for use within the sport specifically. ", "Curling brooms do not have traditional bristle heads, and the heads are costly to replace. "], "decomposition": ["What are the characteristics of brooms used in curling?", "What are the characteristics of brooms used for house cleaning?", "Does #1 completely match #2?"], "evidence": [[[["Curling-31"]], [["Broom-2"]], ["operation"]], [[["Curling-31"], "no_evidence"], [["Broom-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Curling-31"]], [["Broom-1"]], ["operation"]]]}
{"id": 848, "term": "French toast", "description": "bread soaked in beaten eggs and then fried", "question": "Can a goat be used for one of the ingredients in French toast?", "answer": true, "facts": ["French toast is made from bread, eggs, milk, and cinnamon.", "Goats are able to produce milk, similar to cows.", "Goats milk is used in a variety of cheeses and milks sold in super markets."], "decomposition": ["What common dairy product can be obtained from goats?", "What are the typical ingredients of French toast?", "Is #1 included in #2?"], "evidence": [[[["Goat-46"]], [["French toast-1"]], ["operation"]], [[["Goat-1"]], [["French toast-2"]], ["operation"]], [[["Goat-46"]], [["French toast-1"]], ["operation"]]]}
{"id": 789, "term": "Sloth", "description": "tree dwelling animal noted for slowness", "question": "Will a sloth explode if it's not upside down?", "answer": false, "facts": ["sloth can climb trees in various positions.", "sloth can crawl along the ground on their stomachs. "], "decomposition": ["What are some common positions that a sloth can stay in?", "Is all of #1 upside down in orientation?"], "evidence": [[[["Sloth-4"], "no_evidence"], ["no_evidence", "operation"]], [[["Sloth-1"]], [["Sloth-1"]]], [[["Sloth-1", "Sloth-2"]], ["operation"]]]}
{"id": 497, "term": "Oceanography", "description": "The study of the physical and biological aspects of the ocean", "question": "Does a person suffering from Thalassophobia enjoy oceanography?", "answer": false, "facts": ["Thalassophobia is a deep and persistent fear of the sea.", "Oceanography is the study of bodies of water.", "Oceanographers frequently observe and interact with bodies of water such as lakes, seas, and oceans."], "decomposition": ["What do people that have thalassophobia fear?", "Oceanography is the study of what?", "Is #1 excluded from #2?"], "evidence": [[[["Thalassophobia-1"]], [["Oceanography-1"]], ["operation"]], [[["Thalassophobia-1"]], [["Oceanography-1"]], ["operation"]], [[["Thalassophobia-1"]], [["Oceanography-1"]], ["operation"]]]}
{"id": 183, "term": "Lecturer", "description": "tenure-track or tenured position at a university or similar institution", "question": "Would Quiet from Metal Gear be a poor hypothetical choice for lecturer at Haub?", "answer": true, "facts": ["Quiet is an assassin from the Metal Gear video game series that does not speak.", "Haub is a school at Pace University that has annual lectures.", "Haub is a law school that has annual lectures on topics in the law field."], "decomposition": ["Who is Quiet?", "What is #1 unable to do?", "How does one convey information as a lecturer?", "Is #2 the same as #3?"], "evidence": [[[["Quiet (Metal Gear)-1"]], [["Quiet (Metal Gear)-5"]], [["Lecture-1"]], ["operation"]], [[["Quiet (Metal Gear)-1"]], [["Quiet (Metal Gear)-7"]], [["Lecture-1"]], ["operation"]], [[["Quiet (Metal Gear)-1"]], [["Quiet (Metal Gear)-7"]], [["Lecture-1"]], ["operation"]]]}
{"id": 433, "term": "Sugar Ray Robinson", "description": "American boxer", "question": "Could Sugar Ray Robinson box if he stole in Iran?", "answer": false, "facts": ["Sugar Ray Robinson was an American boxer who relied on his fists to achieve 109 KO victories.", "The penalty for stealing in Iran is having your hand cut off.", "In August 2015 a prisoner in Iran, who was caught stealing, had his right hand and part of his left leg cut off."], "decomposition": ["What body part does Iran cut off if someone steals?", "What body part is necessary for boxing?", "Is #1 different from #2?"], "evidence": [[[["Hudud-26"]], [["Boxing-1"]], ["operation"]], [[["Guardian Council-2", "Sharia-80"], "no_evidence"], [["Boxing-1", "Boxing-4"]], ["operation"]], [[["Hudud-9"], "no_evidence"], [["Boxing-4"], "operation"], ["operation"]]]}
{"id": 661, "term": "Hollywood", "description": "District in Los Angeles, California, United States", "question": "Is it normally unnecessary to wear a coat in Hollywood in July?", "answer": true, "facts": ["The average high temperature in Hollywood in July is 77.2°F.", "The average low temperature in Hollywood in July is 61.5°F.", "A coat is a garment worn on the upper body for warmth."], "decomposition": ["What is the average high temperature in Hollywood in July?", "What is the average low temperature in Hollywood in July?", "What temperature does one usually wear a coat?", "Is #3 outside of #1 to #2?"], "evidence": [[[["Hollywood-1", "Los Angeles-36"]], [["Los Angeles-34"]], [["Overcoat-1", "Winter-5"]], ["operation"]], [[["Climate of Los Angeles-5", "Climate of Los Angeles-7"], "no_evidence"], [["Climate of Los Angeles-7"], "no_evidence"], [["Winter clothing-1"]], ["operation"]], [[["Los Angeles-35"], "no_evidence"], [["Los Angeles-35"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 527, "term": "Maize", "description": "Cereal grain", "question": "Would a bodybuilder choose maize over chicken breast for dinner?", "answer": false, "facts": ["Bodybuilders aim to eat high amounts of protein in order to stimulate muscle growth.", "Maize contains 9.4 grams of protein per 100 grams.", "Baked chicken breast contains 31 grams of protein per 100 grams."], "decomposition": ["What nutrient is critical for bodybuilding?", "How much #1 is in maize?", "How much #1 is in chicken breast?", "Is #2 greater than #3?"], "evidence": [[[["Bodybuilding-39"]], [["Maize-76"]], ["no_evidence"], ["operation"]], [[["Bodybuilding-41"]], [["Maize-77"], "no_evidence"], [["Chicken as food-11"]], ["no_evidence", "operation"]], [[["Bodybuilding-41"]], [["Maize-76"]], [["Chicken as food-11"]], ["operation"]]]}
{"id": 80, "term": "Marco Polo", "description": "Italian explorer and merchant noted for travel to central and eastern Asia", "question": "Did Marco Polo travel with Christopher Columbus?", "answer": false, "facts": ["Marco Polo died in 1324.", "Christopher Columbus was born in 1451."], "decomposition": ["When did Marco Polo die?", "When was Columbus born?", "Was #1 after #2?"], "evidence": [[[["Marco Polo-1"]], [["Christopher Columbus-1"]], ["operation"]], [[["Marco Polo-24"]], [["Christopher Columbus-5"]], ["operation"]], [[["Marco Polo-24"]], [["Christopher Columbus-5"]], ["operation"]]]}
{"id": 525, "term": "Guitarist", "description": "person who plays the guitar", "question": "Do guitarists need both hands to play?", "answer": true, "facts": ["The left hand typically positions the chords on the fretboard.", "The right hand plays the strings, either strumming a whole chord or finger-picking individual strings.", "The position of the left hand on the fretboard changes the tones of the strings played by the right hand, so both hands are necessary."], "decomposition": ["Which musical instrument do guitarists play?", "How many hands are typically used to play #1?", "Is #2 equal to two?"], "evidence": [[[["Guitarist-1"]], [["Guitarist-2", "Guitarist-3"]], ["no_evidence", "operation"]], [[["Guitarist-1"]], [["Guitar-1"]], ["operation"]], [[["Guitarist-1"]], [["Guitar-1"]], ["operation"]]]}
{"id": 395, "term": "Attack on Pearl Harbor", "description": "Surprise attack by the Imperial Japanese Navy on the U.S. Pacific Fleet in Pearl Harbor in Hawaii", "question": "Was only woman to serve as U.S. Speaker of the House alive during the attack on Pearl Harbor?", "answer": true, "facts": ["Nancy Pelosi is the only woman to ever serve as Speaker of the United States House of Representatives.", "Nancy Pelosi was born on Mar 26, 1940", "The attach on Pearl Harbor occurred on December 7, 1941"], "decomposition": ["Who is the only woman to ever serve as Speaker of the United States House of Representatives?", "When was #1 born?", "When did the attack on Pearl Harbor occur?", "Is #2 before #3?"], "evidence": [[[["Speaker of the United States House of Representatives-3"]], [["Nancy Pelosi-1"]], [["Attack on Pearl Harbor-1"]], ["operation"]], [[["Nancy Pelosi-1"]], [["Nancy Pelosi-1"]], [["Attack on Pearl Harbor-1"]], ["operation"]], [[["Speaker of the United States House of Representatives-3"]], [["Nancy Pelosi-1"]], [["Attack on Pearl Harbor-1"]], ["operation"]]]}
{"id": 421, "term": "Subway (restaurant)", "description": "American fast food chain", "question": "Did Subway have a sex offender as a spokesperson?", "answer": true, "facts": ["Jared Fogle was a national spokesman for the company in the US starting in January 2000.", "Jared Scott Fogle is a convicted sex offender. "], "decomposition": ["Who was the spokesman for Subway in January 2000?", "Has #1 ever been convicted of a sex crime?"], "evidence": [[[["Jared Fogle-2"]], [["Jared Fogle-19"]]], [[["Jared Fogle-1", "Jared Fogle-8"]], [["Jared Fogle-3"], "operation"]], [[["Jared Fogle-1"]], [["Jared Fogle-1"]]]]}
{"id": 96, "term": "Rand Paul", "description": "American politician, ophthalmologist, and United States Senator from Kentucky", "question": "Did Rand Paul frequently swim in Lake Michigan during his undergraduate years?", "answer": false, "facts": ["Rand Paul joined the swim team when he attended Baylor University.", "Baylor University is located in Waco, Texas.", "Lake Michigan is nearly 1,000 miles from Waco, Texas."], "decomposition": ["Where did Rand Paul do his undergraduate studies?", "In what state is #1?", "Is Lake Michigan near #2?"], "evidence": [[[["University of Pittsburgh School of Medicine-26"]], [["Baylor University-1"]], ["operation"]], [[["Rand Paul-2"]], [["Baylor University-1"]], ["operation"]], [[["Rand Paul-9"]], [["Baylor University-1"]], [["Lake Michigan-2"]]]]}
{"id": 45, "term": "Julian calendar", "description": "solar calendar in use from imperial Rome until after the Reformation", "question": "Did Saint Augustine use the Julian calendar?", "answer": true, "facts": ["The Julian calendar was in use from 45 BC to the late 16th century AD", "Saint Augustine lived from 354 AD to 430 AD"], "decomposition": ["During what years was the Julian calendar used?", "When did Saint Augustine live?", "Is #2 during the time period listed in #1?"], "evidence": [[[["Julian calendar-1", "Julian calendar-2"]], [["Augustine of Hippo-1"]], ["operation"]], [[["Julian calendar-1", "Julian calendar-2"]], [["Augustine of Hippo-1"]], ["operation"]], [[["Julian calendar-2"]], [["Augustine of Hippo-1"]], ["operation"]]]}
{"id": 70, "term": "Heracles", "description": "divine hero in Greek mythology, son of Zeus and Alcmene", "question": "Were all of Heracles's children present for his funeral pyre?", "answer": false, "facts": ["Heracles killed his children by his first wife Megara.", "They were not returned to life prior to his death."], "decomposition": ["What did Heracles do to his children by his first wife?", "Are people who have been #1 able to come back to life?"], "evidence": [[[["Heracles-21"], "no_evidence"], [["Death-11"], "operation"]], [[["Megara (mythology)-4"]], [["Death (disambiguation)-1"], "operation"]], [[["Megara (mythology)-4"]], ["operation"]]]}
{"id": 298, "term": "European wildcat", "description": "Small wild cat", "question": "Do black-tailed jackrabbits fear the European wildcat?", "answer": false, "facts": ["The European wildcat is native to continental Europe, Scotland, Turkey and the Caucasus.", "The black-tailed jackrabbit is native to Mexico and the western United States."], "decomposition": ["What is the range of the black-tailed jackrabbit?", "What is the range of the European wildcat?", "Does #1 and #2 overlap?"], "evidence": [[[["Black-tailed jackrabbit-1"]], [["European wildcat-1"]], ["operation"]], [[["Black-tailed jackrabbit-1"]], [["European wildcat-1"]], ["operation"]], [[["Black-tailed jackrabbit-1"]], [["European wildcat-1"]], ["operation"]]]}
{"id": 893, "term": "Ohio University", "description": "public university in Athens, Ohio, United States", "question": "Would the current president of Ohio University hypothetically wear a jockstrap?", "answer": true, "facts": ["The current president of Ohio University is Duane Nellis.", "Duane Nellis is a man.", "A jockstrap is an undergarment for protecting the testes and penis during cycling, contact sports or other vigorous physical activity.", "The testes and penis are the sexual organs of men."], "decomposition": ["Which gender wears jockstrap?", "Who is the current President of Ohio University?", "Does #2 identify with the gender #1?"], "evidence": [[[["Jockstrap-1"]], [["Duane Nellis-1"]], ["operation"]], [[["Jockstrap-1"]], [["Kristina M. Johnson-1"], "no_evidence"], ["operation"]], [[["Thong-27"]], [["Duane Nellis-1"]], ["operation"]]]}
{"id": 266, "term": "Dosa", "description": "Thin pancakes originating from South India", "question": "Would lumberjacks get full after eating three dosa?", "answer": false, "facts": ["Dosa are thin rice pancakes from South India.", "One dosa is approximately 110 calories.", "The average lumberjack would eat 8000 calories per day."], "decomposition": ["What is a Dosa?", "How many calories are in #1?", "How many calories does a lumberjack need per day?", "Is 3 times #2 a significant amount of #3?"], "evidence": [[[["Dosa-1"]], ["no_evidence"], [["Food energy-14"]], ["operation"]], [[["Dosa-1"]], ["no_evidence"], ["no_evidence"], ["operation"]], [[["Dosa-1"]], ["no_evidence"], [["Food energy-14", "Lumberjack-1"], "no_evidence"], ["operation"]]]}
{"id": 427, "term": "Jack Dempsey", "description": "American boxer", "question": "Did Jack Dempsey have most title fight wins in either of his weight classes?", "answer": false, "facts": ["Jack Dempsey competed as a heavyweight and a lightheavyweight.", "Jack Dempsey only had a handful of title defenses as heavyweight champion.", "Wladimir Klitschko had 25 heavyweight title fight wins.", "Jack Dempsey did not hold the lightheavyweight title.", "Dariusz Michalczewski had 23 lightheavyweight title fight wins."], "decomposition": ["What weight class did Jack Dempsey have title fight wins in?", "How many title fight wins did Jack Dempsey have in #1?", "How many title fight wins did Wladimir Klitschko have in #1?", "Is #2 greater than #3?"], "evidence": [[[["Jack Dempsey-1"]], [["Jack Dempsey-12", "Jack Dempsey-22", "Jack Dempsey-23", "Jack Dempsey-26", "Jack Dempsey-27", "Jack Dempsey-28"]], [["Wladimir Klitschko-4"]], ["operation"]], [[["Jack Dempsey-1"]], [["Jack Dempsey-11"], "no_evidence"], [["Heavyweight-6"]], ["operation"]], [[["Jack Dempsey-1"]], [["Jack Dempsey-12", "Jack Dempsey-23", "Jack Dempsey-24", "Jack Dempsey-28"], "no_evidence"], [["Wladimir Klitschko-4"]], ["operation"]]]}
{"id": 290, "term": "Jeremy Irons", "description": "English actor", "question": "Did Jeremy Irons master sweep picking as a child?", "answer": false, "facts": ["Jeremy Irons was the drummer and harmonica player in a four-man school band called the Four Pillars of Wisdom.", "Sweep picking is a guitar playing technique."], "decomposition": ["What kind of musical instrument involves sweet picking?", "What musical instruments did Jeremy Irons play in the school band Four Pillars of Wisdom?", "Is #1 included in #2?"], "evidence": [[[["Sweep picking-1"]], [["Jeremy Irons-5"]], ["operation"]], [[["Sweep picking-1"]], [["Jeremy Irons-5"]], ["operation"]], [[["Guitar picking-14"]], [["Jeremy Irons-5"]], ["operation"]]]}
{"id": 332, "term": "1999", "description": "Year", "question": "Were some people afraid of New Years Day coming in 1999?", "answer": true, "facts": ["It was believed that computers might not know how to change from 1999 to 2000 on New Years Day.", "People were concerned that human services and utilities that were computerized might crash due to the Y2K bug.", "People believed that the year 2000 would cause computers to crash due to the 'Y2K' bug."], "decomposition": ["Which New Year's Day followed 1999?", "What concerns were there about computers during the transition from 1999 to #1?", "Was #2 a cause of fear?"], "evidence": [[[["January 1-1"], "no_evidence"], [["Year 2000 problem-1"]], ["operation"]], [[["Year 2000 problem-3"]], [["Year 2000 problem-1"]], ["operation"]], [[["New Year's Day-1", "Year 2000 problem-15"]], [["Year 2000 problem-1"]], [["2000-3", "Year 2000 problem-15"]]]]}
{"id": 620, "term": "Olive oil", "description": "liquid fat extracted by pressing olives", "question": "Would Carmine's kitchen staff be panicked if they had no olive oil?", "answer": true, "facts": ["Carmine's is an Italian restaurant.", "Olive oil is a large component of a lot of Italian cooking."], "decomposition": ["What kind of food does Carmine's serve?", "What are essential ingredients in #1?", "Is olive oil listed in #2?"], "evidence": [[["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], [["Pizza in the United States-3"]], ["operation"]], [[["Carmine Romano-2"], "no_evidence"], [["Italian cuisine-16"]], ["operation"]]]}
{"id": 928, "term": "Dance", "description": "A performing art consisting of movement of the body", "question": "Is waltz less injurious than slam dance?", "answer": true, "facts": ["The waltz is a rhythmic dance performed in triple time by a couple.", "A slam dance is a type of dance in which leaping dancers collide against each other."], "decomposition": ["What kinds of body movements are involved in waltz?", "What kinds of body movements are involved in slam dance?", "Is #1 less likely to cause injuries than #2?"], "evidence": [[[["Waltz-2"], "no_evidence"], [["Moshing-1"]], [["Moshing-4"], "operation"]], [[["Waltz-5"]], [["Moshing-1"]], [["Moshing-4"], "operation"]], [[["Ballroom dance-28", "Waltz-1"]], [["Moshing-1"]], [["Moshing-4"], "operation"]]]}
{"id": 652, "term": "Breast", "description": "Region of the torso of a primate containing the mammary gland", "question": "Do people in middle school usually get breast exams?", "answer": false, "facts": ["Women should begin giving themselves breast exams at the age of 20.", "Middle school students are usually preteens or young teens."], "decomposition": ["What age do people usually get breast exams?", "How old are the students in Middle school in the US?", "Is #1 the same as #2?"], "evidence": [[[["Mammography-1", "Mammography-3"]], [["Secondary education in the United States-1"]], ["operation"]], [[["Mammography-1", "Mammography-3"]], [["Middle school-88"]], ["operation"]], [[["Breast cancer screening-3"]], [["Secondary education in the United States-1"]], ["operation"]]]}
{"id": 883, "term": "One Thousand and One Nights", "description": "Collection of Middle Eastern stories and folk tales compiled in Arabic during the Islamic Golden Age", "question": "Was The Canterbury Tales written before One Thousand and One Nights?", "answer": false, "facts": ["One Thousand and One Nights was compiled during the Islamic Golden Age.", "The Islamic Golden Age lasted from 800 AD to 1258 AD.", "The Canterbury Tales was written in 1392."], "decomposition": ["When were the The Canterbury Tales written?", "When was One Thousand and One Nights written?", "Which years are included in #2?", "Is #1 before #3?"], "evidence": [[[["The Canterbury Tales-7"]], [["One Thousand and One Nights-1"]], [["One Thousand and One Nights-1"]], [["The Canterbury Tales-7"]]], [[["The Canterbury Tales-1"]], [["One Thousand and One Nights-13"], "no_evidence"], [["One Thousand and One Nights-33"], "no_evidence"], ["operation"]], [[["The Canterbury Tales-1"]], [["One Thousand and One Nights-1"]], [["Islamic Golden Age-1"]], ["operation"]]]}
{"id": 797, "term": "DARPA", "description": "Agency of the U.S. Department of Defense responsible for the development of new technologies", "question": "Did DARPA influence Albert Einstein? ", "answer": false, "facts": ["DARPA is an agency in the US focused on defense and new technologies.", "DARPA was founded in 1958 under Dwight D Eisenhower.", "Albert Einstein was a famous physicist who died in 1955."], "decomposition": ["When was DARPA formed?", "When did Albert Einstein die?", "Is #1 before #2?"], "evidence": [[[["DARPA-2"]], [["Albert Einstein-1"]], ["operation"]], [[["DARPA-2"]], [["Albert Einstein-1"]], ["operation"]], [[["DARPA-2"]], [["Albert Einstein-1"]], ["operation"]]]}
{"id": 391, "term": "The Godfather", "description": "1972 film directed by Francis Ford Coppola", "question": "Is Y2K relevant to the plot of The Godfather?", "answer": false, "facts": ["The story in the Godfather spans from 1945 to 1955.", "Y2K refers to events related to the formatting and storage of calendar data for dates beginning in the year 2000."], "decomposition": ["What era is the story of The Godfather set in?", "What year does Y2K refer to?", "Is #2 included in #1?"], "evidence": [[[["The Godfather-1"]], [["Year 2000 problem-1"]], ["operation"]], [[["The Godfather-1"]], [["Year 2000 problem-10"]], ["operation"]], [[["The Godfather-1"]], [["Year 2000 problem-1"]], ["operation"]]]}
{"id": 504, "term": "Durian", "description": "genus of plants", "question": "Are Durian fruits an olfactory delight?", "answer": false, "facts": ["Durian is a plant type that produces several kinds of fruit.", "Olfactory refers to the human sense of smell.", "Pleasant smells according to polls include flowers and sweet foods.", "Durian fruits have been banned in Singapore due to its overwhelming smell."], "decomposition": ["What kind of smell is the durian known for?", "Is #1 pleasant?"], "evidence": [[[["Durian-3"]], ["operation"]], [[["Durian-3"]], ["operation"]], [[["Durian-3"]], [["Durian-3"]]]]}
{"id": 931, "term": "Earth Day", "description": "Annual event on 22 April", "question": "Is Earth Day celebrated in summer?", "answer": false, "facts": ["Earth Day is celebrated on April 22.", "Summer runs from about June 20 to September 20."], "decomposition": ["What is summer?", "What is the date of Earth day?", "Is #2 in #1?"], "evidence": [[[["Summer-2"]], [["Earth Day-30"]], ["operation"]], [[["Summer-5"]], [["Earth Day-1"]], ["operation"]], [[["Summer-2"]], [["Earth Day-1"]], ["operation"]]]}
{"id": 976, "term": "Saint Kitts and Nevis", "description": "country in Central America and Caribbean", "question": "Are brown rock fish found in the waters surrounding Saint Kitts and Nevis?", "answer": false, "facts": ["Saint Kitts and Nevis is located in the Caribbean Sea and Atlantic Sea", "Brown rock fish are found in the Pacific Ocean"], "decomposition": ["What waters surround Saint Kitts and Nevis?", "In what body of water are brown rock fish found?", "Is #1 the same as #2?"], "evidence": [[[["Saint Kitts and Nevis-1"]], [["Brown rockfish-3"]], ["operation"]], [[["Saint Kitts-1"]], [["Brown rockfish-3"]], ["operation"]], [[["Saint Kitts-1"]], [["Brown rockfish-2"]], ["operation"]]]}
{"id": 870, "term": "Final Fantasy VI", "description": "1994 video game", "question": "Does Final Fantasy VI require electricity to play?", "answer": true, "facts": ["Final Fantasy VI is a video game.", "Video games are played using a video game console and television.", "Video game consoles and televisions require electricity in order to function."], "decomposition": ["Which device(s) would be needed to play the video game Final Fantasy VI?", "Do any of #1 run on electricity?"], "evidence": [[[["Final Fantasy VI-2"]], [["Super Nintendo Entertainment System-22"]]], [[["Final Fantasy VI-1", "Super Nintendo Entertainment System-1"]], ["operation"]], [[["Final Fantasy VI-1"]], [["Video game console-1"], "operation"]]]}
{"id": 117, "term": "Viscosity", "description": "Resistance of a fluid to shear deformation", "question": "Do people with swallowing disorders need high viscosity drinks?", "answer": true, "facts": ["Swallowing disorders can make thin liquids like water dangerous to drink.", "Liquid thickeners are marketed towards people with difficulty drinking."], "decomposition": ["If a person has a swallowing disorder, what types of liquids are dangerous for them to drink?", "Are high viscosity drinks the opposite of #1?"], "evidence": [[[["Thickened fluids-1"]], [["Viscosity-1"], "operation"]], [[["Dysphagia-2"], "no_evidence"], [["Viscosity-1"], "operation"]], [[["Oropharyngeal dysphagia-2"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 112, "term": "The Young and the Restless", "description": "television series", "question": "Would a binge watch of entire Young and the Restless take longer than a leap year?", "answer": true, "facts": ["A leap year has 366 total days.", "As of March 19th, 2018, every episode of the Young and the Restless would take 467 days and 2 hours to watch."], "decomposition": ["How many days are in a leap year?", "How long would it take to watch every episode of the Young and the Restless?", "Is #2 greater than #1?"], "evidence": [[[["Leap year-2"]], [["The Young and the Restless-1", "The Young and the Restless-12"], "no_evidence"], ["operation"]], [[["Leap year-1", "Leap year-6"]], [["The Young and the Restless-1", "The Young and the Restless-12"], "no_evidence"], ["operation"]], [[["Leap year-2"]], [["The Young and the Restless-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 949, "term": "Alice's Adventures in Wonderland", "description": "book by Lewis Carroll", "question": "Would a Jehovah's witness approve of Alice's Adventures in Wonderland?", "answer": false, "facts": ["Jehovah's Witness is a religious group that strictly forbids tobacco and smoking.", "A prominent character in Alice's Adventures in Wonderland, the caterpillar, blows rings of smoke from a large pipe."], "decomposition": ["What are Jehovah's Witnesses?", "What items do #1's forbid?", "In Alice's Adventures in Wonderland, what is the caterpillar seen doing with a pipe?", "Is #2 different from #3?"], "evidence": [[[["Jehovah's Witnesses-1"]], [["Religious views on smoking-6"]], [["Caterpillar (Alice's Adventures in Wonderland)-6"]], ["operation"]], [[["Jehovah's Witnesses-1"]], [["Jehovah's Witnesses-36"]], [["Alice's Adventures in Wonderland-13"]], ["operation"]], [[["Jehovah's Witnesses-1"]], [["Jehovah's Witnesses practices-27"], "no_evidence"], [["Alice's Adventures in Wonderland-13"]], ["no_evidence", "operation"]]]}
{"id": 807, "term": "Potato", "description": "plant species producing the tuber used as a staple food", "question": "Are potatoes native to the European continent?", "answer": false, "facts": ["Potatoes originated in South America and spread throughout the Americas by indigenous tribes.", "European explorers discovered potatoes and brought them back to share at home in Europe."], "decomposition": ["Where did potatoes originate?", "Is #1 located in Europe?"], "evidence": [[[["Potato-13"]], [["Potato-13"]]], [[["Potato-2"]], ["operation"]], [[["Potato-2"]], [["Peru-1"]]]]}
{"id": 325, "term": "Pompey", "description": "1st/2nd-century BC Roman general", "question": "Has type of political association Pompey had with Caesar influenced reality TV?", "answer": true, "facts": ["Pompey, Julius Caesar, and Marcus Licinius Crassus formed a political association called a triumvirate.", "A triumvirate spits rule between three powerful people that get to make decisions.", "Reality show The Challenge: Total Madness appoints three weekly winners to make decisions for the group, known as the Tribunal.", "Reality show American Idol has had three judges making decisions about which contestants advance."], "decomposition": ["Which political association did Pompey form with Julius Caesar and Marcus Licinius Crassus?", "How many people does #1 typically involve?", "How many judges are on reality show American Idol?", "Is #2 equal to #3?"], "evidence": [[[["First Triumvirate-1"]], [["Triumvirate-1"]], [["American Idol-10", "American Idol-9"]], ["operation"]], [[["Pompey-2"]], [["First Triumvirate-1"]], [["American Idol-3"]], ["operation"]], [[["Triumvirate-5"]], [["Triumvirate-3"]], [["American Idol-3"]], ["operation"]]]}
{"id": 160, "term": "Gulf of Mexico", "description": "An Atlantic Ocean basin extending into southern North America", "question": "Are fossil fuels reducing jobs in the Gulf of Mexico?", "answer": true, "facts": ["An oil spill is still polluting the Gulf of Mexico", "Workers such as fishermen are out of work due to pollution"], "decomposition": ["What are the consequences of fossil fuel presence in the Gulf of Mexico?", "Is #1 putting some people out of job?"], "evidence": [[[["Deepwater Horizon oil spill-2", "Taylor oil spill-2"]], [["Deepwater Horizon oil spill-71", "Deepwater Horizon oil spill-72"], "operation"]], [[["Gulf of Mexico-38"]], [["Gulf of Mexico-38"], "no_evidence"]], [[["Gulf of Mexico-42"]], ["no_evidence"]], [[["Gulf of Mexico-42"]], [["Gulf of Mexico-36"], "no_evidence", "operation"]]]}
{"id": 126, "term": "C-SPAN", "description": "American pay television network", "question": "Does the name C-SPAN refer to a form of telecommunications that utilizes outer space?", "answer": true, "facts": ["The S in C-SPAN refers to Satellite.", "Satellite communications require communicating with satellites that orbit the Earth in outer space."], "decomposition": ["What does C-SPAN's transmission equipment consist of, according to its full meaning?", "Is any of #1 located in outer space?"], "evidence": [[[["Cable television-2"]], [["Satellite-1"], "operation"]], [[["C-SPAN-14"]], [["Technology of television-4"]]], [[["C-SPAN-1"]], [["Satellite-1"]]]]}
{"id": 224, "term": "Depression (mood)", "description": "state of low mood and fatigue", "question": "In teenagers and young adults with depression, are SSRI medications less safe than they are for adults?", "answer": true, "facts": ["In teens, SSRI medications may increase the risk of suicidal thinking.", "In adults over 25, SSRI medications are regarded as generally safe."], "decomposition": ["What are potential side effects of SSRIs for adults?", "What are the potential side effects of SSRIs for teenagers?", "Are the hazards in #2 worse than the hazards in #1?"], "evidence": [[[["Selective serotonin reuptake inhibitor-37"]], [["Selective serotonin reuptake inhibitor-33"]], ["operation"]], [[["Development and discovery of SSRI drugs-10"], "no_evidence"], [["Development and discovery of SSRI drugs-10"], "no_evidence"], ["no_evidence"]], [[["Selective serotonin reuptake inhibitor-21"], "no_evidence"], [["Selective serotonin reuptake inhibitor-33"]], ["operation"]]]}
{"id": 953, "term": "Tibia", "description": "larger of the two bones of the leg below the knee for vertebrates", "question": "Is the tibia required for floor exercises?", "answer": true, "facts": ["The tibia is a bone in the lower leg", "Floor exercises are a program in gymnastics competitions", "Gymnastics requires use of arms and legs, as well as other parts of the body"], "decomposition": ["What sport are floor exercises part of?  ", "What body parts does #1 require?", "What part of the body part is the tibia?", "Is #3 in #2?"], "evidence": [[[["Floor (gymnastics)-17"]], [["Leg-6"]], [["Tibia-1"]], ["operation"]], [[["Floor (gymnastics)-1"]], [["Gymnastics-1"]], [["Tibia-1"]], ["operation"]], [[["Floor (gymnastics)-1"]], [["Floor (gymnastics)-2"]], [["Tibia-1"]], ["operation"]]]}
{"id": 393, "term": "Chives", "description": "edible species of plant", "question": "Could chives be mistaken for grass?", "answer": true, "facts": ["Chives grow upwards in thin green cylindrical shoots. ", "Grass grows upwards in thin green flat shoots."], "decomposition": ["What is the shape and color of Chives?", "What is the shape and color of grass?", "Is #1 the same as #2?"], "evidence": [[[["Chives-4"]], ["no_evidence"], ["operation"]], [[["Chives-4"], "no_evidence"], [["Poaceae-42"], "no_evidence"], ["operation"]], [[["Chives-6"]], [["Poaceae-15"], "no_evidence"], ["operation"]]]}
{"id": 368, "term": "Barley", "description": "Species of plant", "question": "Would the owners of the company Peter Griffin works for need barley?", "answer": true, "facts": ["Peter Griffin works for Pawtucket Brewery.", "Pawtucket Brewery produces beer.", "Barley is the preferred grain for making beer."], "decomposition": ["What kind of company is Peter Griffin?", "What does #1 produce?", "Does producing #2 require barley?"], "evidence": [[[["Peter Griffin-2"], "no_evidence"], [["Brewery-1"]], [["Brewery-27"], "operation"]], [[["Peter Griffin-2"]], [["Brewery-1"]], [["Beer-1"], "operation"]], [[["Peter Griffin-2"]], [["Brewery-1"]], [["Barley-1"]]]]}
{"id": 595, "term": "Monarch butterfly", "description": "milkweed butterfly in the family Nymphalidae", "question": "Could a monarch butterfly rule a kingdom?", "answer": false, "facts": ["A monarch butterfly would be easily killed by a human due to its small size.", "A monarch butterfly does not have the intellectual capacity to rule over a kingdom of humans."], "decomposition": ["Does a monarch butterfly have the physical capacity to rule over humans?", "Does a monarch butterfly have the intellectual ability to rule over humans?", "Is #1 or #2 positive?"], "evidence": [[[["Monarch butterfly-1"]], [["Monarch butterfly-1"]], [["Monarch butterfly-1"]]], [[["Monarch butterfly-1"]], [["Butterfly-15"], "no_evidence"], ["operation"]], [[["Monarch butterfly-1"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 934, "term": "New Testament", "description": "Second division of the Christian biblical canon", "question": "Would a kindergarten teacher make a lesson of the New Testament?", "answer": false, "facts": ["The majority of Kindergarten teachers work in public schools.", "Public schools abide by a separation of church and state, and do not have any overall religion.", "Students of all religions are welcome to attend public school."], "decomposition": ["Where do the majority of kindergarten teachers work?", "Do students in #1 follow a paritcular religion?"], "evidence": [[[["Kindergarten-1"]], [["Kindergarten Playway-3"]]], [[["Kindergarten-89"]], [["Education in the United States-2"], "no_evidence"]], [[["Education in the United States-47"]], [["School prayer in the United States-1"], "operation"]]]}
{"id": 816, "term": "High Speed 1", "description": "high-speed railway between London and the Channel Tunnel", "question": "Would the tunnels at CERN fit onto the High Speed 1 rails?", "answer": true, "facts": ["High Speed 1 (HS1), legally the Channel Tunnel Rail Link (CTRL), is a 67-mile (108 km) high-speed railway.", "The CERN collider is contained in a circular tunnel, with a circumference of 26.7 kilometres (16.6 mi).", "The circumference of a circle is the length of the enclosing boundary."], "decomposition": ["How long are the tunnels at the CERN collider?", "How long is the High Speed 1 railway?", "Is #1 less than or equal to #2?"], "evidence": [[[["Large Electron–Positron Collider-2"]], [["High Speed 1-1"]], ["operation"]], [[["CERN-18"]], [["High Speed 1-1"]], ["operation"]], [[["CERN-18"]], [["High Speed 1-1"]], ["operation"]]]}
{"id": 22, "term": "Riksdag", "description": "Legislative body of Sweden", "question": "Is the Riksdag a political entity in Scandinavia?", "answer": true, "facts": ["The Riksdag is the legislative branch of the Swedish government.", "Sweden is part of Scandinavia."], "decomposition": ["What country does the Riksdag belong to?", "Which countries are part of Scandinavia?", "Is #1 included in #2?"], "evidence": [[[["Riksdag-1"]], [["Scandinavia-1"]], ["operation"]], [[["Riksdag-1"]], [["Scandinavia-1"]], ["operation"]], [[["Riksdag-1"]], [["Scandinavia-1"]], ["operation"]]]}
{"id": 948, "term": "Argon", "description": "Chemical element with atomic number 18", "question": "Can you chew argon?", "answer": false, "facts": ["Chewing is the act of breaking down solid objects with your teeth", "Under normal conditions, argon exists as a gas"], "decomposition": ["What kind of substance is argon?", "Do humans usually chew #1?"], "evidence": [[[["Argon-1"]], [["Chewing-1"], "operation"]], [[["Argon-1"]], [["Chewing-1"]]], [[["Argon-1"]], ["operation"]]]}
{"id": 501, "term": "Golden Gate Bridge", "description": "suspension bridge on the San Francisco Bay", "question": "Do depressed people travel to the Golden Gate Bridge often?", "answer": true, "facts": ["The Golden Gate Bridge is one of the most popular suicide spots in the USA.", "Suicide is often caused by severe depression."], "decomposition": ["What is the ultimate end that severe depression can lead to?", "Is the Golden Gate Bridge a place where #1 is known to often happen?"], "evidence": [[[["Major depressive disorder-22"]], [["Suicides at the Golden Gate Bridge-4"], "operation"]], [[["Suicide-7"]], [["Golden Gate Bridge-50"]]], [[["Suicide-1"]], [["Suicides at the Golden Gate Bridge-4"]]]]}
{"id": 762, "term": "WWE Raw", "description": "WWE television program", "question": "Would a viewer of Monday Night Football be able to catch WWE Raw during commercial breaks?", "answer": true, "facts": ["Monday Night Football begins at 8pm EST on Monday nights during the NFL season", "WWE Raw airs on Monday nights between 8pm and 11pm EST"], "decomposition": ["When does Monday Night Football air?", "When does WWE Raw air?", "Is there and overlap between #1 and #2?"], "evidence": [[[["Monday Night Football-68"]], [["WWE Raw-1"]], ["operation"]], [[["Monday Night Football-7"], "operation"], [["WWE Raw-59"], "operation"], ["operation"]], [[["Monday Night Football-68"]], [["WWE Raw-1"]], ["operation"]]]}
{"id": 763, "term": "Voyager 2", "description": "Space probe and the second-farthest man-made object from Earth", "question": "Would Jon Brower Minnoch break a chair before Voyager 2 launch mass?", "answer": false, "facts": ["Jon Brower Minnoch was the heaviest human being ever recorded.", "At his peak weight, Jon Brower Minnoch weighed almost 1.400 lb.", "The launch mass of Voyager 2 was 1,820 lb."], "decomposition": ["What was Jon Brower Minnoch's heaviest weight?", "What was the Voyager 2 launch mass?", "Is #1 greater than #2?"], "evidence": [[[["Jon Brower Minnoch-1"]], [["Voyager 2-9"]], ["operation"]], [[["Jon Brower Minnoch-1"]], [["Voyager 2-9"]], ["operation"]], [[["Jon Brower Minnoch-5"]], ["no_evidence"], ["operation"]]]}
{"id": 64, "term": "Cuban Revolution", "description": "Revolution in Cuba between 1953 and 1959", "question": "During the Cuban revolution, did the US experience a population boom?", "answer": true, "facts": ["After WWII, the US experienced a baby boom.", "WWII ended in 1945."], "decomposition": ["When was the Cuban Revolution?", "When did the United States experience a rapid growth in its population?", "Does some or all of #2 overlap with #1?"], "evidence": [[[["Cuban Revolution-8"]], [["Baby boom-3"]], [["Baby boom-3", "Cuban Revolution-8"], "operation"]], [[["Cuban Revolution-1"]], [["Mid-twentieth century baby boom-1", "Mid-twentieth century baby boom-3"]], ["operation"]], [[["Cuban Revolution-1"]], [["Mid-twentieth century baby boom-12"]], ["operation"]]]}
{"id": 29, "term": "Snowshoe", "description": "Footwear for walking easily across snow", "question": "Can a snake wear a snowshoe?", "answer": false, "facts": ["Snowshoes are worn by attaching them to the wearer's feet.", "Snakes do not have feet."], "decomposition": ["Which part of the body are snowshoes worn on?", "Do snakes have #1?"], "evidence": [[[["Snowshoe-1"]], [["Snake-1"]]], [[["Snowshoe-1"]], [["Snake-1"], "operation"]], [[["Footwear-1", "Snowshoe-1"]], [["Snake-1"]]]]}
{"id": 794, "term": "Kaffir lime", "description": "A citrus fruit native to tropical Southeast Asia and southern China", "question": "Would a kaffir lime be a good ingredient for making a candle?", "answer": true, "facts": ["Kaffir limes are citrus fruits originating in tropical climates.", "The Kaffir lime leaves and rind emit an intense citrus fragrance when crushed up.", "Yankee Candle, one of the largest candle companies, sells several popular varieties of citrus candles.", "Sage and Citrus is one of the highest rated scents that Yankee Candle sells."], "decomposition": ["Which fragrance do Kaffir lime leaves emit when crushed?", "What are the scents of some popular varieties of candles that Yankee Candle sells?", "Is #2 included in #1?"], "evidence": [[[["Kaffir lime-2"]], [["Yankee Candle-14"], "no_evidence"], ["operation"]], [[["Kaffir lime-8"], "no_evidence"], [["Yankee Candle-14"], "no_evidence"], ["no_evidence", "operation"]], [[["Kaffir lime-2"]], [["Yankee Candle-14"], "no_evidence"], ["no_evidence"]]]}
{"id": 310, "term": "Lionel Richie", "description": "American singer-songwriter, musician, record producer and actor", "question": "Is Lionel Richie related to Sheila E?", "answer": false, "facts": ["Lionel Richie is an American singer and raised Nicole Richie.", "Nicole Richie was born to Sheila E's brother, Peter Michael Escovedo.", "Lionel Richie adopted Nicole Richie from Peter Michael Escovedo.", "Adoptive parents are not considered related to birth parents."], "decomposition": ["What is the relationship between Lionel Richie and Nicole Richie?", "Are #1 considered related to birth parents?"], "evidence": [[[["Lionel Richie-27"]], [["Adoption-1"], "operation"]], [[["Nicole Richie-3"]], ["operation"]], [[["Lionel Richie-27"]], [["Adoption-1"]]]]}
{"id": 55, "term": "Samsung Galaxy", "description": "series of Android mobile computing devices", "question": "Can you save every HD episode of Game of Thrones on Samsung Galaxy A10e?", "answer": false, "facts": ["The Samsung Galaxy A10e has 32GB of storage.", "The average storage requirement of an HD episode of Game of Thrones is 600MB", "There are 60 total episodes of Game of Thrones.", "There are 1000MB in one GB."], "decomposition": ["How much storage does a Samsung Galaxy A10e have?", "What is #1 multiplied by 1000?", "What is the average storage requirement for an HD episode of Game of Thrones?", "How many episodes are the of Game of Thrones?", "Is #2 greater than or equal to #3 multiplied by #4?"], "evidence": [[[["Samsung Galaxy A10-1"]], ["operation"], ["no_evidence"], [["The Iron Throne (Game of Thrones)-1"]], ["no_evidence", "operation"]], [[["Samsung Galaxy-1"], "no_evidence"], ["no_evidence", "operation"], [["High-definition video-18"], "no_evidence"], [["Game of Thrones-1"]], ["no_evidence", "operation"]], [[["Samsung Galaxy A10-1"]], ["operation"], [["Game of Thrones (season 1)-26"], "no_evidence"], [["Game of Thrones-1"]], ["operation"]]]}
{"id": 392, "term": "Scrabble", "description": "board game with words", "question": "Could a two-year old win a Scrabble tournament?", "answer": false, "facts": ["Scrabble is a word game that requires a large vocabulary in order to play well.", "A two-year old has a very limited vocabulary and lacks the reasoning capability needed to perform well in Scrabble."], "decomposition": ["What size vocabulary do Scrabble champions have?", "What size vocabulary do two-year olds have?", "is #2 greater than #1?"], "evidence": [[["no_evidence"], [["Language development-13"]], ["no_evidence", "operation"]], [[["World Scrabble Championship-4"], "no_evidence"], [["Vocabulary-3"], "no_evidence"], ["no_evidence", "operation"]], [[["Official Scrabble Players Dictionary-9"], "no_evidence"], [["Toddler-5"]], ["operation"]]]}
{"id": 343, "term": "Red hair", "description": "Hair color", "question": "Does a Disney princess on Broadway have red hair?", "answer": true, "facts": ["Ariel, the princess from Disney's the Little Mermaid, has red hair.", "The Little Mermaid is one of several Disney animated classics that was adapted for the stage and performed on Broadway."], "decomposition": ["What is the name of the princess with red hair?", "What is the name of the animated classic in which #1 is the main star of?", "Has #2 been adapted for Broadway?"], "evidence": [[[["Merida (Brave)-9"]], [["Merida (Brave)-10"]], [["Disney Princess-36"]]], [[["Ariel (The Little Mermaid)-7", "Merida (Brave)-9"]], [["Ariel (The Little Mermaid)-1", "Merida (Brave)-1"]], [["Ariel (The Little Mermaid)-33"]]], [[["Ariel (The Little Mermaid)-7"]], [["Ariel (The Little Mermaid)-49"]], [["The Little Mermaid (musical)-1"], "operation"]]]}
{"id": 146, "term": "Charlemagne", "description": "King of the Franks, King of Italy, and Holy Roman Emperor", "question": "Would Temujin hypothetically be jealous of Charlemagne's conquests?", "answer": false, "facts": ["Temujin was the birth name of Genghis Khan.", "Genghis Khan founded the Mongol Empire which was the largest land empire in world history.", "Charlemagne, King of the Franks, conquered most of Western Europe.", "At its peak, the Mongol Empire had 110 million people.", "Charlemagne's empire had around 20 million people at its height."], "decomposition": ["Temujin was the name of which leader?", "How many people did #1's empire have at its peak?", "How many people did Charlemagne's empire have at its peak?", "Is #3 greater than #2?"], "evidence": [[[["Genghis Khan-1"]], ["no_evidence"], [["Carolingian Empire-1", "Carolingian Empire-3"]], ["no_evidence", "operation"]], [[["Genghis Khan-1"]], [["Mongol Empire-1"], "no_evidence"], [["Carolingian Empire-3", "Charlemagne-1"]], ["no_evidence", "operation"]], [[["Genghis Khan-1"]], [["Mongol Empire-109"], "no_evidence"], [["Carolingian Empire-1", "Carolingian Empire-3"]], ["operation"]]]}
{"id": 47, "term": "Wheat", "description": "Cereal grain", "question": "Can a woman on average have a baby before wheat seed blooms?", "answer": false, "facts": ["The average time it takes for a woman to give birth is 9 months.", "Wheat takes between 7 to 8 months to harvest."], "decomposition": ["How long does pregnancy typically last in humans?", "How long does it typically take to grow and harvest wheat?", "Is #1 shorter than #2?"], "evidence": [[[["Pregnancy-1"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Pregnancy-1"]], [["Intensive crop farming-11"]], ["operation"]], [[["Pregnancy-1"]], [["Intensive crop farming-11"]], ["operation"]]]}
{"id": 49, "term": "Vice President of the United States", "description": "Second highest executive office in United States", "question": "Was the first Vice President of the United States an Ottoman descendant?", "answer": false, "facts": ["The first Vice President of the United States was John Adams.", "The Ottomans were a Turkic group that conquered Constantinople in 1453.", "John Adams was descended from English Puritans."], "decomposition": ["Who was the first Vice President of the United States?", "Which group of people was #1 a descendant of?", "Is #2 the same as Ottoman?"], "evidence": [[[["John Adams-1"]], [["John Adams-5"], "no_evidence"], [["Ottoman dynasty-1"], "operation"]], [[["Vice President of the United States-52"]], [["John Adams-6"], "no_evidence"], [["Christianity in the modern era-12"], "operation"]], [[["John Adams-1"]], [["John Adams-5"]], ["operation"]]]}
{"id": 375, "term": "History of Europe", "description": "History of Europe from the beginnings of recorded history", "question": "Does the history of Europe include the age of dinosaurs?", "answer": false, "facts": ["Dinosaurs went extinct many millions of years ago.", "In contrast, ancient humans only started recording history several thousand years ago."], "decomposition": ["When did the dinosaurs exist?", "When did humans first colonize Europe?", "Is #2 contained within the range of #1?"], "evidence": [[[["Dinosaur-1"]], [["Europe-29"]], ["operation"]], [[["Dinosaur-1"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Dinosaur-1"]], [["Hominid dispersals in Europe-10"]], ["operation"]]]}
{"id": 677, "term": "Swan", "description": "large water bird", "question": "Would a Nike shoebox be too small to fit a swan in?", "answer": true, "facts": ["Nike Shoeboxes are usually 14\" x 10\" x 5\".", "An average swan is 4-5.6 ft in length."], "decomposition": ["What is the average size of a Nike Shoebox?", "What is the average length of a swan?", "Is #2 smaller than #1?"], "evidence": [[[["Shoe size-13", "Sneakers-16"], "no_evidence"], [["Swan-3"], "no_evidence"], ["operation"]], [[["Shoe-1"], "no_evidence"], [["Swan-3"]], ["operation"]], [["no_evidence"], [["Swan-3"]], ["no_evidence", "operation"]]]}
{"id": 24, "term": "Quran", "description": "The central religious text of Islam", "question": "Would Dave Chappelle pray over a Quran?", "answer": true, "facts": ["Dave Chappelle converted to Islam in 1998.", "Dave Chappelle has not deviated from his religious beliefs since 1998 and is a practicing Muslim.", "Practicing Muslims pray often."], "decomposition": ["Which group uses the Quran as their religious text?", "Does Dave Chappelle belong to #1?"], "evidence": [[[["Quran-1"]], [["Dave Chappelle-57"], "operation"]], [[["Quran-1"]], [["Dave Chappelle-57"]]], [[["Quran-1"]], [["Dave Chappelle-57"], "operation"]]]}
{"id": 429, "term": "Earth's magnetic field", "description": "Magnetic field that extends from the Earth’s inner core to where it meets the solar wind", "question": "Are implants from an ORIF surgery affected by the magnetic field of the Earth?", "answer": false, "facts": ["An ORIF surgery is an Open Reduction Internal Fixation, done to fix broken bones.", "Most hardware from ORIF surgeries is made of titanium.", "Titanium is only slightly magnetic and does not affect metal detectors."], "decomposition": ["What kind of materials can be significantly affected by the earth's magnetic field?", "What kind of materials are ORIF surgery implants made of?", "Is #2 included in #1?"], "evidence": [[[["Magnetic mineralogy-4"], "no_evidence"], [["Internal fixation-1"]], ["operation"]], [[["Earth's magnetic field-9"], "no_evidence"], [["Internal fixation-1"]], [["Titanium-7"], "operation"]], [[["Ferromagnetism-1", "Magnetic field-90"], "no_evidence"], [["Internal fixation-1", "Internal fixation-3"]], [["Stainless steel-1"]]]]}
{"id": 526, "term": "Karachi", "description": "Megacity in Sindh, Pakistan", "question": "Karachi was a part of Alexander the Great's success?", "answer": true, "facts": ["Karachi is a city in modern day Pakistan.", "Krokola was an ancient port located in what is now Karachi.", "Alexander the Great stationed his fleet in Krokola on his way to Babylon.", "Alexander the Great defeated Darius and conquered Babylon before expanding his empire."], "decomposition": ["What is Karachi?", "What was the name of the ancient port that was once located in #1?", "Before expanding his empire, what city did Alexander the Great conquer?", "Did Alexander the Great station his fleet at #2 prior to #3?"], "evidence": [[[["Karachi-1"]], [["Karachi-8"]], [["Achaemenid Assyria-41"]], ["operation"]], [[["Karachi-1"]], [["Karachi-8"]], ["no_evidence"], ["operation"]], [[["Karachi-1"]], [["Port of Karachi-2"]], [["Alexander the Great-51"], "no_evidence"], [["Karachi-8"], "no_evidence", "operation"]]]}
{"id": 465, "term": "Easy Rider", "description": "1969 film by Dennis Hopper", "question": "Will the producer of Easy Rider become an octogenarian in 2021?", "answer": false, "facts": ["The producer of Easy Rider was Peter Fonda.", "Peter Fonda died in 2019 at the age of 79.", "An octogenarian is someone who is between 80 and 89 years old and is still alive."], "decomposition": ["Who produced Easy Rider?", "What characteristics does someone need to be considered an octogenarian?", "What characteristics does #1 have?", "Are all the characteristics in #2 also in #3?"], "evidence": [[[["Easy Rider-1"]], [["Illustrations of the rule against perpetuities-2"]], [["Peter Fonda-1"]], ["operation"]], [[["Easy Rider-1"]], ["no_evidence"], [["Peter Fonda-1"]], ["operation"]], [[["Easy Rider-1"]], [["Ageing-46"], "no_evidence"], [["Peter Fonda-58"]], ["operation"]]]}
{"id": 211, "term": "Artisan", "description": "skilled craft worker who makes or creates things by hand", "question": "Are twinkies considered artisan made products?", "answer": false, "facts": ["Twinkies are mass produced in multiple commercial bakeries.", "In bakeries, Twinkies are made by machines."], "decomposition": ["How are artisan-made products made?", "How are Twinkies produced?", "Does #2 match with #1?"], "evidence": [[[["Artisanal food-1"]], [["Twinkie-2"]], ["operation"]], [[["Artisanal food-1"]], [["Twinkie-12", "Twinkie-2"], "no_evidence"], ["operation"]], [[["Artisan-2"]], [["Hostess CupCake-4"]], ["operation"]]]}
{"id": 34, "term": "Salsa music", "description": "Latin American dance music genre", "question": "Would Ibn Saud tolerate salsa music?", "answer": false, "facts": ["Ibn Saud was the first ruler of Saudi Arabia and adhered to Wahhabism.", "Wahhabism is an ultra conservative sect of Islam that prohibits dancing.", "Salsa is a popular Latin American music genre that is heavily connected to dance."], "decomposition": ["Which religion(s) did Ibn Saud practice?", "Did #1 permit its adherents to listen to or play music during Ibn Saud's lifetime?"], "evidence": [[[["Ibn Saud-3"]], [["Islamic music-28"], "operation"]], [[["Ibn Saud-3"]], [["Wahhabism-1", "Wahhabism-52"], "operation"]], [[["Ibn Saud-3"]], [["Najd-23"], "no_evidence"]]]}
{"id": 709, "term": "Batman (1989 film)", "description": "1989 film directed by Tim Burton", "question": "Is Batman (1989 film) likely to be shown on flight from NY to Kansas City?", "answer": true, "facts": ["A flight from NY to Kansas City is four and a half hours.", "The run time of Batman (1989 film) is two hours and six minutes.", "Batman (1989 film) is rated PG-13", "The average age group of passengers is 18-34.", "Airlines have relaxed their rules for in-flight movies in last few years and even R rated movies have been shown."], "decomposition": ["How long is a flight from NY to Kansas City?", "How long is the 1989 Batman film? ", "Is #2 less than #1?"], "evidence": [[["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Kansas City metropolitan area-1", "New York City-1"], "no_evidence"], [["Batman (1989 film)-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Flight length-5"], "no_evidence"], [["Batman (1989 film)-23"], "no_evidence"], ["operation"]]]}
{"id": 185, "term": "1960", "description": "Year", "question": "Could you buy Hershey's Kisses in red foil with farthings after 1960?", "answer": false, "facts": ["The British farthing was made obsolete at the end of 1960", "In 1962, Hershey's Kisses began to be sold in colored wrappers (such as red foil)"], "decomposition": ["When was the British farthing made obsolete?", "When did Hershey's Kisses begin selling candy sold in colored wrappers?", "Is #2 before #1?"], "evidence": [[[["Farthing (British coin)-1"]], [["Hershey's Kisses-10"]], ["operation"]], [[["Farthing (British coin)-1"]], [["Hershey's Kisses-10"]], ["operation"]], [[["Farthing (British coin)-1"]], [["Hershey's Kisses-11"]], ["operation"]]]}
{"id": 37, "term": "Dessert", "description": "A course that concludes a meal; usually sweet", "question": "Is dessert eaten before breakfast?", "answer": false, "facts": ["Desserts are sweets.", "Meals generally begin with savory foods, and sweets eaten after."], "decomposition": ["What is a dessert?", "Are #1 usually sweet or salty?", "Do meals generally begin with foods that are #2?"], "evidence": [[[["Dessert-1"]], [["Dessert-1"]], ["no_evidence", "operation"]], [[["Dessert-1"]], [["Dessert-1"]], ["operation"]], [[["Dessert-1"]], [["Dessert-2"]], [["Breakfast-85"], "no_evidence"]]]}
{"id": 904, "term": "Rupert Murdoch", "description": "Australian-born American media mogul", "question": "Does Rupert Murdoch's alma mater have more history than the USA?", "answer": true, "facts": ["Rupert Murdoch's alma mater is Worcester College.", "Worcester College was founded in 1714.", "The first documented use of the term the United States of America was in a January 2, 1776 letter."], "decomposition": ["What is Rupert Murdoch's alma mater?", "When was #1 founded?", "When was the United States founded?", "Is #2 prior to #3?"], "evidence": [[[["Rupert Murdoch-8"]], [["Worcester College, Oxford-1"]], [["United States Declaration of Independence-1"]], ["operation"]], [[["Rupert Murdoch-8"]], [["Worcester College, Oxford-1"]], [["United States Declaration of Independence-1"]], ["operation"]], [[["Rupert Murdoch-8"]], [["Worcester College, Oxford-1"]], [["United States-27"]], ["operation"]]]}
{"id": 729, "term": "Christmas carol", "description": "Song or hymn or carol on the theme of Christmas", "question": "When the shuttle Columbia 11 landed, was it the season for Christmas carols?", "answer": true, "facts": ["The Columbia 11 shuttle landed on December 10th 1990.", "Christmas is celebrated during the month of December every year."], "decomposition": ["What month did the space shuttle Columbia 11 land?", "In what month are Christmas carols typically sung?", "Are #1 and #2 the same answer?"], "evidence": [[[["STS-40-1"], "no_evidence"], [["Christmas-1"]], ["operation"]], [[["STS-40-7"]], [["Christmas and holiday season-1", "Christmas carol-1"]], ["operation"]], [[["Space Shuttle Columbia-1"], "no_evidence"], [["Christmas and holiday season-1", "Christmas carol-1"]], ["no_evidence", "operation"]]]}
{"id": 755, "term": "Ludacris", "description": "American rapper and actor", "question": "Does Ludacris perform classical music?", "answer": false, "facts": ["Ludacris is a rap artist.", "Rap and hip hop music are not related to classical music."], "decomposition": ["Which kind of music does Ludacris perform?", "Is #1 the same as classical music?"], "evidence": [[[["Ludacris-6"]], ["operation"]], [[["Ludacris-6"]], ["operation"]], [[["Ludacris-1"]], ["operation"]]]}
{"id": 470, "term": "Indian Ocean", "description": "The ocean between Africa, Asia, Australia and Antarctica (or the Southern Ocean)", "question": "Does the United States of America touch the Indian Ocean?", "answer": false, "facts": ["The United States of America is bordered by the Atlantic and Pacific Oceans.", "Even the westernmost point of the USA, the Hawaiian Islands, is too far east in the Pacific to be anywhere near that ocean's border with the Indian Ocean."], "decomposition": ["What oceans does the US of America border?", "Is the Indian Ocean part of #1?"], "evidence": [[[["East Coast of the United States-1", "West Coast of the United States-1"]], ["operation"]], [[["Arctic Ocean-2", "Arctic Ocean-3", "Atlantic Ocean-2", "Pacific Ocean-1"]], ["operation"]], [[["Borders of the United States-2"]], ["operation"]]]}
{"id": 746, "term": "Stroke", "description": "Medical condition where poor blood flow to the brain causes cell death", "question": "Is it impossible to tell if someone is having a stroke?", "answer": false, "facts": ["Strokes have numerous physical symptoms including facial unevenness and trouble walking.", "Strokes have behavioral symptoms including slurred speech, disorientation, and trouble understanding speech."], "decomposition": ["What are the symptoms of a stroke?", "Are all of #1 hidden from physical observation?"], "evidence": [[[["Stroke-1"]], ["operation"]], [[["FAST (stroke)-2"]], ["no_evidence"]], [[["Stroke-15"]], [["Stroke-15"], "no_evidence"]]]}
{"id": 452, "term": "Hanging", "description": "execution or suicide method involving suspension of a person by a ligature", "question": "Is hanging a viable execution method on a ship at sea?", "answer": true, "facts": ["Hanging is typically set up using rope.", "Ships have plenty of rope on board because their operation relies heavily on rope."], "decomposition": ["What materials are necessary for hanging?", "Would #1 be available on a ship?"], "evidence": [[[["Gallows-1"]], ["operation"]], [[["Hanging-4"]], [["Rigging-1"]]], [[["Hanging-15"], "operation"], ["operation"]]]}
{"id": 125, "term": "Grey seal", "description": "species of seal", "question": "Can a grey seal swim in the same water as the subject of Moby Dick?", "answer": true, "facts": ["The range of gray seals is limited to parts of the northern hemisphere bordered by the Atlantic ocean", "The subject of Moby Dick was a sperm whale", "Sperm whales can be found in the north Atlantic, in addition to most other bodies of water on earth."], "decomposition": ["What kind of whale was Moby Dick?", "What is the range of #1?", "What is the range of gray seals?", "Is there an overlap between #2 and #3?"], "evidence": [[[["Moby-Dick-1"]], [["Sperm whale-2"], "no_evidence"], [["Grey seal-1"]], ["no_evidence", "operation"]], [[["Moby-Dick-1"]], [["Sperm whale-2"]], [["Grey seal-1"]], ["operation"]], [[["Moby-Dick-1"]], [["Sperm whale-2"]], [["Grey seal-7"]], ["operation"]]]}
{"id": 90, "term": "Mitsubishi", "description": "group of autonomous, Japanese multinational companies", "question": "Can someone in Uberlandia work for Mitsubishi?", "answer": true, "facts": ["Mitsubishi is a Japanese auto manufacturer", "Mitsubishi operates a plant in Catalao, Brazil", "Uberlandia is just under 70 miles from Catalao"], "decomposition": ["How far is Uberlandia from Catalao?", "Is #1 within reasonable distance to commute to work?", "Is there a Mitsubishi organization in Catalao?", "Are #2 and #3 positive?"], "evidence": [[[["Catalão-1", "Uberlândia-1"], "no_evidence"], ["operation"], ["no_evidence"], ["operation"]], [[["Catalão-4"]], ["operation"], [["Catalão-1"]], ["operation"]], [[["Catalão-1", "Uberlândia-1"], "no_evidence"], ["no_evidence", "operation"], [["Catalão-1"], "operation"], ["no_evidence", "operation"]]]}
{"id": 10, "term": "Yuri Gagarin", "description": "Soviet pilot and cosmonaut, first human in space", "question": "Would LeBron James hypothetically glance upwards at Yuri Gagarin?", "answer": false, "facts": ["LeBron James is 6 feet 9 inches tall.", "Yuri Gagarin was 5 feet 2 inches tall.", "Typically shorter individuals look up at taller individuals when they are speaking as it is polite to look face to face at someone when you are speaking to them."], "decomposition": ["How tall is LeBron James?", "How tall was Yuri Gagarin?", "Is #1 lesser than #2?"], "evidence": [[[["LeBron James-42"], "no_evidence"], [["Yuri Gagarin-9"], "no_evidence"], ["no_evidence", "operation"]], [[["LeBron James-42"]], [["Yuri Gagarin-9"]], ["operation"]], [[["LeBron James-42"]], [["Yuri Gagarin-9"]], ["operation"]]]}
{"id": 167, "term": "Ubuntu", "description": "Linux distribution based on Debian", "question": "If you were at an Apple store, would most of the computers be running Ubuntu?", "answer": false, "facts": ["Apple stores stock only Mac brand computers.", "Mac computers come preinstalled with the latest iOS."], "decomposition": ["Which operating system do Apple computers run on?", "Is #1 the same as Ubuntu?"], "evidence": [[[["Operating system-40"]], [["Ubuntu-1"]]], [[["MacOS-1"]], ["operation"]], [[["MacOS-1"]], ["operation"]]]}
{"id": 514, "term": "The Dark Knight (film)", "description": "2008 film directed by Christopher Nolan", "question": "Would The Dark Knight be appropriate for a preschool class?", "answer": false, "facts": ["Preschoolers are between 3 and 5 years old.", "The Dark Knight is rated PG-13.", "PG-13 is a rating that means parents are strongly cautioned that the content of a film may not be appropriate for children under 13."], "decomposition": ["What is the average age of preschoolers?", "What is the Dark Knight rated?", "What is the minimum age to watch something rated #2?", "Is age #1 above #3?"], "evidence": [[[["Preschool-4"]], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Preschool-4"]], ["no_evidence"], ["no_evidence"], ["operation"]], [[["Preschool-4"]], ["no_evidence"], [["PG-13 (disambiguation)-1"]], ["operation"]]]}
{"id": 576, "term": "Metropolitan Museum of Art", "description": "Art museum in New York City, New York", "question": "Could someone in Tokyo take a taxi to the The Metropolitan Museum of Art?", "answer": false, "facts": ["Tokyo is located in Japan.", "Japan and the United States are separated by the Pacific Ocean.", "A taxi is not capable of travelling over water."], "decomposition": ["Where is Tokyo?", "Where is the Metropolitan Museum of Art?", "What separates #1 and #2?", "Can a taxi drive on #3?"], "evidence": [[[["Tokyo-1"]], [["Metropolitan Museum of Art-1"]], [["Pacific Ocean-1"]], [["Taxicab-44", "Water taxi-1"]]], [[["Tokyo City-5"]], [["Metropolitan Museum of Art-3"]], [["Ocean-3"], "operation"], [["Ocean-3"]]], [[["Tokyo-1"]], [["Metropolitan Museum of Art-58"]], [["Pacific Ocean-1"]], [["Taxicab-1"], "no_evidence", "operation"]]]}
{"id": 438, "term": "Uniting Church in Australia", "description": "christian denomination", "question": "Was Muhammed a member of the Uniting Church in Australia?", "answer": false, "facts": ["The Uniting Church in Australia is a combination of Methodist and Presbyterian congregations.", "Methodists and Presbyterians are Christians.", "Muhammed was the Muslim prophet and was not a Christian."], "decomposition": ["Which religion was Muhammed a prophet in?", "What is the religion of the members of the Uniting Church in Australia?", "Is #1 the same as #2?"], "evidence": [[[["Last prophet-2"]], [["Uniting Church in Australia-23"]], ["operation"]], [[["Muhammad-1"]], [["Uniting Church in Australia-1"]], ["operation"]], [[["Muhammad-1"]], [["Uniting Church in Australia-1"]], ["operation"]]]}
{"id": 892, "term": "Heart failure", "description": "condition in which the heart is unable to provide sufficient pump action", "question": "Would ramen be bad for someone with heart failure?", "answer": true, "facts": ["People with heart failure have to limit their sodium intake.", "Ramen is notorious for having incredibly high sodium levels. "], "decomposition": ["What is the recommended maximum daily sodium allowance for someone with heart failure?", "How much sodium is in a bowl of ramen?", "Is #2 greater than #1 divided by three?"], "evidence": [[[["Reference Daily Intake-15"], "no_evidence"], [["Ramen-11"], "no_evidence"], ["operation"]], [[["Reference Daily Intake-14"], "no_evidence"], [["Instant noodle-23"], "no_evidence"], ["no_evidence", "operation"]], [[["Sodium-35"], "no_evidence"], [["Instant noodle-12"]], ["no_evidence", "operation"]]]}
{"id": 288, "term": "Spinach", "description": "species of plant", "question": "Has spinach been a source of power in a comic movie?", "answer": true, "facts": ["The comic character Popeye uses spinach as a source of power.", "A movie was made about Popeye.", "Popeye consumes spinach as a source of power in the movie."], "decomposition": ["Which movie was made for comic character Popeye?", "What was Popeye's source of power in #1", "Is #2 spinach?"], "evidence": [[[["Popeye-53"]], [["Popeye-68"]], [["Popeye-68"], "operation"]], [[["Popeye (film)-1"]], [["Popeye-6"]], ["operation"]], [[["Popeye the Sailor (film)-1"]], [["Popeye the Sailor (film)-4"]], ["operation"]]]}
{"id": 644, "term": "Daily Mirror", "description": "British daily tabloid newspaper owned by Reach plc.", "question": "Did William Shaespeare read the Daily Mirror?", "answer": false, "facts": ["The Daily Mirror is a British tabloid founded in 1903.", "William Shakespeare died in 1616."], "decomposition": ["When did William Shakespeare die?", "When was the Daily Mirror founded?", "Is #2 before #1?"], "evidence": [[[["William Shakespeare-17"]], [["Daily Mirror-1"]], ["operation"]], [[["William Shakespeare-1"]], [["Daily Mirror-1"]], ["operation"]], [[["William Shakespeare-1"]], [["Daily Mirror-1"]], ["operation"]]]}
{"id": 502, "term": "Olive oil", "description": "liquid fat extracted by pressing olives", "question": "Do some people soak in olive oil and water?", "answer": true, "facts": ["Adding olive oil to bath water is a common practice for dry skin.", "In baths, people tend to soak for a period of time. "], "decomposition": ["During which activity do people soak in water for some time?", "Is it common to add olive oil water for dry skin during #1?"], "evidence": [[[["Bathing-1"]], [["Bathing-44"], "no_evidence"]], [[["Bathing-1"]], [["Bathing-44"], "no_evidence"]], [[["Bathing-1"]], [["Olive oil-28"], "no_evidence", "operation"]], [[["Bathing-1"]], ["no_evidence"]]]}
{"id": 135, "term": "Florence", "description": "Capital and most populous city of the Italian region of Tuscany", "question": "Is there a Harry Potter character named after Florence?", "answer": true, "facts": ["Firenze is the native Italian form of the name Florence.", "There is a centaur who appars as a minor character in the Harry Potter series named Firenze.", "Firenze appears in three of the Harry Potter books but only one movie."], "decomposition": ["What is the native Italian form for the name Florence?", "What is the name of the centaur who appears  in the Harry Potter series?", "Is #1 the same as #2?"], "evidence": [[[["Florence (given name)-5"]], [["Magical creatures in Harry Potter-65"]], [["Florence (given name)-5", "Magical creatures in Harry Potter-65"], "operation"]], [[["Florence-1"]], [["Magical creatures in Harry Potter-65"]], ["operation"]], [[["Florence-1"]], [["Magical creatures in Harry Potter-65"]], ["operation"]]]}
{"id": 866, "term": "President of India", "description": "Ceremonial head of state of India", "question": "Is it more expensive to run for President of India than to buy a new iPhone 11?", "answer": false, "facts": ["Candidates for the presidency of India must pay a deposit of Rs 15,000", "A brand new iPhone 11 costs Rs 67,300"], "decomposition": ["How much must a candidate pay to run for president in India?", "How much does a new iPhone 11 cost?", "Is #1 more than #2?"], "evidence": [[[["President of India-63"], "no_evidence"], [["IPhone-10"], "no_evidence"], ["operation"]], [[["President of India-2"], "no_evidence"], [["IPhone 11-1"], "no_evidence"], ["no_evidence", "operation"]], [[["President of India-57"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 617, "term": "Latitude", "description": "The angle between zenith at a point and the plane of the equator", "question": "Is latitude required to determine the coordinates of an area?", "answer": true, "facts": ["Longitude is one of the required data points needed for determining coordinates.", "Latitude is the other angle required to determine coordinates of an area. "], "decomposition": ["What are the two sets of data points that determine coordinates of a location?", "Is latitude one of the answers to #1?"], "evidence": [[[["Geographic coordinate system-15"]], ["operation"]], [[["Geographic coordinate system-4"]], ["operation"]], [[["Geographic coordinate system-15"]], ["operation"]]]}
{"id": 835, "term": "Kingdom of Hungary", "description": "former Central European monarchy (1000–1946)", "question": "Were Walkman's used in the Kingdom of Hungary?", "answer": false, "facts": ["The Kingdom of Hungary ended in 1946. ", "The Walkman was invented in 1979."], "decomposition": ["When did the Kingdom of Hungary come to an end?", "When was Walkman invented?", "Is #2 before #1?"], "evidence": [[[["Kingdom of Hungary-1"]], [["Walkman-1"]], ["operation"]], [[["Kingdom of Hungary-1"]], [["Walkman-5"]], ["operation"]], [[["Kingdom of Hungary-1"]], [["Walkman-2"]], ["operation"]]]}
{"id": 264, "term": "Spice Girls", "description": "British girl group", "question": "Tata Hexa can accomodate every Spice Girl?", "answer": true, "facts": ["The Spice Girls is a five woman musical group from Britain.", "The Tata Hexa is a car with 6 and 7 seat capacities."], "decomposition": ["How many women are in the Spice Girls group?", "How many people can the Tata Hexa seat?", "Is #2 greater than or equal to #1?"], "evidence": [[[["Spice Girls-1"]], [["Tata Aria-2", "Tata Aria-5"], "no_evidence"], ["operation"]], [[["Spice Girls-1"]], [["Tata Hexa-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Spice Girls-1"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 39, "term": "Bob Marley", "description": "Jamaican singer-songwriter", "question": "Could Bob Marley's children hypothetically win tug of war against Kublai Khan's children?", "answer": false, "facts": ["Bob Marley had 9 children.", "Kublai Khan had 23 children.", "Many of Bob Marley's children became singers, and followed his themes of peace and love.", "The children of Kublai Khan followed in his footsteps and were fierce warlords."], "decomposition": ["How many children did Bob Marley have?", "How many children did Kublai Khan have?", "Is #1 greater than #2?"], "evidence": [[[["Bob Marley-42"]], [["Kublai Khan-71", "Toghon (son of Kublai)-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Bob Marley-42"]], [["Kublai Khan-71", "Kublai Khan-76"], "no_evidence"], ["operation"]], [[["Bob Marley-42"]], [["Kublai Khan-76"]], ["operation"]]]}
{"id": 494, "term": "Rick and Morty", "description": "Animated sitcom", "question": "Could Rich and Morty be triggered for children of alcoholics?", "answer": true, "facts": ["Rick, one of the titular characters of Rick and Morty, is often seen drunk and speaking abusively to Morty.", "Morty's mother Beth is depicted multiple times neglecting her children while getting drunk on wine. ", "Trauma triggers can occur when someone is exposed to something that reminds them of a traumatic situation. "], "decomposition": ["What depictions are common triggers for children of alcoholics?", "Do any of the characters from Rick and Morty exhibit the characteristics in #1?"], "evidence": [[[["Alcoholism-13"], "no_evidence"], [["Rick and Morty-5"], "operation"]], [[["Alcoholism-13"], "no_evidence"], [["Rick and Morty-5"], "no_evidence", "operation"]], [[["Adult Children of Alcoholics-4"]], [["Adult Children of Alcoholics-4", "Rick and Morty-4", "Rick and Morty-5"]]]]}
{"id": 319, "term": "Chlorophyll", "description": "group of chemical compounds", "question": "Would human race go extinct without chlorophyll?", "answer": true, "facts": ["Chlorophyll is a pigment in plants responsible for photosynthesis.", "Photosynthesis is the process by which plants release oxygen into the atmosphere.", "Humans need oxygen to live."], "decomposition": ["What is Chlorophyll responsible for in plants?", "What does #1 release into the air?", "Do humans need #2 in order to survive?"], "evidence": [[[["Chlorophyll-1"]], [["Photosynthesis-1"]], ["operation"]], [[["Chlorophyll-6"]], [["Photosynthesis-1"]], [["Breathing-2"]]], [[["Chlorophyll-1"]], [["Photosynthesis-1"]], [["Breathing-2"]]]]}
{"id": 811, "term": "Eggplant", "description": "plant species Solanum melongena", "question": "Is eggplant deadly to most atopic individuals? ", "answer": false, "facts": ["Atopic individuals have a genetic tendency to develop allergic reactions", "Eggplant allergies are usually not life-threatening "], "decomposition": ["What kind of reactions do atopic people have a tendency of getting?", "Are #1 caused by eggplant usually deadly in nature?"], "evidence": [[[["Atopy-4"]], [["Eggplant-53"], "operation"]], [[["Atopy-1"]], ["no_evidence", "operation"]], [[["Atopy-1", "Atopy-4", "Atopy-5"]], [["Atopy-6"], "no_evidence", "operation"]]]}
{"id": 517, "term": "The Jackson 5", "description": "American pop music family group", "question": "Did Jackson 5 members exceed number in The Osmonds?", "answer": false, "facts": ["The Jackson 5 was composed of: Jackie, Tito, Jermaine, Marlon and Michael.", "The Osmonds consisted of:  Alan, Wayne, Merrill, Jay and Donny."], "decomposition": ["How many members did The Jackson 5 have?", "How many members did The Osmonds have?", "Is #1 greater than #2?"], "evidence": [[[["The Jackson 5-1"]], [["The Osmonds-1"]], ["operation"]], [[["The Jackson 5-1"]], [["The Osmonds-1"]], [["The Jackson 5-1", "The Osmonds-1"], "operation"]], [[["The Jackson 5-1"]], [["Quintet-1", "The Osmonds-1"]], ["operation"]]]}
{"id": 14, "term": "Breast cancer", "description": "cancer that originates in the mammary gland", "question": "Is someone more likely to survive having breast cancer in Japan than in Sweden?", "answer": false, "facts": ["84.70% of people in Japan with breast cancer survive", "86.20% of people in Sweden with breast cancer survive"], "decomposition": ["What percentage of people survive breast cancer in Japan?", "What percentage of people survive breast cancer in Sweden?", "Is #1 more than #2?"], "evidence": [[[["Breast cancer-4"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 649, "term": "Lord Voldemort", "description": "Fictional character of Harry Potter series", "question": "Would Lord Voldemort hypothetically be an effective fighter after Final Fantasy silence is cast?", "answer": false, "facts": ["Lord Voldemort is a powerful wizard from the Harry Potter Series.", "Lord Voldemort casts magical curses and charms on his enemies.", "Silence spell in Final Fantasy mutes the enemies spells.", "Mute makes it impossible for characters to cast any spells."], "decomposition": ["What does Lord Voldemort use in combat against enemies?", "What would Lord Voldemort have to do in order to cast #1?", "Which ability does the silence spell in Final Fantasy affect?", "Can all of #2 still be done when #3 is gone?"], "evidence": [[[["Lord Voldemort-15"], "no_evidence"], [["Incantation-1"], "no_evidence"], [["Speech-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Lord Voldemort-28"], "no_evidence"], [["Lord Voldemort-29"], "no_evidence"], ["no_evidence"], ["operation"]], [[["Lord Voldemort-2", "Lord Voldemort-30"]], ["no_evidence"], ["no_evidence"], ["operation"]]]}
{"id": 854, "term": "Caracal", "description": "Small wild cat", "question": "Could a student at the University of Houston see a caracal on campus?", "answer": false, "facts": ["The caracal is native to Africa, the Middle East, Central Asia, and India.", "The University of Houston is located in the United States.", "The United States is located in North America."], "decomposition": ["What areas is the caracal native to?", "In what area is the University of Houston located?", "Is there an area present in both #1 and #2?"], "evidence": [[[["Caracal-1"]], [["University of Houston-1"]], ["operation"]], [[["Caracal-20"]], [["University of Houston-11"]], [["Houston-2", "Kyzylkum Desert-1"], "operation"]], [[["Caracal-1"]], [["University of Houston-1"]], ["operation"]]]}
{"id": 353, "term": "Astronomer", "description": "Scientist who studies celestial bodies", "question": "Does Nintendo's link ever see an astronomer?", "answer": true, "facts": ["Link is the main character of the Nintendo franchise 'Zelda\".", "In \"Legend of Zelda: Majora's Mask\" Link meets an astronomer in an observatory."], "decomposition": ["Which game is Link from?", "In #1, did link meet an astronomer?"], "evidence": [[[["The Legend of Zelda-24"]], [["Universe of The Legend of Zelda-60"], "no_evidence", "operation"]], [[["Link (The Legend of Zelda)-1"]], ["no_evidence"]], [[["Link (The Legend of Zelda)-1"]], ["no_evidence", "operation"]]]}
{"id": 657, "term": "Professional boxing", "description": "sport", "question": "Can professional boxers expect to have low dental bills?", "answer": false, "facts": ["Professional boxers often receive punches to their face.", "Even with a mouth guard, dental injuries occur often in boxing.", "The average cost for one dental crown is between $500-$3000"], "decomposition": ["What types of injuries are professional boxers likely to sustain?", "Are #1 inexpensive to treat?"], "evidence": [[[["Boxing-63"]], [["History of dental treatments-6"]]], [[["Boxing-82"]], ["operation"]], [[["Boxing-63"]], [["Dental insurance-1"]]]]}
{"id": 671, "term": "JPEG", "description": "Lossy compression method for reducing the size of digital images", "question": "Would JPEG be a good format for saving an image of Da Vinci's Vitruvian Man?", "answer": false, "facts": ["JPEG is not well suited for line drawings and other textual or iconic graphics, where the sharp contrasts between adjacent pixels can cause noticeable artifacts. ", "Da Vinci's Vitruvian Man is a line drawing done in pen and ink."], "decomposition": ["What kind of details are portrayed in Da Vinci's Vitruvian Man?", "Are JPEGs an ideal format for saving pictures containing #1?"], "evidence": [[[["Vitruvian Man-3"]], [["JPEG-29"]]], [[["Vitruvian Man-3"]], [["JPEG-1", "JPEG-110"]]], [[["Vitruvian Man-2"], "no_evidence"], [["JPEG-1"], "no_evidence", "operation"]]]}
{"id": 297, "term": "Kelly Clarkson", "description": "American singer-songwriter, actress, and television personality", "question": "Has Kelly Clarkson outsold season 4 American Idol winner?", "answer": false, "facts": ["Carrie Underwood was the winner of the fourth season of American Idol.", "Carrie Underwood has sold a little over 65 million albums.", "Kelly Clarkson has sold a little over 25 million albums."], "decomposition": ["Who was the season 4 American Idol winner?", "How many albums has Kelly Clarkson sold?", "How many albums by #1 have been sold?", "Is #2 more than #3?"], "evidence": [[[["American Idol (season 4)-20"]], [["Kelly Clarkson-3"]], [["Carrie Underwood-79"]], ["operation"]], [[["American Idol (season 4)-1"]], [["Kelly Clarkson-3"]], [["Carrie Underwood-3"]], ["operation"]], [[["American Idol (season 4)-1"]], [["Kelly Clarkson-3"]], [["Carrie Underwood-3"]], ["operation"]]]}
{"id": 461, "term": "Bumblebee", "description": "genus of insects", "question": "Does a bumblebee have to worry about spider veins?", "answer": false, "facts": ["Spider veins is a condition in which the veins become inflamed.", "Bumblebees have a free flowing blood system and do not have veins or arteries."], "decomposition": ["What anatomical features are necessary for a being to have spider veins?", "Do bumblebees have #1?"], "evidence": [[[["Telangiectasia-1"]], [["Drone (bee)-7"], "no_evidence", "operation"]], [[["Telangiectasia-1"]], [["Blood vessel-1", "Insect physiology-12"], "operation"]], [[["Skin-1", "Telangiectasia-1"]], [["Arthropods in culture-1", "Invertebrate-1"], "operation"]]]}
{"id": 338, "term": "Mongoose", "description": "family of mammals", "question": "Did mongoose come from later period than rhinos?", "answer": true, "facts": ["The mongoose originated  in the Neogene geological period.", "Rhinos are from the Paleogene geological period.", "The Paleogene period spans 43 million years from the end of the Cretaceous Period 66 million years ago to the beginning of the Neogene Period."], "decomposition": ["During which period did the mongoose originate?", "Which period did Rhinos originate from?", "Is #2 before #1?"], "evidence": [[[["Mongoose-2"]], [["Rhinoceros-5"]], [["Mongoose-2", "Rhinoceros-5"], "operation"]], [[["Mongoose-1", "Mongoose-2"]], [["Rhinoceros-5"]], ["operation"]], [[["Mongoose-2"]], [["Rhinoceros-5"]], ["operation"]]]}
{"id": 369, "term": "Chipmunk", "description": "Tribe of mammals (rodent (marmot))", "question": "Is an Eastern chipmunk likely to die before seeing two leap years?", "answer": true, "facts": ["A leap year happens every four years.", "The Eastern chipmunk has an average lifespan of three years."], "decomposition": ["What is the average lifespan of an Eastern chipmunk?", "How often does a leap year occur?", "Is #2 greater than #1?"], "evidence": [[[["Eastern chipmunk-7"]], [["Leap year-6"]], ["operation"]], [[["Chipmunk-11"]], [["Leap year-2"]], ["operation"]], [[["Chipmunk-11"]], [["Leap year-2"]], ["operation"]]]}
{"id": 449, "term": "Ginger", "description": "Species of plant", "question": "If you're pregnant, might you be recommended ginger?", "answer": true, "facts": ["Pregnancy often causes nausea and stomach upset.", "Small doses of ginger have been shown to help with vomiting and nausea.", "Doctors say that, in small doses, ginger is safe for pregnant women."], "decomposition": ["What symptoms can ginger help alleviate?", "Do pregnant women suffer from any symptoms in #1?"], "evidence": [[[["Ginger-36"]], [["Morning sickness-1"]]], [[["Ginger-36"]], [["Pregnancy-1"], "operation"]], [[["Jamaica ginger-2"]], [["Signs and symptoms of pregnancy-15"], "operation"]]]}
{"id": 38, "term": "Alice in Wonderland (1951 film)", "description": "1951 American animated musical fantasy film produced by Walt Disney Productions", "question": "Does Disney's Alice in Wonderland involve the celebration of a holiday?", "answer": true, "facts": ["In the movie, Alice meets the Mad Hatter.", "The Mad Hatter is having a tea party to celebrate his Unbirthday.", "The Unbirthday is a holiday which happens every day of the year which is not the subject's actual birthday."], "decomposition": ["What celebrations were featured in the Disney movie Alice in Wonderland?", "Is any of #1 an holiday?"], "evidence": [[[["Alice in Wonderland (1951 film)-7"]], ["operation"]], [[["Alice in Wonderland (franchise)-14"]], [["Birthday-1"], "operation"]], [[["Alice in Wonderland (1951 film)-9"], "no_evidence"], ["operation"]]]}
{"id": 910, "term": "Greyhound", "description": "Dog breed used in dog racing", "question": "Can a greyhound walk on two legs?", "answer": false, "facts": ["Greyhounds are dogs.", "Dogs walk on four legs. "], "decomposition": ["What type of animal is a greyhound?", "Does #1 walk on two legs?"], "evidence": [[[["Greyhound-1"]], ["no_evidence", "operation"]], [[["Greyhound-1"]], ["no_evidence"]], [[["Greyhound-1"]], [["Bipedalism-22", "Quadrupedalism-1"]]]]}
{"id": 270, "term": "Hypertension", "description": "Long term medical condition", "question": "Are two cans of Campbell's Soup a day good for hypertension?", "answer": false, "facts": ["Hypertension is a medical condition in which the blood pressure is high.", "Salt increases blood pressure.", "Campbell's Soup has an average of 1400 to 1800 mg of sodium (salt).", "The FDA states that sodium intake per day should not exceed 2300 mg."], "decomposition": ["Which substance has generated controversy about Campbell's canned soups regarding health concerns?", "Is excess of #1 good for people with hypertension?"], "evidence": [[[["Chicken soup-45"]], [["Hypertension-24"]]], [[["Soup-11"]], [["Hypertension-16"]]], [[["Campbell Soup Company-29"]], [["Sodium-36"]]]]}
{"id": 967, "term": "Narcissism", "description": "Personality trait of self love of a fake perfect self.", "question": "Is narcissism's origin a rare place to get modern words from?", "answer": false, "facts": ["Narcissism comes from the ancient Greek story of Narcissus, who fell in love with his own reflection.", "Aphrodisiac comes from stories about the ancient Greek goddess Aphrodite.", "Europe comes from Europa, an ancient Greek princess.", "The word stygian relates to the river of Hades in Greek mythology.", "Hypnosis comes from Hypnos, the Greek god of sleep."], "decomposition": ["From what culture does the word \"narcissism\" come? ", "What percent of English words come from #1?", "Is #2 small enough to be considered \"rare\"?"], "evidence": [[[["Narcissism-5"]], [["English words of Greek origin-34"]], ["operation"]], [[["Narcissism-1"]], [["English language-105", "English language-108", "English words of Greek origin-1"], "no_evidence"], ["operation"]], [[["Narcissism-5"]], [["English words of Greek origin-4"], "no_evidence"], ["operation"]]]}
{"id": 631, "term": "Casablanca", "description": "City / State in Casablanca-Settat, Morocco", "question": "Is it hard to get a BLT in Casablanca?", "answer": true, "facts": ["A BLT is a sandwich consisting of bacon, lettuce and tomato", "Casablanca is predominantly Muslim", "Islam forbids the consumption of pork and pork products"], "decomposition": ["What is the predominant religion of Casablanca?", "What dietary restrictions does #1 impose?", "What all goes on a BLT?", "Are there items common to both #2 and #3?"], "evidence": [[[["Casablanca-43"]], [["Islamic culture-45"]], [["BLT-1"]], ["operation"]], [[["Casablanca-43"]], [["Haram-13"]], [["BLT-7"]], ["operation"]], [[["Casablanca-43"]], [["Islamic culture-45"]], [["BLT-1"]], [["Bacon-1"]]]]}
{"id": 11, "term": "Ludacris", "description": "American rapper and actor", "question": "Is Ludacris in same music genre as 2000's Binaural?", "answer": false, "facts": ["Ludacris is a rapper, particularly in the southern rap style.", "Binaural was a 2000 album released by Pearl Jam.", "Pearl Jam is a grunge rock band formed in Seattle."], "decomposition": ["What genre does Ludacris produce music in?", "Who recorded the 2000 album Binaural?", "What genre does #2 produce music in?", "Is #1 the same as #3?"], "evidence": [[[["Hip hop music-1", "Ludacris-1"]], [["Binaural (album)-1"]], [["Binaural (album)-1"]], ["operation"]], [[["Ludacris-1"]], [["Binaural (album)-1"]], [["Pearl Jam-1"]], ["operation"]], [[["Ludacris-1"]], [["Binaural (album)-1"]], [["Pearl Jam-1"]], ["operation"]]]}
{"id": 254, "term": "Saltwater crocodile", "description": "species of reptile", "question": "Is the saltwater crocodile less endangered than the European otter?", "answer": true, "facts": ["The saltwater crocodile is listed as \"least concern\" on the International Union for the Conservation of Nature Red List.", "The European otter is listed as \"near threatened\" on the International Union for the Conservation of Nature Red List.", "The International Union for the Conservation of Nature Red List starts with \"least concern\", then \"near threatened\", \"vulnerable\", \"endangered\", \"critically endangered\", \"extinct in the wild\", and \"extinct\"."], "decomposition": ["What is the saltwater crocodile's conservation status on the IUCN red list?", "What is the European otter's conservation status on the IUCN red list?", "Is #1 less severe than #2?"], "evidence": [[[["Saltwater crocodile-1"]], [["Eurasian otter-8"]], [["Least-concern species-1"], "operation"]], [[["Saltwater crocodile-1"]], [["Eurasian otter-8"]], [["IUCN Red List-11"], "no_evidence", "operation"]], [[["Saltwater crocodile-1"]], [["Otter-12"]], ["operation"]]]}
{"id": 542, "term": "Comma", "description": "Punctuation mark", "question": "Would three commas be sufficient for displaying US 2018 GDP?", "answer": false, "facts": ["The 2018 GDP of US was 20.54 trillion dollars.", "There are three commas in a billion.", "There are four commas in a trillion."], "decomposition": ["How much was US GDP in 2018?", "When written in figures, how many commas would #1 contain?", "Is #2 less than or equal to three?"], "evidence": [[[["United States-142"], "no_evidence"], [["Trillion-2"], "operation"], ["operation"]], [[["United States-142"]], [["Trillion-2"]], ["operation"]], [[["Economy of the United States-21"]], [["Trillion-2"]], [["Trillion-2"], "operation"]]]}
{"id": 833, "term": "Coca", "description": "group of plant varieties cultivated for coca production", "question": "Would someone with a nosebleed benefit from Coca?", "answer": true, "facts": ["Coca constricts blood vessels.", "As a result, it serves to stop bleeding. ", "Someone with a nosebleed would want the bleeding to stop."], "decomposition": ["What does Coca do to blood vessels?", "What happens to blood when #1 occurs?", "Would someone with a nose want #2 to occur?"], "evidence": [[[["Coca-30"]], [["Blood vessel-16"]], ["operation"]], [[["Coca-30"]], ["no_evidence"], ["no_evidence"]], [[["Coca-30"]], ["no_evidence"], ["operation"]]]}
{"id": 991, "term": "Hamster", "description": "subfamily of mammals", "question": "Could a hamster experience two leap years?", "answer": false, "facts": ["Pet hamsters typically have a maximum lifespan of three years.", "Leap years are typically separated by four years."], "decomposition": ["How long is the lifespan of a hamster?", "How many years are between two leap years?", "Is #1 longer than #2?"], "evidence": [[[["Hamster-27"]], [["Leap year-16"]], ["operation"]], [[["Hamster-27"]], [["Leap year-16"]], ["operation"]], [[["Hamster-27"]], [["Leap year-6"]], ["operation"]]]}
{"id": 467, "term": "Zucchini", "description": "Edible summer squash, typically green in color", "question": "Would 7 zucchini's satisfy potassium USDA daily recommendation?", "answer": true, "facts": ["The USDA recommends at least 3500 mg of potassium a day.", "One zucchini has 512 mg of potassium."], "decomposition": ["How much potassium is in a zucchini?", "How much potassium does the USDA recommend daily?", "Would seven times #1 be more than #2?"], "evidence": [[[["Zucchini-27"], "no_evidence"], [["Dietary Reference Intake-10"], "no_evidence"], ["no_evidence", "operation"]], [[["Zucchini-27"]], ["no_evidence"], ["operation"]], [["no_evidence"], [["Potassium-46"], "operation"], ["no_evidence"]]]}
{"id": 577, "term": "Game engine", "description": "Software-development environment designed for building video games", "question": "Does Adobe Suite have video game engine coding?", "answer": true, "facts": ["Adobe applications runs on the C++ framework.", "Many video games are run on Unity game engine.", "The Unity game engine is a C++ coded engine."], "decomposition": ["What framework does Adobe Suite run on?", "What game engine do most video games run on?", "What type of engine is #2?", "Is the framework for #1 the same as the engine for #3?"], "evidence": [[[["Adobe Creative Suite-1", "Starling Framework-2"]], [["Starling Framework-1"], "no_evidence"], [["Starling Framework-3"], "no_evidence"], ["operation"]], [[["Adobe Creative Suite-1"], "no_evidence"], [["Game engine-27"], "no_evidence"], [["Game engine-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Adobe Creative Suite-1", "C++-2"], "no_evidence"], [["Unreal Engine-1"]], [["Unreal Engine-1"]], ["operation"]]]}
{"id": 351, "term": "National Hockey League", "description": "North American professional ice hockey league", "question": "Do American teams in National Hockey League outnumber Canadian teams?", "answer": true, "facts": ["The National Hockey League is the premiere North American hockey league.", "The National Hockey League has 7 Canadian teams.", "The National Hockey League has 24 teams from the United States."], "decomposition": ["How many Canadian teams are in the The National Hockey League?", "How many American teams are in the The National Hockey League?", "Is #2 greater than #1?"], "evidence": [[[["National Hockey League-1"]], [["National Hockey League-1"]], ["operation"]], [[["Ice hockey in the United States-5"]], [["Ice hockey in the United States-5"]], ["operation"]], [[["National Hockey League-1"]], [["National Hockey League-1"]], ["operation"]]]}
{"id": 832, "term": "Led Zeppelin", "description": "English rock band", "question": "Did the lead singer of Led Zepplin ever perform with Ernest Chataway?", "answer": true, "facts": ["Robert Plant is the lead singer of Led Zepplin", "Robert Plant was in the band The Honeydrippers", "Ernest Chataway was in the band The Honeydrippers"], "decomposition": ["Who was the lead singer of Led Zepplin?", "Who are the members of the Honeydrippers?", "Is Ernest Chataway also part of #2?", "Is #1 in #2?", "Is #3 and #4 both yes?"], "evidence": [[[["Led Zeppelin-1"]], [["The Honeydrippers-1"]], ["operation"], ["operation"], ["operation"]], [[["Robert Plant-1"]], [["The Honeydrippers-1"]], [["The Honeydrippers-1"]], ["operation"], ["operation"]], [[["The Honeydrippers-1"]], [["The Honeydrippers-1"]], ["operation"], ["operation"], ["operation"]]]}
{"id": 35, "term": "House of Lords", "description": "upper house in the Parliament of the United Kingdom", "question": "Was Aristotle a member of the House of Lords?", "answer": false, "facts": ["Aristotle died in 322 BC.", "The House of Lords is grown out of the Model Parliament, which was the first English Parliament.", "The Model Parliament was held in 1295."], "decomposition": ["When did Aristotle die?", "Where did the House of Lords originate from?", "When did #2 occur?", "Did #3 happen before #1?"], "evidence": [[[["Aristotle-1"]], [["House of Commons of the United Kingdom-17"]], [["House of Commons of the United Kingdom-17"]], ["operation"]], [[["Aristotle-10"], "no_evidence"], [["House of Lords-8"]], [["House of Lords-8"]], ["operation"]], [[["Aristotle-69"], "no_evidence"], [["House of Lords-18"], "no_evidence"], ["no_evidence"], ["no_evidence"]]]}
{"id": 114, "term": "Preventive healthcare", "description": "Prevent and minimize the occurrence of diseases", "question": "Do you need to schedule separate preventive healthcare and sickness visits? ", "answer": true, "facts": ["Preventive healthcare options are typically covered at no charge by health insurance.", "Sick visits to the doctor are billed separately from preventive healthcare visits.", "Sick visits and preventive healthcare visits are generally given different time allotments. "], "decomposition": ["How are preventive healthcare visits billed to insurance companies?", "How are sick visits to the doctor billed to insurance companies?", "Is #1 different from #2?"], "evidence": [[[["Preventive healthcare-60"], "no_evidence"], ["no_evidence"], ["operation"]], [[["Health care-11"], "no_evidence"], [["Health care-15"], "no_evidence"], ["operation"]], [[["Preventive healthcare-54"], "no_evidence"], [["Managed care-38"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 673, "term": "Hair", "description": "protein filament that grows from follicles found in the dermis, or skin", "question": "Is it safe to eat hair?", "answer": true, "facts": ["Hair is made of keratin.", "Food manufacturers use L-cysteine as a food additive.", "L-cysteine is made from keratin."], "decomposition": ["What is hair made of?", "What else is made from #1?", "Are any of #2 used in food production?"], "evidence": [[[["Hair-2"]], [["Alpha-keratin-1"]], ["no_evidence", "operation"]], [[["Hair-6"]], [["Hair-6"]], [["Food-1"]]], [[["Hair-1"]], [["Beef-1"]], [["Hamburger-1"], "operation"]]]}
{"id": 701, "term": "Snowboarding", "description": "winter sport", "question": "Snowboarding is a rarity in Hilo?", "answer": true, "facts": ["Snowboarding is a sport that involves descending snow-covered slopes.", "Hilo, a town in Hawaii, has not had snow in almost 200 years."], "decomposition": ["What kind of surface is needed for snowboarding?", "Is #1 likely to be nonexistent in Hilo, going by the prevailing climatic conditions?"], "evidence": [[[["Snowboarding-1"]], [["Hilo, Hawaii-12"], "operation"]], [[["Snowboarding-1"]], [["Hilo, Hawaii-13"], "operation"]], [[["Snowboarding-1"]], [["Hilo, Hawaii-12"], "operation"]]]}
{"id": 845, "term": "Mercury (planet)", "description": "Smallest and closest planet to the Sun in the Solar System", "question": "Would only warm weather attire be a good idea on Mercury?", "answer": false, "facts": ["Warm weather attire would not protect your body in cold temperatures.", "Mercury can reach temperatures of −280 °F at night."], "decomposition": ["What are the best temperatures to wear warm weather attire?", "What is the average temperature of Mercury at night?", "Is there any overlap between #1 and #2?"], "evidence": [[[["Clothing-2"]], [["Mercury (planet)-4"]], [["Clothing-2"]]], [[["Winter-18"], "no_evidence"], [["Mercury (planet)-4"]], ["operation"]], [[["Highest temperature recorded on Earth-4"], "no_evidence"], [["Mercury (planet)-4"]], ["no_evidence", "operation"]]]}
{"id": 801, "term": "Black swan", "description": "species of bird", "question": "Can black swan's formation type help spell longest word in Dictionary?", "answer": true, "facts": ["Black swan's fly in a \"V\" formation.", "The longest word in the dictionary is pneumonoultramicroscopicsilicovolcanoconiosis."], "decomposition": ["What letter does the formation of black swans in flight resemble?", "What is the longest word in English language?", "Can #1 be found in #2?"], "evidence": [[[["Black swan-6"]], [["Longest word in English-4"]], ["operation"]], [[["Black swan-6"]], [["Pneumonoultramicroscopicsilicovolcanoconiosis-1"]], ["operation"]], [[["Swan-6"], "no_evidence"], [["Pneumonoultramicroscopicsilicovolcanoconiosis-1"]], ["operation"]]]}
{"id": 413, "term": "Iris (mythology)", "description": "Greek goddess of the rainbow", "question": "Would Iris (mythology) and Hermes hypothetically struggle at a UPS job?", "answer": false, "facts": ["UPS is the number one delivery/courier service according to 2019 sales.", "Iris is the goddess of the rainbow and serves as a messenger of the gods in Greek mythology.", "Hermes in Greek mythology was a god that functioned as the emissary and messenger of the gods."], "decomposition": ["What role does the Greek goddess Iris play for gods?", "What role does the Greek deity Hermes play for gods?", "What kind of service does UPS provide?", "Are #1 and #2 much different from #3?"], "evidence": [[[["Iris (mythology)-1"]], [["Hermes-1"]], [["United Parcel Service-1"]], ["operation"]], [[["Iris (mythology)-1"]], [["Hermes-2"]], [["United Parcel Service-1"]], ["operation"]], [[["Iris (mythology)-1"]], [["Hermes-1"]], [["United Parcel Service-1"]], ["operation"]]]}
{"id": 958, "term": "John the Baptist", "description": "1st-century Jewish preacher and later Christian saint", "question": "Would John the Baptist be invited to a hypothetical cephalophore reunion in heaven?", "answer": false, "facts": ["John the Baptist was a preacher that became a Catholic Saint.", "John the Baptist was beheaded by king Herod.", "A cephalophore is a Saint martyred by beheading, and is depicted in art as carrying their own head.", "Saint Denis was one of several beheaded saints that is said to have carried his own head and is depicted as such in art.", "John the Baptist did not carry his head, since it was on a plate owned by King Herod's stepdaughter."], "decomposition": ["What does one carry for one to be considered a cephalophore?", "Did John the Baptist carry #1?"], "evidence": [[[["Cephalophore-1"]], [["Cephalophore-4"], "operation"]], [[["Cephalophore-1"]], [["Cephalophore-5"], "operation"]], [[["Cephalophore-1"]], [["John the Baptist-188"], "no_evidence", "operation"]]]}
{"id": 177, "term": "Emu", "description": "Large flightless bird endemic to Australia", "question": "Are emus related to elks?", "answer": false, "facts": ["Emus are a type of flightless bird.", "Elks are deer, which are mammals."], "decomposition": ["What type of animal are Emus?", "What type of animals are Elks?", "Are #1 and #2 the same?"], "evidence": [[[["Emu-1"]], [["Elk-1"]], ["operation"]], [[["Emu-2"]], [["Elk-1"]], ["operation"]], [[["Emu-1"]], [["Elk-1"]], ["operation"]]]}
{"id": 309, "term": "Napoleonic Wars", "description": "Series of early 19th century European wars", "question": "Was a nuclear bomb used in the Napoleonic Wars?", "answer": false, "facts": ["The Napoleonic Wars took place between 1803 and 1815.", "Nuclear bombs have only been used in warfare twice, both times in 1945."], "decomposition": ["When was the Napoleonic Wars?", "What year were nuclear bombs used in war?", "Is #2 in the range of years of #1?"], "evidence": [[[["Napoleonic Wars-1"]], [["Nuclear weapon-2"]], ["operation"]], [[["Napoleonic Wars-1"]], [["Nuclear weapons debate-1"]], ["operation"]], [[["Napoleonic Wars-1"]], [["Nuclear weapon-2"]], ["operation"]]]}
{"id": 636, "term": "Christopher Walken", "description": "American actor", "question": "Is Christopher Walken close to achieving EGOT status?", "answer": false, "facts": ["EGOT refers to people that have won an Emmy, a Grammy, an Oscar, and a Tony Award.", "Christopher Walken won the Oscar in 1979 for Best Actor in a Supporting Role.", "Christopher Walken was nominated for two Tony Awards but has never won.", "Christopher Walken was nominated for an Emmy Award but has never won.", "Christopher Walken has never been nominated for a Grammy."], "decomposition": ["What awards are included in EGOT?", "What entertainment awards has Christopher Walken won?", "Do the awards listed in #2 belong to at least 3 different awards listed in #1?"], "evidence": [[[["EGOT (disambiguation)-1"]], [["Christopher Walken-1"]], [["Christopher Walken-1"]]], [[["Emmy Award-2"]], [["Christopher Walken-2", "Christopher Walken-43"]], ["operation"]], [[["EGOT (disambiguation)-1"]], [["Christopher Walken-1"], "no_evidence"], ["operation"]]]}
{"id": 623, "term": "Fibonacci number", "description": "integer in the infinite Fibonacci sequence", "question": "Are there five different single-digit Fibonacci numbers?", "answer": true, "facts": ["The first six numbers in the Fibonacci sequence are 1,1,2,3,5,8.", "Since 1 is doubled, there are only five different single digit numbers."], "decomposition": ["What are the single-digit numbers in the Fibonacci sequence?", "How many unique numbers are in #1?", "Does #2 equal 5?"], "evidence": [[[["Fibonacci-12"]], ["operation"], ["operation"]], [[["Random Fibonacci sequence-4"]], ["operation"], ["operation"]], [[["Fibonacci-12"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 561, "term": "Donatello", "description": "Italian painter and sculptor", "question": "Did Donatello use a smartphone?", "answer": false, "facts": ["Donatello died on December 13, 1466.", "The first smartphone did not come out until 1992."], "decomposition": ["What years was Donatello alive?", "When was the first smartphone released?", "Did #2 occur during #1?"], "evidence": [[[["Donatello-1"]], [["Smartphone-6"]], ["operation"]], [[["Donatello-1"]], [["Smartphone-16"]], ["operation"]], [[["Donatello-1"]], [["Smartphone-6"]], ["operation"]]]}
{"id": 565, "term": "Acetylene", "description": "chemical compound", "question": "Did Julio Gonzalez like acetylene?", "answer": true, "facts": ["Julio Gonzalez was an artist who welded metal to create sculptures", "Welding is achieved by using a blowtorch on metal", "Blowtorches use acetylene as fuel"], "decomposition": ["What technique did Julio Gonzalez use to create his scultures?", "What is the main tool used for #1?", "What is a common fuel for #2?"], "evidence": [[[["Julio González (sculptor)-5"], "no_evidence"], [["Welding-10"]], [["Acetylene-14"], "operation"]], [[["Julio González (sculptor)-4"]], [["Oxy-fuel welding and cutting-3"]], [["Oxy-fuel welding and cutting-30"]]], [[["Julio González (sculptor)-1", "Julio González (sculptor)-4"]], [["Welding-10"]], [["Acetylene-14"]]]]}
{"id": 162, "term": "Small Solar System body", "description": "object in the Solar System that is neither a planet, nor a dwarf planet, nor a satellite", "question": "Is the name of a mythical creature also the name of a Small Solar System body?", "answer": true, "facts": ["A centaur is a kind of Small Solar System body with characteristics of both asteroids and comets.", "A centaur is also a mythical creature that has the body of a horse and the head of a man."], "decomposition": ["What is a mythical creature with the body of a horse and the head of a man called?", "Is any Small Solar System named after #1?"], "evidence": [[[["Centaur-1"]], [["Centaur (small Solar System body)-1"], "operation"]], [[["Centaur-5"]], [["Centaurus-18"]]], [[["Centaur-1"]], [["Centaur (small Solar System body)-1"]]]]}
{"id": 74, "term": "Oyster", "description": "salt-water bivalve mollusc", "question": "Can oysters be used in guitar manufacturing?", "answer": true, "facts": ["Oysters produce nacre", "Nacre is also known as mother of pearl", "Mother of pearl is commonly used as an inlay on guitar fretboards, headstocks, and soundboards"], "decomposition": ["What non-food products are derived from oysters?", "Which of #1 are used for decoration?", "What materials are used to decorate a guitar?", "Is there overlap between #2 and #3?"], "evidence": [[[["Nacre-1", "Nacre-17"], "no_evidence"], [["Oyster-2"], "no_evidence"], [["Guitar-45"], "no_evidence"], ["operation"]], [[["Oyster-9"]], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Oyster-6"]], [["Oyster-2"]], [["Inlay (guitar)-1"]], [["Inlay (guitar)-1", "Oyster-2"], "operation"]]]}
{"id": 480, "term": "Peach", "description": "species of fruit tree (for the fruit use Q13411121)", "question": "Will you see peach blossoms and Andromeda at the same time?", "answer": false, "facts": ["Peach trees bloom in the spring.", "Andromeda is visible in the fall."], "decomposition": ["When do peach trees bloom?", "When can you see Andromeda?", "Is #1 the same as #2?"], "evidence": [[[["Peach-18"]], [["Andromeda Galaxy-56"]], [["Andromeda Galaxy-56", "Peach-18"]]], [[["Peach-5"]], [["Andromeda (constellation)-3"], "no_evidence"], ["operation"]], [[["Peach-18"]], [["Andromeda (constellation)-1", "Andromeda (constellation)-3"], "no_evidence"], ["operation"]]]}
{"id": 321, "term": "Toyota Hilux", "description": "Series of light commercial vehicles produced by the Japanese car-manufacturer Toyota.", "question": "Can a human heart last from NYC to Raleigh NC by Toyota Hiux?", "answer": true, "facts": ["Human hearts can last up to six hours outside the body.", "The distance from NYC to Raleigh, NC is 505 miles.", "The top speed of a Toyota Hilux is 105 MPH."], "decomposition": ["How many hours can a human heart last outside of the human body?", "What is the distance between NYC to Raleigh, NC in miles?", "What is the top speed of a Toyota Hilux in MPH?", "Is #1 times #3 more than #2?"], "evidence": [[[["Organ transplantation-3"]], [["New York City-1", "Raleigh, North Carolina-1"], "operation"], [["Toyota Hilux-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Organ donation-8"], "no_evidence"], ["no_evidence"], [["Toyota Hilux-9"]], ["operation"]], [["no_evidence"], ["no_evidence"], [["Toyota Hilux-2"], "no_evidence"], ["operation"]]]}
{"id": 716, "term": "Don't ask, don't tell", "description": "Former policy on gay people serving in the United States military", "question": "During the time immediately after 9/11, was don't ask don't tell still in place?", "answer": true, "facts": ["Don't ask don't tell was the official military policy for LGBT service members until 2011.", "9/11 Occured on September 11th, 2001."], "decomposition": ["Until what year was \"Don't ask; Don't tell.\" in place?", "In what year did 9/11 occur?", "Is #1 more recent than #2?"], "evidence": [[[["Don't ask, don't tell-23"]], [["Post-9/11-2"]], ["operation"]], [[["Don't ask, don't tell-1"]], [["September 11 attacks-1"]], ["operation"]], [[["Don't ask, don't tell-1"]], [["September 11 attacks-1"]], ["operation"]]]}
{"id": 603, "term": "Copper", "description": "Chemical element with atomic number 29", "question": "Would a fungal life-form be threatened by a pigment from copper?", "answer": true, "facts": ["Verdigris is a pigment made from copper", "Verdigris is also used as a fungicide "], "decomposition": ["Which element is the pigment verdigris derived from?", "Is #1 copper and verdigris also used as a fungicide?"], "evidence": [[[["Verdigris-1"]], [["Verdigris-6"]]], [[["Verdigris-1"]], [["Copper-5", "Verdigris-6"], "operation"]], [[["Verdigris-1"]], [["Copper-5", "Verdigris-6"], "operation"]]]}
{"id": 261, "term": "Red Sea", "description": "Arm of the Indian Ocean between Arabia and Africa", "question": "Would it be very difficult for Nuno Gomes to dive to the Red Sea's deepest point?", "answer": true, "facts": ["The Red Sea has a maximum depth of 3,040 m (9,970 ft).", "Nuno Gomes' deepest dive in the Red Sea to date is 318 metres (1,043 ft)."], "decomposition": ["How deep is the Red Sea's maximum depth?", "What is the deepest Nuno Gomes can dive?", "Is #1 greater than #2?"], "evidence": [[[["Red Sea-2"]], [["Nuno Gomes (diver)-2", "Nuno Gomes (diver)-4"]], ["operation"]], [[["Red Sea-2"]], [["Nuno Gomes (diver)-4"]], ["operation"]], [[["Red Sea-2"], "no_evidence"], [["Nuno Gomes (diver)-2"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 52, "term": "Universal Music Group", "description": "American music corporation", "question": "Will NY Stock Exchange closing bell be heard in Universal Music Group's headquarters?", "answer": false, "facts": ["The New York Stock Exchange is located in New York, USA.", "Universal Music Group's headquarters is located in Santa Monica, California.", "Santa Monica is about 2800 miles from New York.", "A shout can be heard up to 100 meters away."], "decomposition": ["Where is the New York Stock Exchange located?", "Where is Universal Music Group's headquarters located?", "What is the distance between #1 and #2?", "Is #3 a reasonable distance within which a bell's chime can be heard?"], "evidence": [[[["New York Stock Exchange-1"]], [["Universal Music Group-1"]], ["no_evidence", "operation"], ["operation"]], [[["New York Stock Exchange-1"]], [["Universal Music Group-1"]], ["no_evidence"], ["no_evidence"]], [[["New York Stock Exchange-1"]], [["Universal Music Group-1"]], ["no_evidence", "operation"], [["Bell-32"], "operation"]]]}
{"id": 275, "term": "Cheeseburger", "description": "hamburger topped with cheese", "question": "Is a krabby patty similar to a cheeseburger?", "answer": true, "facts": ["A krabby patty is a fictional sandwich featuring a patty on a split bun with toppings like lettuce, onion, and tomato.", "A hamburger is typically served on a bun and offers toppings like lettuce, onion, and tomato."], "decomposition": ["What are the ingredients of a Krabby Patty?", "What are the ingredients of a cheeseburger?", "Is there significant overlap between #1 and #2?"], "evidence": [[[["Krabby Patty-4"]], [["Cheeseburger-10"]], ["operation"]], [[["Krabby Patty-4"]], [["Cheeseburger-1"]], ["operation"]], [[["Krabby Patty-4"]], [["Cheeseburger-1"]], ["operation"]]]}
{"id": 121, "term": "Compact disc", "description": "Optical disc for storage and playback of digital audio", "question": "Would a compact disc melt in magma?", "answer": true, "facts": ["Magma is the molten material beneath the earth's surface.", "The temperature of magma ranges between 1300F and 2400F degrees.", "A compact disc is made of polycarbonate plastic.", "Polycarbonate plastic melts at 311F degrees."], "decomposition": ["What material is a compact disc made of?", "At what temperature does #1 melt", "What is the typical temperature range of magma?", "Is #2 less than or within #3"], "evidence": [[[["Compact disc-23"]], [["Polycarbonate-25"], "no_evidence"], [["Magma-6"]], ["no_evidence", "operation"]], [[["CD-ROM-4"]], [["Plastic-19"]], [["Magma-6"]], ["operation"]], [[["CD-R-7"]], [["Polycarbonate-10"]], [["Magma-6"]], ["operation"]]]}
{"id": 783, "term": "Black fly", "description": "family of insects", "question": "Was Black fly upstaged by another insect in Jeff Goldblum's 1986 film?", "answer": true, "facts": ["Jeff Goldnlum starred in the 1986 movie The Fly.", "The fly used in the movie The Fly was a common Housefly.", "The Black fly is most closely related to Chironomidae since they both feed on mammals."], "decomposition": ["Which fly was used in the 1986 movie The Fly?", "is #1 a black fly?"], "evidence": [[["no_evidence"], ["operation"]], [[["The Fly (1986 film)-4"]], [["Black fly-1", "Housefly-1"]]], [[["The Fly (1986 film)-4"]], ["operation"]]]}
{"id": 900, "term": "Mount Sharp", "description": "mountain on Mars", "question": "Do mountain goats inhabit the summit of Mount Sharp?", "answer": false, "facts": ["Mountain goats are animals", "Animals require oxygen in order to live", "Mount Sharp is located on Mars", "The atmosphere of Mars contains only trace amounts of oxygen"], "decomposition": ["Where is Mount Sharp located?", "Does #1 have enough atmospheric oxygen to support the life of animals, such as mountain goats?"], "evidence": [[[["Mount Sharp-1"]], [["Life on Mars-9"]]], [[["Mount Sharp-1"]], [["Mars-59"], "operation"]], [[["Mount Sharp-1"]], [["Life on Mars-1"]]]]}
{"id": 316, "term": "Easy Rider", "description": "1969 film by Dennis Hopper", "question": "Did producer of Easy Rider ever star in a movie with Dean Cain's Princeton girlfriend?", "answer": true, "facts": ["Easy Rider was produced by Peter Fonda.", "Dean Cain dated Brooke Shields while at Princeton.", "Brooke Shields and Peter Fonda star in the movie Wanda Nevada."], "decomposition": ["Who produced Easy Rider?", "Who did Dean Cain date while at Princeton?", "What movies did #1 star in?", "What movies did #2 star in?", "Is at least one element of #3 also found in #4?"], "evidence": [[[["Easy Rider-1"]], [["Dean Cain-16"]], [["Peter Fonda-48"], "no_evidence"], [["Brooke Shields-1"], "no_evidence"], [["Wanda Nevada-1"], "no_evidence", "operation"]], [[["Easy Rider-1"]], [["Dean Cain-3"]], [["Wanda Nevada-1"]], [["Wanda Nevada-1"]], ["operation"]], [[["Easy Rider-40"], "operation"], [["Dean Cain-16"], "operation"], ["no_evidence"], ["no_evidence"], ["no_evidence"]]]}
{"id": 681, "term": "Samsung", "description": "South Korean multinational conglomerate", "question": "Is Samsung accountable to shareholders?", "answer": true, "facts": ["Samsung is a publicly traded company.", "Publicly traded companies are ultimately accountable to shareholders. "], "decomposition": ["What kind of company is Samsung?", "Are #1's accountable to shareholders?"], "evidence": [[[["Samsung Electronics-1"], "no_evidence"], ["operation"]], [[["Samsung-1"]], [["Conglomerate (company)-21"], "operation"]], [[["Samsung-14"], "operation"], ["operation"]]]}
{"id": 458, "term": "Land of Israel", "description": "Traditional Jewish name for an area of indefinite geographical extension in the Southern Levant.", "question": "Was Land of Israel in possession of an Islamic empire in 16th century?", "answer": true, "facts": ["Land of Israel was controlled by the Ottoman Empire in 16th century. ", "The religion of Ottoman Empire was Sunni Islam. "], "decomposition": ["Who ruled the geographic region of Israel in the 16th century?", "Was Islam the state religion of #1?"], "evidence": [[[["Israel-23", "Palestine (region)-20"]], [["Ottoman Empire-93"], "operation"]], [[["Israel-22"]], [["Ottoman Empire-96"], "no_evidence"]], [[["Israel-22"]], [["Ottoman Empire-96"], "operation"]]]}
{"id": 41, "term": "Star Wars", "description": "Epic science fantasy space opera franchise", "question": "Do Star Wars fans say \"beam me up\" often?", "answer": false, "facts": ["Beam me up is an expression from Star Trek.", "Much to the annoyance of fans, Star Trek and Star Wars are often confused for one another. "], "decomposition": ["Where does the expression beam me up come from?", "Is the answer to #1 the same as Star Wars?"], "evidence": [[[["Beam me up, Scotty-1"]], ["operation"]], [[["Beam me up, Scotty-1"]], ["operation"]], [[["Beam me up, Scotty-1"]], ["operation"]]]}
{"id": 244, "term": "Baptism", "description": "Christian rite of admission and adoption, almost invariably with the use of water", "question": "Was Alexander the Great baptized?", "answer": false, "facts": ["Baptism is a symbolic Christian rite using water.", "Christianity started in the first century AD.", "Alexander the Great lived from 356 BC- 323 BC."], "decomposition": ["Baptism is a rite in which religion?", "When did #1 develop?", "When did Alexander the Great die?", "Is #2 before #3?"], "evidence": [[[["Baptism-1"]], [["Christianity in the 1st century-2"]], [["Alexander the Great-62"]], ["operation"]], [[["Baptism-1"]], [["Baptism-8"]], [["Alexander the Great-62"]], [["Alexander the Great-62", "Baptism-8"], "operation"]], [[["Baptism-1"]], [["Christianity-3"]], [["Alexander the Great-1"]], ["operation"]]]}
{"id": 559, "term": "Marco Polo", "description": "Italian explorer and merchant noted for travel to central and eastern Asia", "question": "Do you often hear Marco Polo's name shouted near water?", "answer": true, "facts": ["\"Marco Polo\" is a popular game among children and adults played while swimming.", "To play \"Marco Polo\", one person shouts \"Marco\" and the other shouts \"Polo\" while avoiding being tagged."], "decomposition": ["What is the game Marco Polo?", "When is #1 typically played?", "Does #2 occur near or in water?"], "evidence": [[[["Marco Polo (game)-1"]], [["Marco Polo (game)-1"]], [["Swimming pool-1"]]], [[["Marco Polo (game)-1", "Marco Polo (game)-2"]], ["no_evidence"], ["operation"]], [[["Marco Polo (game)-2"]], [["Marco Polo (game)-2"]], [["Marco Polo (game)-2"]]]]}
{"id": 830, "term": "Oprah Winfrey", "description": "American businesswoman, talk show host, actress, producer, and philanthropist", "question": "Does Oprah Winfrey have a degree from an Ivy League university?", "answer": true, "facts": ["Oprah Winfrey has received honorary doctorates from Duke and Harvard Universities", "Harvard University is a member of the Ivy League"], "decomposition": ["What schools does Oprah Winfrey have honorary degrees from?", "Is #1 Ivy league?"], "evidence": [[[["Oprah Winfrey-4"]], [["Harvard University-1"], "operation"]], [[["Oprah Winfrey-4"]], [["Ivy League-1"], "operation"]], [[["Oprah Winfrey-4"]], [["Outline of Harvard University-2"]]]]}
{"id": 700, "term": "Stanford University", "description": "Private research university in Stanford, California", "question": "Was John Gall from same city as Stanford University?", "answer": true, "facts": ["John Gall is a former major league baseball player born in Stanford, California.", "Stanford University was founded by Leland and Jane Stanford  in Stanford, California."], "decomposition": ["Where was John Gall (baseball player) born?", "Where is Stanford University located?", "Is #1 the same as #2?"], "evidence": [[[["John Gall (baseball)-2"]], [["Stanford University-1"]], ["operation"]], [[["John Gall (baseball)-2"]], [["Stanford University-1"]], ["operation"]], [[["John Gall (baseball)-2"]], [["Stanford University-1"]], ["operation"]]]}
{"id": 230, "term": "Dual-energy X-ray absorptiometry", "description": "diagnostic test for bone mineral density testing", "question": "Would dual-energy X-ray absorptiometry be useful if performed on a crab?", "answer": false, "facts": ["Dual-energy X-ray absorptiometry is typically used to diagnose and follow osteoporosis.", "Osteoporosis is a disease in which bone weakening increases the risk of a broken bone.", "Crabs are invertebrates.", "Invertebrates do not have bones."], "decomposition": ["What condition is diagnosed with dual-energy X-ray absorptiometry?", "What body parts are affected by #1?", "Do crabs have #2?"], "evidence": [[[["Dual-energy X-ray absorptiometry-1"]], [["Dual-energy X-ray absorptiometry-2", "Osteoporosis-1"]], [["Crab-2"], "operation"]], [[["Dual-energy X-ray absorptiometry-2"]], [["Osteoporosis-1"]], [["Crab-1"]]], [[["Dual-energy X-ray absorptiometry-2"]], [["Osteoporosis-1"]], [["Crab-1", "Invertebrate-1"]]]]}
{"id": 742, "term": "Augustus", "description": "First emperor of the Roman Empire", "question": "Was Augustus his real name?", "answer": false, "facts": ["Augustus was given the name Gaius Octavius at birth.", "After he was adopted by his uncle Julius Caesar, he took the name Gaius Iulius Caesar.", "He took the name Augustus upon the breaking of the ruling Triumvirate and becoming Emperor."], "decomposition": ["What name did Augustus have when he was born?", "Is #1 identical to Augustus?"], "evidence": [[[["Augustus-2"]], ["operation"]], [[["Augustus-2"]], ["operation"]], [[["Augustus-2"]], ["operation"]]]}
{"id": 314, "term": "JPEG", "description": "Lossy compression method for reducing the size of digital images", "question": "Could the leader of Heaven's Gate save images in JPEG format?", "answer": true, "facts": ["Marshall Applewhite, Jr. was the leader of the Heaven's Gate cult", "Marshall Applewhite, Jr. died in 1997", "JPEG format was released in 1992"], "decomposition": ["Who led the Heaven's Gate cult?", "During what span of years was #1 alive?", "What year was JPEG released?", "Is #2 inclusive of #3?"], "evidence": [[[["Marshall Applewhite-1"]], [["Marshall Applewhite-1"]], [["JPEG-2"]], ["operation"]], [[["Heaven's Gate (religious group)-20"]], [["Marshall Applewhite-1"]], [["JPEG-15"]], ["operation"]], [[["Heaven's Gate (religious group)-1"]], [["Heaven's Gate (religious group)-1"]], [["JPEG-5"]], ["operation"]]]}
{"id": 558, "term": "Burning Man", "description": "annual experimental festival based in Nevada, United States", "question": "Are people more likely than normal to get sunburn at Burning Man?", "answer": true, "facts": ["Burning Man often attracts lots of young people who are typically wearing minimal clothing due to the weather and for style. ", "Burning Man festivities occur in the hot summer sun and are often not in shaded areas."], "decomposition": ["What style of clothing do people wear to the burning man festival?", "Sun burning occurs easily while wearing what style of clothing?", "Is #1 and #2 the same?"], "evidence": [[[["Burning Man-37"], "no_evidence"], [["Nudity-1", "Swimsuit-2"], "no_evidence"], ["operation"]], [[["Burning Man-37"]], [["Sunburn-36"]], ["operation"]], [[["Burning Man-37"]], [["Bikini-71"]], [["Sunburn-26"], "operation"]]]}
{"id": 679, "term": "Johann Sebastian Bach", "description": "German composer", "question": "Did Johann Sebastian Bach ever win a Grammy Award?", "answer": false, "facts": ["Johann Sebastian Bach died in 1750.", "The first Grammy Awards ceremony was held on May 4, 1959."], "decomposition": ["In what year did Johann Sebastian Bach die?", "When was the first Grammy Award given?", "Is #2 before #1?"], "evidence": [[[["Johann Sebastian Bach-1"]], [["Grammy Award-3"]], ["operation"]], [[["Johann Sebastian Bach-34"]], [["Grammy Award-6"]], ["operation"]], [[["Johann Sebastian Bach-5"]], [["Grammy Award-6"]], ["operation"]]]}
{"id": 354, "term": "Swastika", "description": "a geometrical figure and an ancient religious icon in the cultures of Eurasia and 20th-century symbol of Nazism", "question": "Does the swastika have positive uses?", "answer": true, "facts": ["The swastika is used in the Hindu religion to represent the sun.", "People practicing Hindu believe the swastika represents prosperity and good luck."], "decomposition": ["What does the swastika represent in Hinduism?", "What beliefs do Hindu worshippers associate with #1?", "Are #2 positive?"], "evidence": [[[["Swastika-34"]], [["Swastika-34"]], [["Swastika-34"]]], [[["Swastika-1", "Swastika-3"]], [["Swastika-3"]], ["operation"]], [[["Swastika-3"]], [["Swastika-3"]], [["Luck-24", "Prosperity-1"]]]]}
{"id": 285, "term": "United States presidential election", "description": "type of election in the United States", "question": "Will bumblebees derail the United States presidential election?", "answer": false, "facts": ["The United States presidential election is held in November of each year.", "Bees die off during the winter months except for the queen bee.", "During November, bees go into their hives and hibernate."], "decomposition": ["When is the presidential election?", "What is a necessary characteristic for something to disrupt the election? ", "Are bees #2 in #1?"], "evidence": [[[["United States presidential election-3"]], ["no_evidence"], ["operation"]], [[["Election Day (United States)-1"]], ["no_evidence"], [["Bumblebee-30"], "operation"]], [[["2020 United States presidential election-2"]], [["Electrical disruptions caused by squirrels-9"]], ["operation"]]]}
{"id": 725, "term": "Bitcoin", "description": "decentralized cryptocurrency", "question": "Can you put bitcoin in your pocket?", "answer": true, "facts": ["Bitcoin is a digital crypto currency.", "Bitcoin can be stored in tangible wallets, called hard wallets.", "Cryptocurrency hard wallets are the size of a thumb drive.", "Thumb drives can fit in your pocket."], "decomposition": ["What kind of currency is bitcoin?", "What are some common ways of storing #1?", "Which of #2 is a physical object?", "Is #3 small enough to fit in a pocket?"], "evidence": [[[["Bitcoin-1"]], [["Bitcoin-44"]], [["Bitcoin-47"]], ["no_evidence"]], [[["Cryptocurrency-2"]], [["Bitcoin-47"]], ["operation"], ["operation"]], [[["Bitcoin-1"]], [["Bitcoin-46", "Bitcoin-49"]], ["operation"], ["operation"]]]}
{"id": 468, "term": "Colitis", "description": "inflammation of the colon or the large intestine", "question": "Is it best to avoid kola nuts with colitis?", "answer": true, "facts": ["Colitis is a disease in which the colon becomes inflamed.", "Many things can trigger colitis, including dairy, alcohol, and caffeine.", "The kola nut is the fruit of the tropical cola tree that contains caffeine inside."], "decomposition": ["What triggers colitis? ", "Are any of the triggers in #1 present in the kola nut?"], "evidence": [[[["Colitis-17"], "no_evidence"], [["Kola nut-2"], "operation"]], [[["Colitis-10"], "no_evidence"], [["Kola nut-1"], "no_evidence"]], [[["Colitis-3"], "no_evidence"], [["Kola nut-1"], "no_evidence", "operation"]]]}
{"id": 869, "term": "Reza Shah", "description": "Shah of Iran, Founder of the Imperial state of iran", "question": "Did number of Imams Reza Shah believed in exceed number of Jesus's disciples?", "answer": false, "facts": ["Reza Shah, the founder of the Imperial state of Iran, was a Twelver Shia Muslim.", "Twelver Shia Muslims believe that there are 12 Imams.", "Jesus is typically represented as having 12 disciples."], "decomposition": ["What was the religion signature of Reza Shah?", "How many Imams do adherents of #1 believe in?", "How many disciples did Jesus have?", "Is #2 greater than #3?"], "evidence": [[[["Reza Shah-19"]], [["Imam-2"]], [["Disciple whom Jesus loved-4"]], ["operation"]], [[["Reza Shah-26"], "no_evidence"], [["Twelver-1"]], [["Apostles-1"]], ["operation"]], [[["Reza Shah-26"], "no_evidence"], [["Twelver-1"]], [["Apostles-1"]], ["operation"]]]}
{"id": 873, "term": "Anorexia nervosa", "description": "Eating disorder characterized by refusal to maintain a healthy body weight, and fear of gaining weight due to a distorted self image", "question": "Would a person with Anorexia nervosa be more likely to break a bone than a regular person?", "answer": true, "facts": ["People with Anorexia Nervosa restrict food and as a result lack essential nutrients.", "Many people with Anorexia Nervosa, are at high risk for osteoporosis(and to a lesser extent bulimia nervosa) will have low bone density and consequently reduced bone strength.", "People with Anorexia Nervosa, are at high risk for osteoporosis. "], "decomposition": ["What kind of eating behavior do people with anorexia nervosa exhibit?", "Does #1 lead to reduced bone strength?"], "evidence": [[[["Anorexia nervosa-1"]], [["Osteoporosis-1"], "operation"]], [[["Anorexia nervosa-1"]], [["Anorexia nervosa-54"]]], [[["Anorexia nervosa-4"]], [["Malnutrition-3"]]]]}
{"id": 234, "term": "Charles Manson", "description": "American criminal, cult leader", "question": "Was Charles Manson's body unwanted?", "answer": false, "facts": ["Charles Manson's body was debated over for so long that he had to stay on ice.", "Charles Manson had four people fighting over his corpse."], "decomposition": ["How many people tried to claim Charles Manson's body?", "Is #1 equal to zero?"], "evidence": [[[["Charles Manson-66"]], ["operation"]], [[["Charles Manson-66"]], ["operation"]], [[["Charles Manson-66"]], ["operation"]]]}
{"id": 846, "term": "Spinach", "description": "species of plant", "question": "For bone growth, is kale more beneficial than spinach?", "answer": true, "facts": ["Calcium is an important nutrient for bone health.", "Kale has more calcium per serving than spinach."], "decomposition": ["What nutrient is critical for bone growth?", "How much #1 does kale contain?", "How much #1 does spinach contain?", "Is #2 greater than #3?"], "evidence": [[[["Bone growth factor-3"]], [["Kale-11"]], [["Spinach-7"]], ["operation"]], [[["Calcium-36"]], [["Kale-11"]], [["Spinach-7"]], ["operation"]], [[["Calcium-3"]], [["Kale-11"], "no_evidence"], [["Spinach-7"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 572, "term": "Gandalf", "description": "Fictional character created by J. R. R. Tolkien", "question": "Gandalf hypothetically defeats Rincewind in a wizard battle?", "answer": true, "facts": ["Gandalf is a 2000 plus year old wizard that has fought orcs and spirits in Middle Earth.", "Rincewind is the protagonist of the Discworld series.", "Rincewind is a failed student at the Unseen University for wizards in Ankh-Morpork.", "Rincewind is described by other wizards as the magical equivalent to the number zero."], "decomposition": ["How powerful is Gandalf as portrayed in LOTR?", "How powerful is Rincewind as portrayed at the Unseen University for wizards?", "Does #1 include far more experience and accomplishments than #2?"], "evidence": [[[["Gandalf-2"]], [["Rincewind-1"]], ["no_evidence"]], [[["Gandalf-2"], "no_evidence"], [["Rincewind-1"]], ["operation"]], [[["Gandalf-2"]], [["Rincewind-1"]], ["operation"]]]}
{"id": 305, "term": "Watchmaker", "description": "artisan who makes and repairs watches", "question": "Is a watchmaker likely to be able to fix an Apple Watch?", "answer": false, "facts": ["A watchmaker makes and repairs watches using tiny instruments to fix coils, springs, gears, and other metal parts..", "The Apple Watch is a computer driven watch that can connect to devices using wireless technology.", "Apple Watches do not have the usual springs and gears of traditional watches."], "decomposition": ["What components of watches do watchmakers repair?", "What are the main components of an Apple Watch?", "Is there an overlap between #1 and #2?"], "evidence": [[[["Watchmaker-1", "Watchmaker-2"], "no_evidence"], [["Apple Watch-2"], "no_evidence"], ["operation"]], [[["Watchmaker-2"]], [["Apple Watch-29"], "no_evidence"], ["operation"]], [[["Watchmaker-1"]], [["Apple Watch-15"]], ["operation"]]]}
{"id": 920, "term": "John Muir", "description": "Scottish-born American naturalist and author", "question": "Would John Muir not likely have a vitamin D deficiency?", "answer": true, "facts": ["John Muir frequently spent time exploring various places in nature.", "Spending time in nature increases your exposure to sunlight.", "Skin exposure to sunlight increases vitamin D levels in the body."], "decomposition": ["What is the most common cause of vitamin D deficiency?", "What was the nature of John Muir's life's work?", "Does #2 ensure that he does not experience #1?"], "evidence": [[[["Vitamin D-17"]], [["John Muir-2"]], [["John Muir-2"], "operation"]], [[["Vitamin D-13"]], [["John Muir-52"]], ["operation"]], [[["Vitamin D deficiency-1"]], [["John Muir-1"]], ["operation"]]]}
{"id": 142, "term": "Holy Land", "description": "Term used by Jews, Christians, and Muslims to describe the Land of Israel and Palestine", "question": "Is the Holy Land important to Eastern religions?", "answer": false, "facts": ["Eastern religions include Hinduism, Buddhism, and Shintoism.", "Hinduism recognizes seven Holy Cities which are Ayodhya, Mathura, Haridwar, Varanasi, Kanchipuram, Dvaraka and Ujjain.", "Bodh Gaya: (in the current Mahabodhi Temple, Bihar, India), is the most important religious site and place of pilgrimage for Buddhists.", "The most sacred Shinto shrine is located in the city of Ise, within the Shima Peninsula of Japan."], "decomposition": ["What are some typical Eastern religions?", "Which place is referred to as the Holy Land?", "Which places do some of #1 consider sacred or holy?", "Is #2 included in #3?"], "evidence": [[[["Eastern religions-1"]], [["Holy Land-1"]], ["no_evidence"], ["no_evidence"]], [[["Eastern religions-1"]], [["Holy Land-1"]], ["no_evidence"], ["no_evidence"]], [[["Eastern religions-1"]], [["Holy Land-1", "Holy Land-4"]], [["Ganga in Hinduism-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"id": 541, "term": "Soul music", "description": "Genre of music", "question": "Would Brian Warner be a good singer for a soul music band?", "answer": false, "facts": ["Soul music is a music genre that originated in the United States African American community in the 1950s.", "Soul music combines elements of African-American gospel music, rhythm and blues and jazz.", "Brian Warner is the lead singer of the band Marilyn Manson.", "The band Marilyn Manson plays industrial heavy metal music."], "decomposition": ["What kind of music does Brian Warner play?", "Is soul music listed in #1?"], "evidence": [[[["Marilyn Manson-2"]], ["operation"]], [[["Marilyn Manson (band)-46"]], ["operation"]], [[["Marilyn Manson-1", "Marilyn Manson-21", "Marilyn Manson-8"]], ["operation"]]]}
{"id": 373, "term": "White blood cell", "description": "type of cells of the immunological system", "question": "Do white blood cells outnumber red blood cells in the human body?", "answer": false, "facts": ["Red blood cells are about 40-50% of what makes up human blood.", "White blood cells make up about 1% of the blood in a human body."], "decomposition": ["What percent of blood by volume is made up of white blood cells?", "What percent of blood by volume is red blood cells?", "Is #1 greater than #2?"], "evidence": [[[["White blood cell-3"]], [["White blood cell-3"]], [["White blood cell-3"]]], [[["Blood-8"]], [["Blood-8"]], ["operation"]], [[["White blood cell-3"]], [["White blood cell-3"]], ["operation"]]]}
{"id": 737, "term": "Last Supper", "description": "Final meal that, in the Gospel accounts, Jesus shared with his apostles in Jerusalem before his crucifixion", "question": "Is anyone at the Last Supper celebrated in Islam?", "answer": true, "facts": ["The Last Supper was a meal between Jesus and his twelve disciples in Christianity.", "In Islam, Jesus is one of many revered prophets.", "In Islam, Jesus returns in a Second Coming to fight the \"False Messiah\" and establish peace on earth."], "decomposition": ["Who was present at the Last Supper?", "Are any of #1 celebrated in Islam?"], "evidence": [[[["Last Supper-1"]], [["Jesus-4"], "operation"]], [[["Last Supper-1"]], [["Jesus in Islam-2"]]], [[["Apostles-1", "Last Supper-1"]], [["Disciples of Jesus in Islam-1"], "no_evidence", "operation"]]]}
{"id": 12, "term": "Seismology", "description": "The scientific study of earthquakes and propagation of elastic waves through a planet", "question": "Did Brad Peyton need to know about seismology?", "answer": true, "facts": ["Brad Peyton directed the movie San Andreas", "San Andreas is an earthquake disaster film", "Seismology is the science of earthquakes and related phenomena"], "decomposition": ["What does the study of seismology involve?", "What was the movie San Andreas primarily about?", "Did Brad Peyton direct San Andreas and is #2 included in #1?"], "evidence": [[[["Seismology-1"]], [["San Andreas (film)-1"]], [["San Andreas (film)-1"], "operation"]], [[["Seismology-1"]], [["San Andreas (film)-1"]], [["Brad Peyton-1"], "operation"]], [[["Seismology-1"]], [["San Andreas (film)-1"]], ["operation"]]]}
{"id": 471, "term": "QWERTY", "description": "keyboard layout where the first line is \"QWERTYUIOP\"", "question": "Can second row of QWERTY keyboard spell Abdastartus's kingdom?", "answer": true, "facts": ["QWERTY keyboards have one row of numbers followed by three rows of letters.", "The second row of the QWERTY keyboard has the letters: QWERTYUIOP.", "Abdastartus was king of Tyre from 929 – 921 BC."], "decomposition": ["What letters are on the second row of a QWERTY keyboard?", "What was Abdastartus' kingdoms name?", "Are all the letters in #2 also found in #1?"], "evidence": [[[["QWERTY-1"], "no_evidence"], [["Abdastartus-1"]], ["operation"]], [[["QWERTY-1"], "no_evidence"], [["Abdastartus-3"]], ["operation"]], [[["QWERTY-9"]], [["Abdastartus-1"]], ["operation"]]]}
{"id": 732, "term": "Forbidden City", "description": "Art museum, Imperial Palace, Historic site in Beijing, China", "question": "Are people banned from entering the Forbidden City?", "answer": false, "facts": ["The Forbidden City is a tourist attraction.", "Tourist attractions allow people to enter."], "decomposition": ["Is the Forbidden City a tourist attraction?", "Are tourist attractions open to the public?", "Are the answers to #1 and #2 the same?"], "evidence": [[[["History of the Forbidden City-12"]], [["Tourist attraction-1"]], ["operation"]], [[["Forbidden City-3"]], [["Tourist attraction-1"]], ["operation"]], [[["Forbidden City-3"]], [["Tourist attraction-1"]], ["operation"]]]}
{"id": 307, "term": "Fair trade", "description": "form of trade", "question": "Can you buy a fair trade laptop?", "answer": false, "facts": ["Fair trade is a term used with sustainable development focusing on agricultural production", "Laptops are consumer electronics"], "decomposition": ["What type of product is the fair trade label used with? ", "What type of product is a laptop?", "Is #2 the same as #1?"], "evidence": [[[["Fair trade-4"]], [["Laptop-1"]], ["operation"]], [[["Fair trade-1"]], [["Laptop-1"]], ["operation"]], [[["Fair trade-1"]], [["Laptop-1"]], ["operation"]]]}
{"id": 397, "term": "Basel", "description": "Place in Basel-Stadt, Switzerland", "question": "Is it dark is Basel during the day in Los Angeles?", "answer": true, "facts": ["Basel is located in the CEST time zone.", "Los Angeles is located in the PDT time zone."], "decomposition": ["What time zone is Basel in?", "What time zone is Los Angeles in?", "What is the time difference in hours between #1 and #2?", "Is #3 at least equal to 8?"], "evidence": [[[["Basel-1", "Central European Summer Time-1", "Central European Summer Time-6"]], [["Pacific Time Zone-1", "Pacific Time Zone-3"]], [["Central European Summer Time-1", "Pacific Time Zone-1"], "operation"], ["operation"]], [[["Basel-1", "UTC+00:30-2"]], [["Pacific Time Zone-9"]], ["no_evidence", "operation"], ["operation"]], [[["Basel-1", "UTC+01:00-1"]], [["Los Angeles-1", "UTC−08:00-1"]], ["operation"], ["operation"]]]}
{"id": 817, "term": "2000", "description": "Year", "question": "Would 1996 leap year baby technically be 1 year old in 2000?", "answer": true, "facts": ["A leap year happens once every 4 years and has 29 days in February.", "The years 1996, 2000, 2004, 2008, 2012, 2016, and 2020 are the last 7 leap years that have happened.", "1996 to 2000 is one leap year."], "decomposition": ["How many years apart are consecutive leap years?", "What is 2000 minus 1996?", "Is #2 divided by #1 equal to one?"], "evidence": [[[["Leap year-2"]], ["operation"], ["operation"]], [[["Leap year-2"]], ["operation"], ["operation"]], [[["Leap year-16"]], ["operation"], ["operation"]]]}
{"id": 195, "term": "Toyota Supra", "description": "A sports car and grand tourer manufactured by Toyota Motor Corporation", "question": "Would 2020 Toyota Supra lag behind at a Nascar rally?", "answer": true, "facts": ["The 2020 Toyota Supra has a top speed of 155 MPH.", "Nascar stock cars routinely exceed 200 MPH."], "decomposition": ["What speeds do stock cars in a NASCAR race routinely attain?", "What is the top speed of a Toyota Supra?", "Is #2 less than #1?"], "evidence": [[[["Stock car racing-3"]], [["Toyota Supra-61"]], ["operation"]], [[["Stock car racing-2"]], [["Toyota Supra-77"]], [["Stock car racing-2", "Toyota Supra-77"]]], [[["Stock car racing-65"]], [["Toyota Supra-61"]], ["operation"]]]}
{"id": 776, "term": "Eddie Murphy", "description": "American stand-up comedian and actor", "question": "Could Eddie Murphy's children hypothetically fill a basketball court by themselves?", "answer": true, "facts": ["Eddie Murphy has ten children.", "Basketball is played with two teams, each having five players on the court at one time."], "decomposition": ["How many children does Eddie Murphy have?", "How many players are on a basketball team?", "How many teams are on the basketball court at the same time?", "How much is #2 multiplied by #3?", "Is #1 greater than or equal to #4?"], "evidence": [[[["Eddie Murphy-40", "Eddie Murphy-41", "Eddie Murphy-43"]], [["Basketball-1"]], [["Basketball-1"]], ["operation"], ["operation"]], [[["Eddie Murphy-40"], "no_evidence"], [["Basketball-3"]], [["Basketball-1"]], ["operation"], ["operation"]], [[["Eddie Murphy-41"], "no_evidence"], [["Basketball-3"]], [["Basketball-1"]], ["operation"], ["operation"]]]}
{"id": 851, "term": "Johns Hopkins University", "description": "Private research university in Baltimore, Maryland", "question": "Could the endowment of Johns Hopkins University pay off the MBTA debt?", "answer": false, "facts": ["Johns Hopkins University had an endowment of $6.28 billion in 2019.", "The MBTA is in debt for approximately $9 billion."], "decomposition": ["How much was Johns Hopkins University endowment in 2019?", "How much is the MBTA debt?", "Is #1 greater than #2?"], "evidence": [[["no_evidence"], [["Massachusetts Bay Transportation Authority-91"]], ["operation"]], [[["Johns Hopkins University-11"], "no_evidence"], [["Massachusetts Bay Transportation Authority-90", "Massachusetts Bay Transportation Authority-91"], "no_evidence"], ["operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 902, "term": "Gladiator", "description": "combatant who entertained audiences in the Roman Republic and Roman Empire", "question": "Were gladiators associated with the Coloseum?", "answer": true, "facts": ["The Colosseum was a stadium in the ancient city of Rome, large by even today's standards.", "During the Roman era, it was primarily used to host large spectacles including gladiatorial combat, mock battles, and executions."], "decomposition": ["What kind of building was the Colosseum and which city did it exist in?", "In the era of #1, which kind of events were held in such buildings?", "Did any of #2 involve gladiators?"], "evidence": [[[["Colosseum-1"]], [["Colosseum-2"]], [["Colosseum-2"], "operation"]], [[["Colosseum-1"]], [["Colosseum-1"]], [["Colosseum-2"], "operation"]], [[["Colosseum-1"]], [["Colosseum-2"]], [["Inaugural games of the Flavian Amphitheatre-2"], "operation"]]]}
{"id": 984, "term": "3D printing", "description": "Additive process used to make a three-dimensional object", "question": "Do you need a large room if you want to get into 3D printing?", "answer": false, "facts": ["Home 3D printers are sized to be able to sit on a desk or table.", "The accessories and materials needed for 3D Printers can be stored easily and efficiently in a box or tote."], "decomposition": ["What are the equipment needed for 3D printing?", "How were #1 designed to be accommodated?", "Would #2 require a larger-than-average sized room?"], "evidence": [[[["3D printing-47"], "no_evidence"], [["3D printing-47"], "no_evidence"], [["3D printing-47"], "no_evidence"]], [[["3D printing-47"]], ["no_evidence"], ["no_evidence", "operation"]], [[["3D printing processes-39"]], [["3D printing processes-39"]], ["operation"]]]}
{"id": 824, "term": "Beauty and the Beast (1991 film)", "description": "1991 American animated musical fantasy romance film", "question": "Do inanimate objects come alive in Beauty and the Beast?", "answer": true, "facts": ["Beauty and the Beast features a castle full of items that move and speak on their own. ", "An inanimate object is one that is not alive in any way.", "Main characters of Beauty and the Beast include a talking teacup and a sassy duster."], "decomposition": ["Who are the main characters in Beauty and the Beast?", "What type of entities are the characters listed in #1?", "Are any of the types listed in #2 usually inanimate objects?"], "evidence": [[[["Beauty and the Beast (2017 film)-6"]], [["Beauty and the Beast (2017 film)-6"]], [["Beauty and the Beast (2017 film)-6"]]], [[["Beauty and the Beast (1991 film)-6", "Beauty and the Beast (1991 film)-7"], "no_evidence"], [["Beauty and the Beast (1991 film)-7"], "no_evidence"], ["operation"]], [[["Beauty and the Beast (1991 film)-7"]], [["Beauty and the Beast (1991 film)-10"]], ["operation"]]]}
{"id": 718, "term": "The Great Gatsby", "description": "1925 novel by F. Scott Fitzgerald", "question": "Will speed reader devour The Great Gatsby before the Raven?", "answer": false, "facts": ["F. Scott Fitzgerald's The Great Gatsby is 218 pages.", "Edgar Allan Poe's The Raven is 42 pages."], "decomposition": ["How many pages does The Great Gatsby have?", "How many pages does The Raven have?", "Is #2 greater than #1?"], "evidence": [[[["The Great Gatsby-1"], "no_evidence"], [["The Raven-19"], "no_evidence"], ["operation"]], [[["The Great Gatsby-1", "The Great Gatsby-24"], "no_evidence"], [["The Raven-15"]], ["no_evidence", "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 320, "term": "Walt Disney", "description": "American entrepreneur, animator, voice actor and film producer", "question": "Walt Disney dominated his amusement park peers at Academy Awards?", "answer": true, "facts": ["Walt Disney won a total of 26 Academy Awards.", "The founder of Six Flags, Angus G Wynne, had 0 academy awards.", "The founder of Knott's Berry Farm, Walter Knott, had 0 academy awards."], "decomposition": ["At the Academy Awards, how many awards did Walt Disney win?", "At the Academy Awards, how many awards did Angus G Wynne win?", "At the Academy Awards, how many awards did Walter Knott win?", "Is #1 more than #2 and #3?"], "evidence": [[[["Walt Disney-1"]], [["Angus G. Wynne-1"], "no_evidence"], [["Walter Knott-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Walt Disney-1"]], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Walt Disney-1"]], [["Angus G. Wynne-1"]], [["Walter Knott-1"]], ["operation"]]]}
{"id": 299, "term": "Jackson Pollock", "description": "American painter", "question": "Is it understandable to compare a blood spatter pattern to a Jackson Pollock piece?", "answer": true, "facts": ["Jackson Pollock is well known for a style of art formed through splashing liquids on canvas.", "Blood spatter patterns are caused by a splash of blood onto a surface or multiple surfaces."], "decomposition": ["What kinds of work pieces is Jackson Pollock well known for?", "How does he form #1", "How is a blood splatter formed?", "Is #2 comparable to #3?"], "evidence": [[[["Jackson Pollock-1"]], [["Jackson Pollock-2"]], [["Bloodstain pattern analysis-5"]], ["operation"]], [[["Jackson Pollock-1"]], [["Jackson Pollock-2"]], [["Bloodstain pattern analysis-4"]], ["operation"]], [[["Jackson Pollock-10"]], [["Jackson Pollock-2"]], [["Blood squirt-1"]], ["operation"]]]}
{"id": 226, "term": "Cheshire", "description": "County of England", "question": "Do citizens of Cheshire sing La Marseillaise?", "answer": false, "facts": ["Cheshire is a county located in England in the United Kingdom", "La Marseillaise is the national anthem of France"], "decomposition": ["Which song is referred to as 'La Marseillaise'?", "#1 is usually sung by the citizens of which country?", "Which country is Cheshire located in?", "Is #2 the same as #3?"], "evidence": [[[["La Marseillaise-3"]], [["La Marseillaise-3"]], [["Cheshire-53"]], [["Cheshire-54"], "operation"]], [[["La Marseillaise-1"]], [["La Marseillaise-1"]], [["Cheshire-1"]], ["operation"]], [[["La Marseillaise-1"]], [["La Marseillaise-1"]], [["Cheshire-1"]], ["operation"]]]}
{"id": 544, "term": "Walt Disney", "description": "American entrepreneur, animator, voice actor and film producer", "question": "Was Walt Disney able to email his illustrations to people living far away?", "answer": false, "facts": ["Walt Disney died in 1966", "Modern email came into existence in 1971"], "decomposition": ["When was email first used?", "When did Walt Disney die?", "Is #1 before #2?"], "evidence": [[[["Email-9"]], [["Walt Disney-1"]], ["operation"]], [[["Email-1"]], [["Walt Disney-1"]], ["operation"]], [[["Email-1"]], [["Walt Disney-1"]], ["operation"]]]}
{"id": 798, "term": "Family Guy", "description": "American animated sitcom", "question": "Does the art from Family Guy look a lot like the art in American Dad?", "answer": true, "facts": ["Family Guy and American Dad are both Fox Animated Sitcoms animated by Seth MacFarlane.", "Family Guy and American Dad characters all share common facial features and movement styles."], "decomposition": ["Who is the animator for Family Guy?", "Who is the animator for American Dad?", "Is #1 the same as #2?"], "evidence": [[[["Seth MacFarlane-14"]], [["Seth MacFarlane-21"]], ["operation"]], [[["Family Guy-1"]], [["American Dad!-1"]], ["operation"]], [[["Family Guy-2"]], [["American Dad!-14"]], ["operation"]]]}
{"id": 563, "term": "Parody", "description": "Imitative work created to mock, comment on or trivialise an original work", "question": "Is \"A Tale of Two Cities\" a parody of the Bible?", "answer": false, "facts": ["\"A Tale of Two Cities\" is an original work by Charles Dickens.", "The Bible is a religious text written down in the early centuries AD.", "A parody is a deriative work intended to make fun of another piece of media. "], "decomposition": ["Was the story of \"A Tale of Two Cities\" written as an imitation of the Bible?"], "evidence": [[[["A Tale of Two Cities-1", "A Tale of Two Cities-48"], "operation"]], [[["A Tale of Two Cities-1", "Bible-1"]]], [[["A Tale of Two Cities-1"]]]]}
{"id": 212, "term": "Sable", "description": "Species of marten", "question": "Was the sable depicted in Marvel comics anthropomorphic?", "answer": false, "facts": ["Anthropomorphism is the process of giving human characteristics to an animal or non human object.", "A sable is a carnivorous mammal of the weasel family.", "Silver Sable was a female character that first appeared in Marvel Comics in 1985.", "Silver Sable was a human mercenary that wore a silver suit and used hand to hand combat and weaponry to battle war criminals."], "decomposition": ["What characteristics do anthropomorphic characters have? ", "What Marvel character is based on a sable?", "Does #2 fit the criteria for #1?"], "evidence": [[[["Talking animals in fiction-1"]], [["Silver Sable-1"]], ["operation"]], [[["Anthropomorphism-1"]], [["Silver Sable-1"]], ["operation"]], [[["Anthropomorphism-1"]], [["Silver Sable-1"]], ["operation"]]]}
{"id": 315, "term": "Vitamin C", "description": "nutrient found in citrus fruits and other foods", "question": "Did pirates who had scurvy need more Vitamin C?", "answer": true, "facts": ["Pirates were known for having poor teeth and deteriorated gums.", "Gum deterioration and tooth decay is a symptom of scurvy.", "Scurvy is caused by a lack of dietary vitamin C."], "decomposition": ["What causes scurvy?", "Is #1 the same as insufficient vitamin C intake?"], "evidence": [[[["Scurvy-1"]], ["operation"]], [[["Scurvy-1"]], ["operation"]], [[["Scurvy-1"]], ["operation"]]]}
{"id": 594, "term": "Vitamin C", "description": "nutrient found in citrus fruits and other foods", "question": "Can vitamin C rich fruits be bad for health?", "answer": true, "facts": ["Oranges are fruits that are rich in vitamin C.", "Oranges are very acidic fruits that can wear down tooth enamel.", "Too much Vitamin C can cause nausea and diarrhea."], "decomposition": ["Which vitamin are oranges rich in?", "Is #1 the same as vitamin C?", "Can excess of #1 be harmful to a person's health?", "Can the acidity of oranges have adverse effects on human consumers?", "Are #2, #3 and #4 positive?"], "evidence": [[[["Orange (fruit)-20"]], ["operation"], [["Vitamin C megadosage-7"]], [["Citric acid-39", "Orange (fruit)-41"]], ["operation"]], [[["Orange (fruit)-20"]], ["operation"], ["no_evidence", "operation"], [["Citric acid-39"]], ["no_evidence", "operation"]], [[["Vitamin C-69"]], [["Vitamin C-69"]], [["Vitamin C-22"]], ["no_evidence"], ["no_evidence"]]]}
{"id": 250, "term": "Pharmacology", "description": "Branch of biology concerning drugs", "question": "Did Julius Caesar read books on Pharmacology?", "answer": false, "facts": ["Pharmacology has its origins in the Middle Ages.", "The Middle Ages took place from 476 AD-1453 AD.", "Julius Caesar lived from 100 BC-44 BC."], "decomposition": ["When did Julius Caesar die?", "When did Pharmacology emerge as a field of study?", "Is #1 after or within #2?"], "evidence": [[[["Assassination of Julius Caesar-1"]], [["Pharmacology-7"]], ["operation"]], [[["Julius Caesar-1"]], [["Pharmacology-4"]], ["operation"]], [[["Julius Caesar-1"]], [["Pharmacology-7"]], ["operation"]]]}
{"id": 462, "term": "Bee", "description": "Clade of insects", "question": "Are queen bees unnecessary for growing apples?", "answer": true, "facts": ["Mason bees are solitary (they live alone)", "Mason bees are efficient pollinators for orchards", "Apple trees are grown in orchards"], "decomposition": ["What is the social structure of Mason bees?", "Where are Mason bees recognized as efficient pollinators?", "Is #1 needless of a queen, and are apples grown in #2?"], "evidence": [[[["Bee-27"]], [["Mason bee-2", "Orchard-7"], "no_evidence"], ["operation"]], [[["Mason bee-5"]], [["Osmia lignaria-8"]], [["Apple-38", "Mason bee-5"]]], [[["Mason bee-1"]], [["Mason bee-11"], "no_evidence"], [["Apple-1"], "no_evidence", "operation"]]]}
{"id": 545, "term": "AirTrain JFK", "description": "People mover system at JFK Airport in New York City", "question": "Could Katharine Hepburn have ridden the AirTrain JFK?", "answer": false, "facts": ["The AirTrain JFK was built in December 17, 2003.", "Katharine Hepburn died on June 29, 2003."], "decomposition": ["When was the AirTrain JFK built?", "When did Katharine Hepburn die?", "Is #1 before #2?"], "evidence": [[[["AirTrain JFK-20"]], [["Katharine Hepburn-1"]], ["operation"]], [[["AirTrain JFK-2"]], [["Katharine Hepburn-1"]], ["operation"]], [[["AirTrain JFK-15"]], [["Katharine Hepburn-63"]], ["operation"]]]}
{"id": 225, "term": "Anorexia nervosa", "description": "Eating disorder characterized by refusal to maintain a healthy body weight, and fear of gaining weight due to a distorted self image", "question": "Are red legs a sign of failing health in those with Anorexia Nervosa?", "answer": true, "facts": ["Heart failure or disease can lead to the legs becoming red or pink in color.", "Anorexia Nervosa can lead to heart failure and death."], "decomposition": ["What is a complication associated with Anorexia Nervosa that affects the heart?", "What happens to a person's legs when #1 occurs?", "Is #2 a sign of failing health?"], "evidence": [[[["Anorexia nervosa-58"], "no_evidence"], [["Rash-2"], "no_evidence"], ["operation"]], [[["Anorexia nervosa-1"], "no_evidence"], [["Cardiovascular disease-6"], "no_evidence"], ["no_evidence", "operation"]], [[["Anorexia nervosa-53"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 674, "term": "Washington Monument", "description": "Obelisk in Washington, D.C.", "question": "Did Sojourner Truth use the elevator at the Washington Monument?", "answer": false, "facts": ["The Washington Monument was opened to the public in October 1888.", "Sojourner Truth died November 26, 1883. "], "decomposition": ["When did Sojourner Truth pass away?", "When was the Washington Monument opened to the public?", "Is #2 before #1?"], "evidence": [[[["Sojourner Truth-1"]], [["Washington Monument-26"]], [["Washington Monument-26"], "operation"]], [[["Sojourner Truth-1"]], [["Washington Monument-2"]], ["operation"]], [[["Sojourner Truth-1"]], [["Washington Monument-2"]], ["operation"]]]}
{"id": 60, "term": "Robert Downey Jr.", "description": "American actor", "question": "Did Robert Downey Jr. possess same caliber gun as Resident Evil's Barry Burton?", "answer": true, "facts": ["Robert Downey Jr. was arrested in 1996 n drug and weapons charges and possessed a .357 Magnum.", "Barry Burton, a character in the Resident Evil series, used a Colt Python.", "The Colt Python is a type of .357 Magnum revolver."], "decomposition": ["What type of gun did Robert Downey Jr. have when he was arrested?", "What gun does Barry Burton use?", "What type of gun is #2?", "Is #1 the same as #3?"], "evidence": [[[["Robert Downey Jr.-13"]], [["Resident Evil 3: Nemesis-10"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Robert Downey Jr.-13"]], [["Resident Evil 3: Nemesis-10"], "no_evidence"], [["Colt Python-1"]], ["operation"]], [[["Robert Downey Jr.-13"]], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"id": 932, "term": "Metroid", "description": "Video game series", "question": "Did Electronic Arts profit from Metroid sales?", "answer": false, "facts": ["Metroid was created and published by Nintendo.", "Electronic Arts is a video game company that is a competitor to Nintendo.", "Companies cannot profit of the work owned by another company typically.", "Companies do not typically share profits with their competitors."], "decomposition": ["What company created and published Metroid?", "What is the relationship between #1 and Electronic Arts?", "Do two entities engaged in #2 directly benefit each other?"], "evidence": [[[["Metroid-10"]], [["Electronic Arts-15"]], ["operation"]], [[["Metroid-1"]], [["Electronic Arts-15"], "no_evidence"], ["operation"]], [[["Metroid (video game)-8"]], [["Electronic Arts-15"]], ["operation"]]]}
{"id": 651, "term": "Capsaicin", "description": "chemical compound", "question": "Is Black Lives Matter connected with capsaicin?", "answer": true, "facts": ["Black Lives Matter has held numerous protests", "Protesters at Black Lives Matter events have had pepper spray used against them by police", "Capsaicin is the main ingredient of pepper spray"], "decomposition": ["What are the common practical applications of the capsaicin compund?", "What kind of activities does the Black Lives Matter movement engage in?", "Is any of #1 relevant to any of #2?"], "evidence": [[[["Capsaicin-11", "Capsaicin-5", "Capsaicin-7"]], [["Black Lives Matter-20"]], [["Pepper spray-1", "Riot control-1"], "operation"]], [[["Capsaicin-2"]], [["Black Lives Matter-30"]], ["operation"]], [[["Capsaicin-11"]], [["Movement for Black Lives-6"]], [["Movement for Black Lives-7"], "operation"]]]}
