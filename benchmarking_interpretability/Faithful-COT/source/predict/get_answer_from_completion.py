'''Derive the answer from the completions generated by model.
This is useful when you need to run the prediction script on a server, where it may be non-trivial to install certain solvers (e.g. SoufflÃ©).
In this case, you can simply run `predict.py` with the `--completion_only` flag, which will generate the completions only but not derive the answer.
Then, on your local machine with the necessary solvers installed, you can run this script to derive the answer from the completions.
'''
import os
cwd = os.getcwd()
if cwd.endswith("source/predict"):
	os.chdir("../..")  # change the working directory to the root directory
import sys
sys.path.append("source")
from configuration.configuration import Config
from keys import API_KEYS, ORGANIZATION_IDS
import argparse
from model.codex import Model
from dataset.utils import load_data
import jsonlines

if __name__ == "__main__":

	Parser = argparse.ArgumentParser()
	Parser.add_argument("--dataset_name", help="The name of the dataset.", choices=["GSM8K", "ASDiv", "MultiArith", "SVAMP", "AQUA", "date", "StrategyQA", "sports", "saycan", "CLUTRR"])
	Parser.add_argument("--split", help="The split of the dataset.", choices=["train", "dev", "test"])
	Parser.add_argument("--model_name", help="The name of the model (should have a corresponding config file under `configuration/config_files/dataset_name` called `{model_name}.json`.)")
	Parser.add_argument("--debug", help="If true, only run on the first 10 examples.", action="store_true")
	Parser.add_argument("--api_key_ids", help="The API keys to use.", default="['CCB']")

	args = Parser.parse_args()
	model_name = args.model_name
	dataset_name = args.dataset_name
	split = args.split
	debug = args.debug
	api_key_ids = eval(args.api_key_ids)

	api_keys = [API_KEYS[api_key_id] for api_key_id in api_key_ids]
	org_ids = [ORGANIZATION_IDS[api_key_id] for api_key_id in api_key_ids]

	config_frn = f"source/configuration/config_files/{dataset_name}/{model_name}.json"
	config = Config.from_json_file(config_frn)
	config.split = split
	config.dataset_name = dataset_name
	config.api_keys = api_keys
	config.org_ids = org_ids

	# load the dataset
	dataset_frn = f"data/{dataset_name}/{split}.jsonl"
	dataset = load_data(dataset_frn)

	# load the model
	model = Model(config)

	# predict
	output_dir = f"output_dir/{dataset_name}/{split}/{model_name}"
	completion_frn = f"{output_dir}/predictions_completion_only{'_debug' if debug else ''}.jsonl"
	if not os.path.exists(completion_frn):
		completion_frn = f"{output_dir}/predictions{'_debug' if debug else ''}.jsonl"
	all_completions = load_data(completion_frn)

	output_fwn = f"{output_dir}/predictions{'_debug' if debug else ''}.jsonl"

	start_id = 0

	with open(output_fwn, 'w') as fw:
		writer = jsonlines.Writer(fw, flush=True)

		for i, (example, prediction) in enumerate(zip(dataset, all_completions)):
			if debug and i >= 10:
				break
			if i < start_id:
				continue

			if "completions" in prediction:
				completions = prediction["completions"]
			elif "completion" in prediction:
				completions = [prediction["completion"]]
			else:
				raise ValueError(f"Neither 'completion' nor 'completions' found in example {i}.")

			question = example["question"]
			answer, final_completion = model.derive_answer_from_completions(question, completions)
			prediction["answer"] = answer
			prediction["completion"] = final_completion
			writer.write(prediction)

	print(f"Finished predicting on {i+1} examples. Output written to {output_fwn}.")
